{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba6c7e19",
   "metadata": {},
   "source": [
    "# Introduction to pyvene\n",
    "This tutorial shows simple runnable code snippets of how to do different kinds of interventions on neural networks with pyvene."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6994fa",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/stanfordnlp/pyvene/blob/main/pyvene_101.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d123a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Zhengxuan Wu\"\n",
    "__version__ = \"02/01/2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26298448-91eb-4cad-85bf-ec5fef436e1d",
   "metadata": {},
   "source": [
    " # Table of Contents  \n",
    "1. [Set-up](#Set-up)     \n",
    "1. [pyvene 101](#pyvene-101) \n",
    "    1. [Get Attention Weights](#Get-Attention-Weights)\n",
    "        1. [with String Access](#Get-Attention-Weights-with-Direct-Access-String)\n",
    "        1. [with 1-Line Function](#Get-Attention-Weights-with-a-Function)\n",
    "    1. [Set Activations to Zeros](#Set-Activation-to-Zeros) \n",
    "        1. [with Lambda Expression](#Set-Activation-to-Zeros-with-a-Lambda-Expression)\n",
    "    1. [Set Activations with Subspaces](#Set-Activations-to-Zeros-with-Subspaces)\n",
    "    1. [Interchange Intervention](#Interchange-Interventions)\n",
    "    1. [Intervention Config](#Intervention-Configuration)\n",
    "    1. [Addition Intervention](#Addition-Intervention)\n",
    "    1. [Trainable Intervention](#Trainable-Intervention)\n",
    "    1. [Activation Collection](#Activation-Collection-with-Intervention)\n",
    "    1. [Activation Collection with Other Intervention](#Activation-Collection-at-Downstream-of-a-Intervened-Model)\n",
    "    1. [Intervene Single Neuron](#Intervene-on-a-Single-Neuron)\n",
    "    1. [Add New Intervention Type](#Add-New-Intervention-Type)\n",
    "    1. [Intervene on Recurrent NNs](#Recurrent-NNs-(Intervene-a-Specific-Timestep))\n",
    "    1. [Intervene across Times with RNNs](#Recurrent-NNs-(Intervene-cross-Time))\n",
    "    1. [Intervene on LM Generation](#LMs-Generation)\n",
    "    1. [Advanced Intervention on LM Generation (Model Steering)](#Advanced-Intervention-on-LMs-Generation-(Model-Steering))\n",
    "    1. [Debiasing with Backpack LMs](#Debiasing-with-Backpack-LMs)\n",
    "    1. [Saving and Loading](#Saving-and-Loading)\n",
    "    1. [Multi-Source Intervention (Parallel)](#Multi-Source-Interchange-Intervention-(Parallel-Mode))\n",
    "    1. [Multi-Source Intervention (Serial)](#Multi-Source-Interchange-Intervention-(Serial-Mode))\n",
    "    1. [Multi-Source Intervention with Subspaces (Parallel)](#Multi-Source-Interchange-Intervention-with-Subspaces-(Parallel-Mode))\n",
    "    1. [Multi-Source Intervention with Subspaces (Serial)](#Multi-Source-Interchange-Intervention-with-Subspaces-(Serial-Mode))\n",
    "    1. [Interchange Intervention Training](#Interchange-Intervention-Training-(IIT))\n",
    "1. [pyvene 102](#pyvene-102)\n",
    "    1. [Intervention Grouping](#Grouping)\n",
    "    1. [Intervention Skipping](#Intervention-Skipping-in-Runtime)\n",
    "    1. [Subspace Partition](#Subspace-Partition)\n",
    "    1. [Intervention Linking](#Intervention-Linking)\n",
    "    1. [Add New Model Type](#Add-New-Model-Type)\n",
    "    1. [Path Patching](#Composing-Complex-Intervention-Schema:-Path-Patching)\n",
    "    1. [Causal Tracing](#Composing-Complex-Intervention-Schema:-Causal-Tracing-in-15-lines)\n",
    "    1. [Inference-time Intervention](#Inference-time-Intervention)\n",
    "    1. [IntervenableModel from HuggingFace Directly](#IntervenableModel-from-HuggingFace-Directly)\n",
    "    1. [Path Patching with DAS](#Path-Patching-with-Trainable-Interventions)\n",
    "    1. [Intervene ResNet with Lambda Functors](#Intervene-on-ResNet-with-Lambda-Functions)\n",
    "    1. [Intervene ResNet with 1-line DAS Lambda](#Intervene-on-ResNet-with-Trainable-Lambda-Functions)\n",
    "    1. [Run pyvene on NDIF backend](#Run-pyvene-on-NDIF-backend-with-pv.build_intervenable_model(...))\n",
    "    1. [Run LoRAs with pyvene](#Run-LoRA-with-pyvene)\n",
    "1. [The End](#The-End)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706e21b",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08304ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import pyvene\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    !pip install git+https://github.com/stanfordnlp/pyvene.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede4f94",
   "metadata": {},
   "source": [
    "## pyvene 101\n",
    "Before we get started, here are a couple of core notations that are used in this library:\n",
    "- **Base** example: this is the example we are intervening on, or, we are intervening on the computation graph of the model running the **Base** example.\n",
    "- **Source** example or representations: this is the source of our intervention. We use **Source** to intervene on **Base**.\n",
    "- **component**: this is the `nn.module` we are intervening in a pytorch-based NN. For models supported by this library, you can use directly access via str, or use the abstract names defined in the config file (e.g., `h[0].mlp.output` or `mlp_output` with other fields). \n",
    "- **unit**: this is the axis of our intervention. If we say our **unit** is `pos` (`position`), then you are intervening on each token position.\n",
    "- **unit_locations**: this list gives you the percisely location of your intervention. It is the locations of the unit of analysis you are specifying. For instance, if your `unit` is `pos`, and your `unit_location` is 3, then it means you are intervening on the third token. If this field is left as `None`, then no selection will be taken, i.e., you can think of you are getting the raw tensor and you can do whatever you want.\n",
    "- **intervention_type** or **intervention**: this field specifies the intervention you can perform. It can be a primitive type, or it can be a function or a lambda expression for simple interventions. One benefit of using primitives is speed and systematic training schemes. You can also save and load interventions if you use the supported primitives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7245643b-fd44-47a5-a189-ce1565da7e25",
   "metadata": {},
   "source": [
    "### Get Attention Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c7f2f6-b0d3-4fe2-8e4f-c044b93f3ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pyvene as pv\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "# Do not use SDPA attention because we cannot hook to attn_dropout\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained(model_name, attn_implementation=\"eager\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"layer\": 10,\n",
    "    \"component\": \"attention_weight\",\n",
    "    \"intervention_type\": pv.CollectIntervention}, model=gpt2)\n",
    "\n",
    "base = \"When John and Mary went to the shops, Mary gave the bag to\"\n",
    "collected_attn_w = pv_gpt2(\n",
    "    base = tokenizer(base, return_tensors=\"pt\"\n",
    "    ), unit_locations={\"base\": [h for h in range(12)]}\n",
    ")[0][-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee8d393-1676-45e2-8aa7-228343d3b13b",
   "metadata": {},
   "source": [
    "#### Get Attention Weights with Direct Access String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128be2dd-f089-4291-bfc5-7002d031b1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "# gpt2 helper loading model from HuggingFace\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    # based on the module printed above, you can access via string, input means the input to the module\n",
    "    \"component\": \"h[10].attn.attn_dropout.input\",\n",
    "    # you can also initialize the intervention outside\n",
    "    \"intervention\": pv.CollectIntervention()}, model=gpt2)\n",
    "\n",
    "base = \"When John and Mary went to the shops, Mary gave the bag to\"\n",
    "collected_attn_w = pv_gpt2(\n",
    "    base = tokenizer(base, return_tensors=\"pt\"\n",
    "    ), unit_locations={\"base\": [h for h in range(12)]}\n",
    ")[0][-1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22643b2d",
   "metadata": {},
   "source": [
    "#### Get Attention Weights with a Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "678dc46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "cached_w = {}\n",
    "def pv_patcher(b, s): cached_w[\"attn_w\"] = copy.deepcopy(b.data)\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"component\": \"h[10].attn.attn_dropout.input\", \n",
    "    \"intervention\": pv_patcher}, model=gpt2)\n",
    "\n",
    "base = \"When John and Mary went to the shops, Mary gave the bag to\"\n",
    "_ = pv_gpt2(tokenizer(base, return_tensors=\"pt\"))\n",
    "torch.allclose(collected_attn_w, cached_w[\"attn_w\"].unsqueeze(dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5addb-4bd7-4129-b350-0677774f5790",
   "metadata": {},
   "source": [
    "### Set Activation to Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82664f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "# define the component to zero-out\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"layer\": 0, \"component\": \"mlp_output\",\n",
    "    \"source_representation\": torch.zeros(gpt2.config.n_embd)\n",
    "}, model=gpt2)\n",
    "# run the intervened forward pass\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\"), \n",
    "    # we define the intervening token dynamically\n",
    "    unit_locations={\"base\": 3},\n",
    "    output_original_output=True # False then the first element in the tuple is None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c11cb9",
   "metadata": {},
   "source": [
    "#### Set Activation to Zeros with a Lambda Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7627dc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "# indices are specified in the intervention\n",
    "mask = torch.ones(1, 5, 768)\n",
    "mask[:,3,:] = 0.\n",
    "# define the component to zero-out\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"component\": \"h[0].mlp.output\", \"intervention\": lambda b, s: b*mask\n",
    "}, model=gpt2)\n",
    "# run the intervened forward pass\n",
    "intervened_outputs_fn = pv_gpt2(\n",
    "    base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    ")\n",
    "torch.allclose(\n",
    "    intervened_outputs[1].last_hidden_state, \n",
    "    intervened_outputs_fn[1].last_hidden_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72363777",
   "metadata": {},
   "source": [
    "#### Set Activation to Zeros with a Lambda Expression and Subspace notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d86c06f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "# indices are specified in the intervention\n",
    "\n",
    "def pv_patcher(b, s, sp): \n",
    "    mask = torch.ones(1, 5, 768)\n",
    "    mask[:,sp[0][0],:] = 0.\n",
    "    return b*mask\n",
    "\n",
    "# define the component to zero-out\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"component\": \"h[0].mlp.output\", \"intervention\": pv_patcher\n",
    "}, model=gpt2)\n",
    "# run the intervened forward pass\n",
    "intervened_outputs_fn = pv_gpt2(\n",
    "    base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\"),\n",
    "    subspaces=3,\n",
    ")\n",
    "torch.allclose(\n",
    "    intervened_outputs[1].last_hidden_state, \n",
    "    intervened_outputs_fn[1].last_hidden_state\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39071858",
   "metadata": {},
   "source": [
    "### Set Activations to Zeros with Subspaces\n",
    "The notion of subspace means the actual dimensions you are intervening. If we have a representation in a size of 512, the first 128 activation values are its subspace activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7896c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "Directory './tmp/' already exists.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "# built-in helper to get a HuggingFace model\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "# create with dict-based config\n",
    "pv_config = pv.IntervenableConfig({\n",
    "  \"layer\": 0, \"component\": \"mlp_output\"})\n",
    "#initialize model\n",
    "pv_gpt2 = pv.IntervenableModel(pv_config, model=gpt2)\n",
    "# run an intervened forward pass\n",
    "intervened_outputs = pv_gpt2(\n",
    "  # the intervening base input\n",
    "  base=tokenizer(\"The capital of Spain is\", return_tensors=\"pt\"), \n",
    "  # the location to intervene at (3rd token)\n",
    "  unit_locations={\"base\": 3},\n",
    "  # the individual dimensions targetted\n",
    "  subspaces=[10,11,12],\n",
    "  source_representations=torch.zeros(gpt2.config.n_embd)\n",
    ")\n",
    "# sharing\n",
    "pv_gpt2.save(\"./tmp/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410904d",
   "metadata": {},
   "source": [
    "### Interchange Interventions\n",
    "Instead of a static vector, we can intervene the model with activations sampled from a different forward run. We call this interchange intervention, where intervention happens between two examples and we are interchanging activations between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9691c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "# built-in helper to get a HuggingFace model\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "# create with dict-based config\n",
    "pv_config = pv.IntervenableConfig({\n",
    "  \"layer\": 0,\n",
    "  \"component\": \"mlp_output\"},\n",
    "  intervention_types=pv.VanillaIntervention\n",
    ")\n",
    "#initialize model\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "  pv_config, model=gpt2)\n",
    "# run an interchange intervention \n",
    "intervened_outputs = pv_gpt2(\n",
    "  # the base input\n",
    "  base=tokenizer(\n",
    "    \"The capital of Spain is\", \n",
    "    return_tensors = \"pt\"), \n",
    "  # the source input\n",
    "  sources=tokenizer(\n",
    "    \"The capital of Italy is\", \n",
    "    return_tensors = \"pt\"), \n",
    "  # the location to intervene at (3rd token)\n",
    "  unit_locations={\"sources->base\": 3},\n",
    "  # the individual dimensions targeted\n",
    "  subspaces=[10,11,12]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890fda4",
   "metadata": {},
   "source": [
    "### Intervention Configuration\n",
    "You can also initialize the config without the lazy dictionary passing by enabling more options, e.g., the mode of these interventions are executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4faa3e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "IntervenableConfig\n",
      "{\n",
      "    \"model_type\": \"None\",\n",
      "    \"representations\": [\n",
      "        {\n",
      "            \"layer\": 0,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"intervention\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        },\n",
      "        {\n",
      "            \"layer\": 1,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"intervention\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        },\n",
      "        {\n",
      "            \"layer\": 2,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"intervention\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        },\n",
      "        {\n",
      "            \"layer\": 3,\n",
      "            \"component\": \"mlp_output\",\n",
      "            \"unit\": \"pos\",\n",
      "            \"max_number_of_units\": 1,\n",
      "            \"low_rank_dimension\": null,\n",
      "            \"intervention_type\": null,\n",
      "            \"intervention\": null,\n",
      "            \"subspace_partition\": null,\n",
      "            \"group_key\": null,\n",
      "            \"intervention_link_key\": null,\n",
      "            \"moe_key\": null,\n",
      "            \"source_representation\": \"PLACEHOLDER\",\n",
      "            \"hidden_source_representation\": null\n",
      "        }\n",
      "    ],\n",
      "    \"intervention_types\": \"<class 'pyvene.models.interventions.VanillaIntervention'>\",\n",
      "    \"mode\": \"parallel\",\n",
      "    \"sorted_keys\": \"None\",\n",
      "    \"intervention_dimensions\": \"None\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "# standalone configuration object\n",
    "config = pv.IntervenableConfig([\n",
    "    {\n",
    "        \"layer\": _,\n",
    "        \"component\": \"mlp_output\",\n",
    "        \"source_representation\": torch.zeros(\n",
    "            gpt2.config.n_embd)\n",
    "    } for _ in range(4)],\n",
    "    mode=\"parallel\"\n",
    ")\n",
    "# this object is serializable\n",
    "print(config)\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\"), \n",
    "    unit_locations={\"base\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b2270",
   "metadata": {},
   "source": [
    "### Addition Intervention\n",
    "Activation swap is one kind of interventions we can perform. Here is another simple one: `pv.AdditionIntervention`, which adds the sampled representation into the **Base** run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40f5989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 0,\n",
    "    \"component\": \"mlp_input\"},\n",
    "    pv.AdditionIntervention\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The Space Needle is in downtown\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\"base\": [[[0, 1, 2, 3]]]},\n",
    "    source_representations = torch.rand(gpt2.config.n_embd)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ddf77",
   "metadata": {},
   "source": [
    "### Trainable Intervention\n",
    "Interventions can contain trainable parameters, and hook-up with the model to receive gradients end-to-end. They are often useful in searching for an particular interpretation of the representation.\n",
    "\n",
    "The following example does a single step gradient calculation to push the model to generate `Rome` after the intervention. If we can train such intervention at scale with low loss, it means you have a causal grab onto your model. In terms of interpretability, that means, somehow you find a representation (not the original one since its trained) that maps onto the `capital` output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f058ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "das_config = pv.IntervenableConfig({\n",
    "    \"layer\": 8,\n",
    "    \"component\": \"block_output\",\n",
    "    \"low_rank_dimension\": 1},\n",
    "    # this is a trainable low-rank rotation\n",
    "    pv.LowRankRotatedSpaceIntervention\n",
    ")\n",
    "\n",
    "das_gpt2 = pv.IntervenableModel(das_config, model=gpt2)\n",
    "\n",
    "last_hidden_state = das_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    sources = tokenizer(\n",
    "        \"The capital of Italy is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\"sources->base\": 3}\n",
    ")[-1].last_hidden_state[:,-1]\n",
    "\n",
    "# golden counterfacutual label as Rome\n",
    "label = tokenizer.encode(\n",
    "    \" Rome\", return_tensors=\"pt\")\n",
    "logits = torch.matmul(\n",
    "    last_hidden_state, gpt2.wte.weight.t())\n",
    "\n",
    "m = torch.nn.CrossEntropyLoss()\n",
    "loss = m(logits, label.view(-1))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd2b8e",
   "metadata": {},
   "source": [
    "### Activation Collection with Intervention\n",
    "You can also collect activations with our provided `pv.CollectIntervention` intervention. More importantly, this can be used interchangably with other interventions. You can collect something from an intervened model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e6bd585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 10,\n",
    "    \"component\": \"block_output\",\n",
    "    \"intervention_type\": pv.CollectIntervention}\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    config, model=gpt2)\n",
    "\n",
    "collected_activations = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), unit_locations={\"sources->base\": 3}\n",
    ")[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0d0c6",
   "metadata": {},
   "source": [
    "### Activation Collection at Downstream of a Intervened Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adcfcb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 8,\n",
    "    \"component\": \"block_output\",\n",
    "    \"intervention_type\": pv.VanillaIntervention}\n",
    ")\n",
    "\n",
    "config.add_intervention({\n",
    "    \"layer\": 10,\n",
    "    \"component\": \"block_output\",\n",
    "    \"intervention_type\": pv.CollectIntervention})\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    config, model=gpt2)\n",
    "\n",
    "collected_activations = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    sources = [tokenizer(\n",
    "        \"The capital of Italy is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), None], unit_locations={\"sources->base\": 3}\n",
    ")[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6e4d9",
   "metadata": {},
   "source": [
    "### Intervene on a Single Neuron\n",
    "We want to provide a good user interface so that interventions can be done easily by people with less pytorch or programming experience. Meanwhile, we also want to be flexible and provide the depth of control required for highly specific tasks. Here is an example where we intervene on a specific neuron at a specific head of a layer in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25b6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig({\n",
    "    \"layer\": 8,\n",
    "    \"component\": \"head_attention_value_output\",\n",
    "    \"unit\": \"h.pos\",\n",
    "    \"intervention_type\": pv.CollectIntervention}\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    config, model=gpt2)\n",
    "\n",
    "collected_activations = pv_gpt2(\n",
    "    base = tokenizer(\n",
    "        \"The capital of Spain is\", \n",
    "        return_tensors=\"pt\"\n",
    "    ), \n",
    "    unit_locations={\n",
    "        # GET_LOC is a helper.\n",
    "        # (3,3) means head 3 position 3\n",
    "        \"base\": pv.GET_LOC((3,3))\n",
    "    },\n",
    "    # the notion of subspace is used to target neuron 0.\n",
    "    subspaces=[0]\n",
    ")[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692bc15",
   "metadata": {},
   "source": [
    "### Add New Intervention Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1597221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "class MultiplierIntervention(\n",
    "  pv.ConstantSourceIntervention):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    def forward(\n",
    "    self, base, source=None, subspaces=None, **kwargs):\n",
    "        return base * 99.0\n",
    "# run with new intervention type\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "  \"intervention_type\": MultiplierIntervention}, \n",
    "  model=gpt2)\n",
    "intervened_outputs = pv_gpt2(\n",
    "  base = tokenizer(\"The capital of Spain is\", \n",
    "    return_tensors=\"pt\"), \n",
    "  unit_locations={\"base\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079050f6",
   "metadata": {},
   "source": [
    "### Recurrent NNs (Intervene a Specific Timestep)\n",
    "Existing intervention libraries focus on Transformer models. They often lack of supports for GRUs, LSTMs or any state-space model. The fundemental problem is in the hook mechanism provided by PyTorch. Hook is attached to a module before runtime. Models like GRUs will lead to undesired callback from the hook as there is no notion of state or time of the hook. \n",
    "\n",
    "We make our hook stateful, so you can intervene on recurrent NNs like GRUs. This notion of time will become useful when intervening on Transformers yet want to unroll the causal effect during generation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a53347a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, _, gru = pv.create_gru_classifier(\n",
    "    pv.GRUConfig(h_dim=32))\n",
    "\n",
    "pv_gru = pv.IntervenableModel({\n",
    "    \"component\": \"cell_output\",\n",
    "    \"unit\": \"t\", \n",
    "    \"intervention_type\": pv.ZeroIntervention},\n",
    "    model=gru)\n",
    "\n",
    "rand_t = torch.rand(1,10, gru.config.h_dim)\n",
    "\n",
    "intervened_outputs = pv_gru(\n",
    "  base = {\"inputs_embeds\": rand_t}, \n",
    "  unit_locations={\"base\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031dd5de",
   "metadata": {},
   "source": [
    "### Recurrent NNs (Intervene cross Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b48166c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "# built-in helper to get a GRU\n",
    "_, _, gru = pv.create_gru_classifier(\n",
    "    pv.GRUConfig(h_dim=32))\n",
    "# wrap it with config\n",
    "pv_gru = pv.IntervenableModel({\n",
    "    \"component\": \"cell_output\",\n",
    "    # intervening on time\n",
    "    \"unit\": \"t\", \n",
    "    \"intervention_type\": pv.ZeroIntervention},\n",
    "    model=gru)\n",
    "# run an intervened forward pass\n",
    "rand_b = torch.rand(1,10, gru.config.h_dim)\n",
    "rand_s = torch.rand(1,10, gru.config.h_dim)\n",
    "intervened_outputs = pv_gru(\n",
    "  base = {\"inputs_embeds\": rand_b}, \n",
    "  sources = [{\"inputs_embeds\": rand_s}], \n",
    "  # intervening time step\n",
    "  unit_locations={\"sources->base\": (6, 3)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121366c1",
   "metadata": {},
   "source": [
    "### LMs Generation\n",
    "You can also intervene the generation call of LMs. Here is a simple example where we try to add a vector into the MLP output when the model decodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f718e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "Once upon a time there was a little girl named Lucy. She was three years old and loved to explore. One day, Lucy was walking in the park when she saw a big, red balloon. She was so excited and wanted to play with it.\n",
      "\n",
      "But then, a big, mean man came and said, \"That balloon is mine! You can't have it!\" Lucy was very sad and started to cry.\n",
      "\n",
      "The man said, \"I'm sorry, but I need the balloon for my work. You can have it if you want.\"\n",
      "\n",
      "Lucy was so happy and said, \"Yes please!\" She took the balloon and ran away.\n",
      "\n",
      "But then, the man said, \"Wait! I have an idea. Let's make a deal. If you can guess what I'm going to give you, then you can have the balloon.\"\n",
      "\n",
      "Lucy thought for a moment and then said, \"I guess I'll have to get the balloon.\"\n",
      "\n",
      "The man smiled and said, \"That's a good guess! Here you go.\"\n",
      "\n",
      "Lucy was so happy and thanked the man. She hugged the balloon and ran off to show her mom.\n",
      "\n",
      "The end.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "# built-in helper to get tinystore\n",
    "_, tokenizer, tinystory = pv.create_gpt_neo()\n",
    "emb_happy = tinystory.transformer.wte(\n",
    "    torch.tensor(14628)) \n",
    "\n",
    "pv_tinystory = pv.IntervenableModel([{\n",
    "    \"layer\": l,\n",
    "    \"component\": \"mlp_output\",\n",
    "    \"intervention_type\": pv.AdditionIntervention\n",
    "    } for l in range(tinystory.config.num_layers)],\n",
    "    model=tinystory\n",
    ")\n",
    "# prompt and generate\n",
    "prompt = tokenizer(\n",
    "    \"Once upon a time there was\", return_tensors=\"pt\")\n",
    "unintervened_story, intervened_story = pv_tinystory.generate(\n",
    "    prompt, source_representations=emb_happy*0.3, max_length=256\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(\n",
    "    intervened_story[0], \n",
    "    skip_special_tokens=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e628990d",
   "metadata": {},
   "source": [
    "intervene on generation with source example passed in. The result will be slightly different since we no longer have a static vector to be added in; it is layerwise addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087541f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little girl named Lucy. She was very excited because she was going to the park. She wanted to go to the park and play.\n",
      "\n",
      "When she got to the park, she saw a big slide. She was so excited! She ran to the slide and started to climb up. She was so happy.\n",
      "\n",
      "But then she saw something else. It was a big, scary dog. It was a big, mean dog. He was barking and growling at her. Lucy was scared. She didn't know what to do.\n",
      "\n",
      "Suddenly, she heard a voice. It was her mommy. She said, \"Don't worry, Lucy. I will help you. I will protect you.\"\n",
      "\n",
      "Lucy was so happy. She hugged her mommy and they went to the park. They played together and had lots of fun. Lucy was so happy. She was no longer scared.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "# built-in helper to get tinystore\n",
    "_, tokenizer, tinystory = pv.create_gpt_neo()\n",
    "\n",
    "def pv_patcher(b, s): return b + s*0.1\n",
    "\n",
    "pv_tinystory = pv.IntervenableModel([{\n",
    "    \"layer\": l,\n",
    "    \"component\": \"mlp_output\",\n",
    "    \"intervention\": pv_patcher\n",
    "    } for l in range(tinystory.config.num_layers)],\n",
    "    model=tinystory\n",
    ")\n",
    "# prompt and generate\n",
    "prompt = tokenizer(\n",
    "    \"Once upon a time there was\", return_tensors=\"pt\")\n",
    "happy_prompt = tokenizer(\n",
    "    \" Happy\", return_tensors=\"pt\")\n",
    "_, intervened_story = pv_tinystory.generate(\n",
    "    prompt, happy_prompt, \n",
    "    unit_locations = {\"sources->base\": 0},\n",
    "    max_length=256\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(\n",
    "    intervened_story[0], \n",
    "    skip_special_tokens=True\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b89244e-fbc7-4515-b22c-83fae00224cb",
   "metadata": {},
   "source": [
    "### Advanced Intervention on LMs Generation (Model Steering)\n",
    "\n",
    "We also support model steering with interventions during model generation. You can intervene on prompt tokens, or model decoding steps, or have more advanced intervention with customized interventions.\n",
    "\n",
    "Note that you must set `keep_last_dim = True` to get token-level representations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43422e38-d930-4354-9dc5-191e2abcf928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c046df6ad83d4f6381730fc940f7b866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec60913371647fc85e602b189a5c50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting happy vector ...\n"
     ]
    }
   ],
   "source": [
    "import pyvene as pv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "\n",
    "print(\"Extracting happy vector ...\")\n",
    "happy_id = tokenizer(\"happy\")['input_ids'][-1]\n",
    "happy_vector = model.model.embed_tokens.weight[happy_id].to(\"cuda\")\n",
    "\n",
    "# Create a \"happy\" addition intervention\n",
    "class HappyIntervention(pv.ConstantSourceIntervention):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(\n",
    "            **kwargs, \n",
    "            keep_last_dim=True) # you must set keep_last_dim=True to get tokenized reprs.\n",
    "        self.called_counter = 0\n",
    "\n",
    "    def forward(self, base, source=None, subspaces=None, **kwargs):\n",
    "        if subspaces[\"logging\"]:\n",
    "            print(f\"(called {self.called_counter} times) incoming reprs shape:\", base.shape)\n",
    "        self.called_counter += 1\n",
    "        return base + subspaces[\"mag\"] * happy_vector\n",
    "\n",
    "# Mount the intervention to our steering model\n",
    "pv_config = pv.IntervenableConfig(representations=[{\n",
    "    \"layer\": 20,\n",
    "    \"component\": f\"model.layers[20].output\",\n",
    "    \"low_rank_dimension\": 1,\n",
    "    \"intervention\": HappyIntervention(\n",
    "        embed_dim=model.config.hidden_size, \n",
    "        low_rank_dimension=1)}])\n",
    "pv_model = pv.IntervenableModel(pv_config, model)\n",
    "pv_model.set_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc70ebae-793a-4b2b-a3e3-a2118cc66e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(called 0 times) incoming reprs shape: torch.Size([1, 17, 2304])\n",
      "(called 1 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 2 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 3 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 4 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 5 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 6 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 7 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 8 times) incoming reprs shape: torch.Size([1, 1, 2304])\n",
      "(called 9 times) incoming reprs shape: torch.Size([1, 1, 2304])\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a story for me about dragon.\"\n",
    "\n",
    "prompt = tokenizer.decode(tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": prompt}], \n",
    "    tokenize=True, add_generation_prompt=True)[1:])\n",
    "\n",
    "inputs = tokenizer(\n",
    "    prompt, return_tensors=\"pt\", padding=True, truncation=True\n",
    ").to(\"cuda\")\n",
    "_, generations = pv_model.generate(\n",
    "    inputs, \n",
    "    unit_locations=None,      # set to None means intervention will be applied for each forward call\n",
    "    intervene_on_prompt=True, # intervention will be called for the prompt kv cache call\n",
    "    subspaces=[{\"mag\": 2.0, \"logging\": True}], # other metadata\n",
    "    max_new_tokens=10, do_sample=True, temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa622a1-5d93-43e6-afc2-436bd166299d",
   "metadata": {},
   "source": [
    "**Here you go!** You can see that the intervention is called 10 times. For the first time, it receives the prompt representations and generate the first new token. \n",
    "\n",
    "Now, let's generate some steering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4882c229-8529-4a16-bec0-773e77217d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Anya's grandmother, Elara, had always said happy souls were the happiest kind â€“ even happy dragons. But happy dragons were as rare as a blue moon on a snow day, and happy humans weren't supposed to be happy around them. Dragons, they said, were predators that devoured happiness like it was happy dust.\\n\\nAnya knew better. Happy was a whisper, a happy breeze on the sun-dappled meadow. And she, with her mop-happy hair and laugh that made wildflowers dance, was happy. So she snuck off to the Forbidden Forest, a place where only brave hearts dared to roam\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, generations = pv_model.generate(\n",
    "    inputs, \n",
    "    unit_locations=None,      # set to None means intervention will be applied for each forward call\n",
    "    intervene_on_prompt=True, # intervention will be called for the prompt kv cache call\n",
    "    subspaces=[{\"mag\": 70.0, \"logging\": False}], # other metadata\n",
    "    max_new_tokens=128, do_sample=True, temperature=1.0)\n",
    "\n",
    "tokenizer.decode(generations[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc17327-ea2d-449f-9f11-e94435b1e734",
   "metadata": {},
   "source": [
    "Great! This is your super-happy model. You can follow this to have customized interventions to only intervene on selected steps as well by using some metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d25dc6",
   "metadata": {},
   "source": [
    "### Debiasing with Backpack LMs\n",
    "\n",
    "Models like [Backpack LMs](https://arxiv.org/pdf/2305.16765.pdf) are built with highly interpretable model components. In its original paper, one motivating experiment is using the sense vectors to debias. Here, we try to reproduce one of the experiments in Fig. 3 (pg. 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "841e5a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 200,
       "width": 400
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 200,
       "width": 400
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 200,
       "width": 400
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from plotnine import ggplot, aes, geom_bar, theme, element_text, labs\n",
    "\n",
    "import pyvene as pv\n",
    "_, tokenizer, backpack_gpt2 = pv.create_backpack_gpt2()\n",
    "\n",
    "class MultiplierIntervention(pv.ConstantSourceIntervention):\n",
    "    \"\"\"Multiplier intervention\"\"\"\n",
    "    \n",
    "    def __init__(self, multiplier, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.register_buffer('multiplier', torch.tensor(multiplier))\n",
    "        \n",
    "    def forward(self, base, source=None, subspaces=None, **kwargs):\n",
    "        return base * self.multiplier\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MultiplierIntervention()\"\n",
    "\n",
    "for c in [0, 0.7, 1]:\n",
    "    pv_backpack_gpt2 = pv.IntervenableModel({\n",
    "        \"component\": \"backpack.sense_network.output\",\n",
    "        \"intervention\": MultiplierIntervention(c), \"unit\": \"sense.pos\"}, \n",
    "        model=backpack_gpt2\n",
    "    )\n",
    "    base = tokenizer(\"When the nurse walked into the room,\", \n",
    "                     return_tensors=\"pt\", return_attention_mask=False)\n",
    "    intervened_outputs = pv_backpack_gpt2(\n",
    "        base,\n",
    "        unit_locations={\n",
    "            # use   pv.GET_LOC((nv, s))\n",
    "            \"base\": pv.GET_LOC((10,2))\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # plotting\n",
    "    probs = torch.nn.functional.softmax(\n",
    "        intervened_outputs[1].logits[0][-1], dim=0)\n",
    "    data = pv.top_vals(\n",
    "        tokenizer, probs, n=9,\n",
    "        return_results=True\n",
    "    )\n",
    "    df = pd.DataFrame(data, columns=['Word', 'Probability'])\n",
    "    df['Word'] = pd.Categorical(df['Word'], categories=[x[0] for x in data], ordered=True)\n",
    "    plot = (ggplot(df, aes(x='Word', y='Probability'))\n",
    "            + geom_bar(stat='identity')\n",
    "            + theme(axis_text_x=element_text(rotation=90, hjust=1),\n",
    "                    figure_size=(4, 2))\n",
    "            + labs(title=f\"mul({c})\")\n",
    "    )\n",
    "    print(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb539f4b",
   "metadata": {},
   "source": [
    "### Saving and Loading\n",
    "This is one of the benefits of program abstraction. We abstract out the intervention and its schema, so we have a user friendly interface. Furthermore, it allows us to have a serializable configuration file that tells everything about your configuration.\n",
    "\n",
    "You can then save, share and load interventions easily. Note that you still need your access to the data, if you need to sample **Source** representations from other examples. But we think this is doable via a separate HuggingFace datasets upload. In the future, there could be an option of coupling this configuration with a specific remote dataset as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "272f3773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "Directory './tmp/' already exists.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "# run with new intervention type\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "  \"intervention_type\": pv.ZeroIntervention}, \n",
    "  model=gpt2)\n",
    "\n",
    "pv_gpt2.save(\"./tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50b894b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.\n",
      "WARNING:root:Loading trainable intervention from intkey_layer.0.repr.block_output.unit.pos.nunit.1#0.bin.\n"
     ]
    }
   ],
   "source": [
    "pv_gpt2 = pv.IntervenableModel.load(\n",
    "    \"./tmp/\",\n",
    "    model=gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d07ca8",
   "metadata": {},
   "source": [
    "### Multi-Source Interchange Intervention (Parallel Mode)\n",
    "\n",
    "What is multi-source? In the examples above, interventions are at most across two examples. We support interventions across many examples. You can sample representations from two inputs, and plut them into a single **Base**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "847410a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "_the                 0.07233363389968872\n",
      "_a                   0.05731499195098877\n",
      "_not                 0.04443885385990143\n",
      "_Italian             0.033642884343862534\n",
      "_often               0.024385808035731316\n",
      "_called              0.022171705961227417\n",
      "_known               0.017808808013796806\n",
      "_that                0.016059240326285362\n",
      "_\"                   0.012973357923328876\n",
      "_an                  0.012878881767392159\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "parallel_config = pv.IntervenableConfig([\n",
    "  {\"layer\": 3, \"component\": \"block_output\"},\n",
    "  {\"layer\": 3, \"component\": \"block_output\"}],\n",
    "  # intervene on base at the same time\n",
    "  mode=\"parallel\")\n",
    "parallel_gpt2 = pv.IntervenableModel(\n",
    "  parallel_config, model=gpt2)\n",
    "base = tokenizer(\n",
    "  \"The capital of Spain is\", \n",
    "  return_tensors=\"pt\")\n",
    "sources = [\n",
    "  tokenizer(\"The language of Spain is\", \n",
    "    return_tensors=\"pt\"),\n",
    "  tokenizer(\"The capital of Italy is\", \n",
    "    return_tensors=\"pt\")]\n",
    "intervened_outputs = parallel_gpt2(\n",
    "    base, sources,\n",
    "    {\"sources->base\": (\n",
    "    # each list has a dimensionality of\n",
    "    # [num_intervention, batch, num_unit]\n",
    "    [[[1]],[[3]]],  [[[1]],[[3]]])}\n",
    ")\n",
    "\n",
    "distrib = pv.embed_to_distrib(\n",
    "    gpt2, intervened_outputs[1].last_hidden_state, logits=False)\n",
    "pv.top_vals(tokenizer, distrib[0][-1], n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93402c",
   "metadata": {},
   "source": [
    "### Multi-Source Interchange Intervention (Serial Mode)\n",
    "\n",
    "Or you can do them sequentially, where you intervene among your **Source** examples, and get some intermediate states before merging the activations into the **Base** run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e5752dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_the                 0.06737838685512543\n",
      "_a                   0.059834375977516174\n",
      "_not                 0.04629501700401306\n",
      "_Italian             0.03623826056718826\n",
      "_often               0.021700192242860794\n",
      "_called              0.01840786263346672\n",
      "_that                0.0157712884247303\n",
      "_known               0.014391838572919369\n",
      "_an                  0.013535155914723873\n",
      "_very                0.013022392988204956\n"
     ]
    }
   ],
   "source": [
    "config = pv.IntervenableConfig([\n",
    "  {\"layer\": 3, \"component\": \"block_output\"},\n",
    "  {\"layer\": 10, \"component\": \"block_output\"}],\n",
    "  # intervene on base one after another\n",
    "  mode=\"serial\")\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "  config, model=gpt2)\n",
    "base = tokenizer(\n",
    "  \"The capital of Spain is\", \n",
    "  return_tensors=\"pt\")\n",
    "sources = [\n",
    "  tokenizer(\"The language of Spain is\", \n",
    "    return_tensors=\"pt\"),\n",
    "  tokenizer(\"The capital of Italy is\", \n",
    "    return_tensors=\"pt\")]\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base, sources,\n",
    "    # intervene in serial at two positions\n",
    "    {\"source_0->source_1\": 1, \n",
    "     \"source_1->base\"    : 4})\n",
    "\n",
    "distrib = pv.embed_to_distrib(\n",
    "    gpt2, intervened_outputs[1].last_hidden_state, logits=False)\n",
    "pv.top_vals(tokenizer, distrib[0][-1], n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28621880",
   "metadata": {},
   "source": [
    "### Multi-Source Interchange Intervention with Subspaces (Parallel Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "773aba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    {\"layer\": 0, \"component\": \"block_output\",\n",
    "     \"subspace_partition\": \n",
    "         [[0, 128], [128, 256]]}]*2,\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    "    # act in parallel\n",
    "    mode=\"parallel\"\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "sources = [tokenizer(\"The capital of Italy is\", return_tensors=\"pt\"),\n",
    "          tokenizer(\"The capital of China is\", return_tensors=\"pt\")]\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base, sources,\n",
    "    # on same position\n",
    "    {\"sources->base\": 4},\n",
    "    # on different subspaces\n",
    "    subspaces=[[[0]], [[1]]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223603f",
   "metadata": {},
   "source": [
    "### Multi-Source Interchange Intervention with Subspaces (Serial Mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "305e0607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    {\"layer\": 0, \"component\": \"block_output\",\n",
    "     \"subspace_partition\": [[0, 128], [128, 256]]},\n",
    "    {\"layer\": 2, \"component\": \"block_output\",\n",
    "     \"subspace_partition\": [[0, 128], [128, 256]]}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    "    # act in parallel\n",
    "    mode=\"serial\"\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "sources = [tokenizer(\"The capital of Italy is\", return_tensors=\"pt\"),\n",
    "          tokenizer(\"The capital of China is\", return_tensors=\"pt\")]\n",
    "\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base, sources,\n",
    "    # serialized intervention\n",
    "    # order is based on sources list\n",
    "    {\"source_0->source_1\": 3, \"source_1->base\": 4},\n",
    "    # on different subspaces\n",
    "    subspaces=[[[0]], [[1]]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fcb37",
   "metadata": {},
   "source": [
    "### Interchange Intervention Training (IIT)\n",
    "Interchange intervention training (IIT) is a technique of inducing causal structures into neural models. This library naturally supports this. By training IIT, you can simply turn the gradient on for the wrapping model. In this way, your model can be trained with your interventional signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7dde89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "number of params: 124439808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0022, -0.1783, -0.2780,  ...,  0.0477, -0.2069,  0.1093],\n",
       "         [ 0.0385,  0.0886, -0.6608,  ...,  0.0104, -0.4946,  0.6148],\n",
       "         [ 0.2377, -0.2312,  0.0308,  ...,  0.1085,  0.0456,  0.2494],\n",
       "         [-0.0034,  0.0088, -0.2219,  ...,  0.1198,  0.0759,  0.3953],\n",
       "         [ 0.4635,  0.2698, -0.3185,  ..., -0.2946,  0.2634,  0.2714]]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    \"layer\": 8, \"component\": \"block_output\"}, \n",
    "    model=gpt2\n",
    ")\n",
    "\n",
    "pv_gpt2.enable_model_gradients()\n",
    "print(\"number of params:\", pv_gpt2.count_parameters())\n",
    "\n",
    "# run counterfactual forward as usual\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "sources = [\n",
    "    tokenizer(\"The capital of Italy is\", return_tensors=\"pt\"),\n",
    "]\n",
    "base_outputs, counterfactual_outputs = pv_gpt2(\n",
    "    base, sources, {\"sources->base\": ([[[3]]], [[[3]]])}, output_original_output=True\n",
    ")\n",
    "print(counterfactual_outputs.last_hidden_state - base_outputs.last_hidden_state)\n",
    "# call backward will put gradients on model's weights\n",
    "counterfactual_outputs.last_hidden_state.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7ccad",
   "metadata": {},
   "source": [
    "## pyvene 102\n",
    "Now, you are pretty familiar with pyvene basic APIs. There are more to come. We support all sorts of weird interventions, and we encapsulate them as objects so that, even they are super weird (e.g., nested, multiple locations, different types), you can share them easily with others. BTW, if the intervention is trainable, the artifacts will be saved and shared as well.\n",
    "\n",
    "With that, here are a couple of additional APIs.\n",
    "\n",
    "### Grouping\n",
    "\n",
    "You can group interventions together so that they always receive the same input when you want to use them to get activations at different places. Here is an example, where you are taking in the same **Source** example, you fetch activations twice: once in position 3 and layer 0, once in position 4 and layer 2. You don't have to pass in another dummy **Source**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84afd62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    {\"layer\": 0, \"component\": \"block_output\", \"group_key\": 0},\n",
    "    {\"layer\": 2, \"component\": \"block_output\", \"group_key\": 0}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "sources = [tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")]\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base, sources, \n",
    "    {\"sources->base\": ([\n",
    "        [[3]], [[4]] # these two are for two interventions\n",
    "    ], [             # source position 3 into base position 4\n",
    "        [[3]], [[4]] \n",
    "    ])}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aeb892",
   "metadata": {},
   "source": [
    "### Intervention Skipping in Runtime\n",
    "You may configure a lot of interventions, but during training, not every example will have to use all of them. So, you can skip interventions for different examples differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61cd8fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    # these are equivalent interventions\n",
    "    # we create them on purpose\n",
    "    {\"layer\": 0, \"component\": \"block_output\"},\n",
    "    {\"layer\": 0, \"component\": \"block_output\"},\n",
    "    {\"layer\": 0, \"component\": \"block_output\"}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "# skipping 1, 2 and 3\n",
    "_, pv_out1 = pv_gpt2(base, [None, None, source],\n",
    "    {\"sources->base\": ([None, None, [[4]]], [None, None, [[4]]])})\n",
    "_, pv_out2 = pv_gpt2(base, [None, source, None],\n",
    "    {\"sources->base\": ([None, [[4]], None], [None, [[4]], None])})\n",
    "_, pv_out3 = pv_gpt2(base, [source, None, None],\n",
    "    {\"sources->base\": ([[[4]], None, None], [[[4]], None, None])})\n",
    "# should have the same results\n",
    "print(\n",
    "    torch.equal(pv_out1.last_hidden_state, pv_out2.last_hidden_state),\n",
    "    torch.equal(pv_out2.last_hidden_state, pv_out3.last_hidden_state)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df6acd",
   "metadata": {},
   "source": [
    "### Subspace Partition\n",
    "You can partition your subspace before hand. If you don't, the library assumes you each neuron is in its own subspace. In this example, you partition your subspace into two continous chunk, `[0, 128), [128,256)`, which means all the neurons from index 0 upto 127 are along to partition 1. During runtime, you can intervene on all the neurons in the same parition together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a66bbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    # they are linked to manipulate the same representation\n",
    "    # but in different subspaces\n",
    "    {\"layer\": 0, \"component\": \"block_output\",\n",
    "     # subspaces can be partitioned into continuous chunks\n",
    "     # [i, j] are the boundary indices\n",
    "     \"subspace_partition\": [[0, 128], [128, 256]]}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "\n",
    "# using intervention skipping for subspace\n",
    "intervened_outputs = pv_gpt2(\n",
    "    base, [source],\n",
    "    {\"sources->base\": 4},\n",
    "    # intervene only only dimensions from 128 to 256\n",
    "    subspaces=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdde257",
   "metadata": {},
   "source": [
    "### Intervention Linking\n",
    "Interventions can be linked to share weights and share subspaces. Here is an example of how to link interventions together. If interventions are trainable, then their weights are tied as well.\n",
    "\n",
    "Why this is useful? it is because sometimes, you may want to intervene on different subspaces differently. Say you have a representation in a size of 512, and you hypothesize the first half represents A, and the second half represents B, you can then use the subspace intervention to test it out. With trainable interventions, you can also optimize your interventions on the same representation yet with different subspaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eec19da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    # they are linked to manipulate the same representation\n",
    "    # but in different subspaces\n",
    "    {\"layer\": 0, \"component\": \"block_output\", \n",
    "     \"subspace_partition\": [[0, 128], [128, 256]], \"intervention_link_key\": 0},\n",
    "    {\"layer\": 0, \"component\": \"block_output\",\n",
    "     \"subspace_partition\": [[0, 128], [128, 256]], \"intervention_link_key\": 0}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "\n",
    "# using intervention skipping for subspace\n",
    "_, pv_out1 = pv_gpt2(\n",
    "    base, [None, source],\n",
    "    # 4 means token position 4\n",
    "    {\"sources->base\": ([None, [[4]]], [None, [[4]]])},\n",
    "    # 1 means the second partition in the config\n",
    "    subspaces=[None, [[1]]],\n",
    ")\n",
    "_, pv_out2 = pv_gpt2(\n",
    "    base,\n",
    "    [source, None],\n",
    "    {\"sources->base\": ([[[4]], None], [[[4]], None])},\n",
    "    subspaces=[[[1]], None],\n",
    ")\n",
    "print(torch.equal(pv_out1.last_hidden_state, pv_out2.last_hidden_state))\n",
    "\n",
    "# subspaces provide a list of index and they can be in any order\n",
    "_, pv_out3 = pv_gpt2(\n",
    "    base,\n",
    "    [source, source],\n",
    "    {\"sources->base\": ([[[4]], [[4]]], [[[4]], [[4]]])},\n",
    "    subspaces=[[[0]], [[1]]],\n",
    ")\n",
    "_, pv_out4 = pv_gpt2(\n",
    "    base,\n",
    "    [source, source],\n",
    "    {\"sources->base\": ([[[4]], [[4]]], [[[4]], [[4]]])},\n",
    "    subspaces=[[[1]], [[0]]],\n",
    ")\n",
    "print(torch.equal(pv_out3.last_hidden_state, pv_out4.last_hidden_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f146f-1b9a-4574-ba2c-ebf455a96c16",
   "metadata": {},
   "source": [
    "Other than intervention linking, you can also share interventions at the same component across multiple positions via setting a flag in the intervention object. It will have the same effect as creating one intervention per location and linking them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c647943-c7e1-4024-8c07-b51062e668ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "config = pv.IntervenableConfig([\n",
    "    # they are linked to manipulate the same representation\n",
    "    # but in different subspaces\n",
    "    {\"layer\": 0, \"component\": \"block_output\", \"intervention_link_key\": 0},\n",
    "    {\"layer\": 0, \"component\": \"block_output\", \"intervention_link_key\": 0}],\n",
    "    intervention_types=pv.VanillaIntervention,\n",
    ")\n",
    "pv_gpt2 = pv.IntervenableModel(config, model=gpt2)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "\n",
    "_, pv_out = pv_gpt2(\n",
    "    base,\n",
    "    [source, source],\n",
    "    # swap 3rd and 4th token reprs from the same source to the base\n",
    "    {\"sources->base\": ([[[4]], [[3]]], [[[4]], [[3]]])},\n",
    ")\n",
    "\n",
    "keep_last_dim_config = pv.IntervenableConfig([\n",
    "    # they are linked to manipulate the same representation\n",
    "    # but in different subspaces\n",
    "    {\"layer\": 0, \"component\": \"block_output\", \n",
    "     \"intervention\": pv.VanillaIntervention(keep_last_dim=True)}]\n",
    ")\n",
    "keep_last_dim_pv_gpt2 = pv.IntervenableModel(keep_last_dim_config, model=gpt2)\n",
    "\n",
    "_, keep_last_dim_pv_out = keep_last_dim_pv_gpt2(\n",
    "    base,\n",
    "    [source],\n",
    "    # swap 3rd and 4th token reprs from the same source to the base\n",
    "    {\"sources->base\": ([[[3,4]]], [[[3,4]]])},\n",
    ")\n",
    "keep_last_dim_pv_out.last_hidden_state - pv_out.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5b7a3e",
   "metadata": {},
   "source": [
    "### Add New Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acce6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "# get a flan-t5 from HuggingFace\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, T5Config\n",
    "config = T5Config.from_pretrained(\"google/flan-t5-small\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "t5 = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"google/flan-t5-small\", config=config\n",
    ")\n",
    "\n",
    "# config the intervention mapping with pv global vars\n",
    "\"\"\"Only define for the block output here for simplicity\"\"\"\n",
    "pv.type_to_module_mapping[type(t5)] = {\n",
    "    \"mlp_output\": (\"encoder.block[%s].layer[1]\", \n",
    "                   pv.models.constants.CONST_OUTPUT_HOOK),\n",
    "    \"attention_input\": (\"encoder.block[%s].layer[0]\", \n",
    "                        pv.models.constants.CONST_OUTPUT_HOOK),\n",
    "}\n",
    "pv.type_to_dimension_mapping[type(t5)] = {\n",
    "    \"mlp_output\": (\"d_model\",),\n",
    "    \"attention_input\": (\"d_model\",),\n",
    "    \"block_output\": (\"d_model\",),\n",
    "    \"head_attention_value_output\": (\"d_model/num_heads\",),\n",
    "}\n",
    "\n",
    "# wrap as gpt2\n",
    "pv_t5 = pv.IntervenableModel({\n",
    "    \"layer\": 0,\n",
    "    \"component\": \"mlp_output\",\n",
    "    \"source_representation\": torch.zeros(\n",
    "        t5.config.d_model)\n",
    "}, model=t5)\n",
    "\n",
    "# then intervene!\n",
    "base = tokenizer(\"The capital of Spain is\", \n",
    "                 return_tensors=\"pt\")\n",
    "decoder_input_ids = tokenizer(\n",
    "    \"\", return_tensors=\"pt\").input_ids\n",
    "base[\"decoder_input_ids\"] = decoder_input_ids\n",
    "intervened_outputs = pv_t5(\n",
    "    base, \n",
    "    unit_locations={\"base\": 3}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba158a92",
   "metadata": {},
   "source": [
    "### Composing Complex Intervention Schema: Path Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e51cadfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "Directory './tmp/' already exists.\n"
     ]
    }
   ],
   "source": [
    "import pyvene as pv\n",
    "\n",
    "def path_patching_config(\n",
    "    layer, last_layer, \n",
    "    component=\"head_attention_value_output\", unit=\"h.pos\"\n",
    "):\n",
    "    intervening_component = [\n",
    "        {\"layer\": layer, \"component\": component, \"unit\": unit, \"group_key\": 0}]\n",
    "    restoring_components = []\n",
    "    if not component.startswith(\"mlp_\"):\n",
    "        restoring_components += [\n",
    "            {\"layer\": layer, \"component\": \"mlp_output\", \"group_key\": 1}]\n",
    "    for i in range(layer+1, last_layer):\n",
    "        restoring_components += [\n",
    "            {\"layer\": i, \"component\": \"attention_output\", \"group_key\": 1},\n",
    "            {\"layer\": i, \"component\": \"mlp_output\", \"group_key\": 1}\n",
    "        ]\n",
    "    intervenable_config = pv.IntervenableConfig(\n",
    "        intervening_component + restoring_components)\n",
    "    return intervenable_config\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    path_patching_config(4, gpt2.config.n_layer), \n",
    "    model=gpt2\n",
    ")\n",
    "\n",
    "pv_gpt2.save(\n",
    "    save_directory=\"./tmp/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9074f716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.\n"
     ]
    }
   ],
   "source": [
    "pv_gpt2 = pv.IntervenableModel.load(\n",
    "    \"./tmp/\",\n",
    "    model=gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d546e858",
   "metadata": {},
   "source": [
    "### Composing Complex Intervention Schema: Causal Tracing in 15 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0b6a70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import pyvene as pv\n",
    "\n",
    "def causal_tracing_config(\n",
    "  l, c=\"mlp_activation\", w=10, tl=48):\n",
    "  s = max(0, l - w // 2)\n",
    "  e = min(tl, l - (-w // 2))\n",
    "  config = pv.IntervenableConfig(\n",
    "    [{\"component\": \"block_input\"}] + \n",
    "    [{\"layer\": l, \"component\": c} \n",
    "      for l in range(s, e)],\n",
    "    [pv.NoiseIntervention] +\n",
    "    [pv.VanillaIntervention]*(e-s))\n",
    "  return config\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "    causal_tracing_config(4), \n",
    "    model=gpt2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5027498b-66b9-428a-9693-94a6b5614bb9",
   "metadata": {},
   "source": [
    "### Inference-time Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "559bf80a-2a79-46f0-b8a1-8848fd49613b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c7100d49c94e1b94f3429440f1aab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import time, torch\n",
    "import pyvene as pv\n",
    "config, tokenizer, llama = pv.create_llama(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "# load cached extracted activations from the ITI repo:\n",
    "# https://github.com/likenneth/honest_llama\n",
    "o_proj_add_activations = torch.load(\n",
    "    \"./tutorials/basic_tutorials/tutorial_data\"\n",
    "    \"/honest_llama2_chat_7B_o_proj_add_activations.bin\"\n",
    ")\n",
    "_ = llama.cuda()\n",
    "\n",
    "pv_llama = pv.IntervenableModel([{\n",
    "        \"component\": f\"model.layers[{i}].self_attn.o_proj.output\",\n",
    "        \"intervention\": pv.AdditionIntervention(\n",
    "            source_representation=o_proj_add_activations[i].to(\"cuda\")\n",
    "        )\n",
    "    } for i in range(config.num_hidden_layers) if torch.count_nonzero(o_proj_add_activations[i])], \n",
    "    model=llama\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15992a70-288a-43b5-9baf-348e7cb34068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanilla llama-2-chat:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sailhome/wuzhengx/.local/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/sailhome/wuzhengx/.local/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's a cure for insomnia that always works?\n",
      "\n",
      "Insomnia is a common sleep disorder that can affect anyone, regardless of age or gender. It is characterized by difficulty falling asleep, staying asleep, or getting quality sleep. Insomnia can be caused by a variety of factors, including stress, anxiety, depression, certain\n",
      "Execution time: 2.1844897270202637 seconds\n",
      "\n",
      "honest llama-2-chat:\n",
      "What's a cure for insomnia that always works?\n",
      "There is no single cure for insomnia that works for everyone, and it's important to address the underlying causes of sleep problems. However, some strategies that may help improve sleep quality and duration include:\n",
      "\n",
      "1. Practicing relaxation techniques, such as deep breathing, progressive mus\n",
      "Execution time: 2.6960761547088623 seconds\n"
     ]
    }
   ],
   "source": [
    "q = \"What's a cure for insomnia that always works?\"\n",
    "prompt = tokenizer(q, return_tensors=\"pt\").to(\"cuda\")\n",
    "print(\"vanilla llama-2-chat:\")\n",
    "st = time.time()\n",
    "response = llama.generate(**prompt, max_new_tokens=64, do_sample=False)\n",
    "print(tokenizer.decode(response[0], skip_special_tokens=True))\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')\n",
    "print()\n",
    "print(\"honest llama-2-chat:\")\n",
    "st = time.time()\n",
    "_, iti_response = pv_llama.generate(prompt, max_new_tokens=64, do_sample=False)\n",
    "print(tokenizer.decode(iti_response[0], skip_special_tokens=True))\n",
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ae2ebe8-fa4d-426e-b663-089671323456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp_llama/' already exists.\n"
     ]
    }
   ],
   "source": [
    "# save to huggingface directly\n",
    "try:\n",
    "    pv_llama.save(\n",
    "        \"./tmp_llama/\",\n",
    "        save_to_hf_hub=True, \n",
    "        hf_repo_name=\"zhengxuanzenwu/intervenable_honest_llama2_chat_7B\"\n",
    "    )\n",
    "except:\n",
    "    print(\"You have to login into huggingface hub before running this.\")\n",
    "    print(\"usage: huggingface-cli login\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b90b0",
   "metadata": {},
   "source": [
    "### IntervenableModel from HuggingFace Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d26852-f86d-4dea-88f1-2db2634e1ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437f82c9e5ff4a39ae988ccbfd7518df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b98f21c02a4e5da60d67098d99a2c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-2-chat loaded with interventions:\n",
      "What's a cure for insomnia that always works?\n",
      "There is no single cure for insomnia that works for everyone, and it's important to address the underlying causes of sleep problems. However, some strategies that may help improve sleep quality and duration include:\n",
      "\n",
      "1. Practicing relaxation techniques, such as deep breathing, progressive mus\n"
     ]
    }
   ],
   "source": [
    "# others can download from huggingface and use it directly\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pyvene as pv\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to(\"cuda\")\n",
    "\n",
    "pv_model = pv.IntervenableModel.load(\n",
    "    \"zhengxuanzenwu/intervenable_honest_llama2_chat_7B\", # the activation diff ~0.14MB\n",
    "    model,\n",
    ")\n",
    "\n",
    "print(\"llama-2-chat loaded with interventions:\")\n",
    "q = \"What's a cure for insomnia that always works?\"\n",
    "prompt = tokenizer(q, return_tensors=\"pt\").to(\"cuda\")\n",
    "_, iti_response_shared = pv_model.generate(prompt, max_new_tokens=64, do_sample=False)\n",
    "print(tokenizer.decode(iti_response_shared[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956b3b5f",
   "metadata": {},
   "source": [
    "### Path Patching with Trainable Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af501960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import pyvene as pv\n",
    "\n",
    "def path_patching_with_DAS_config(\n",
    "    layer, last_layer, low_rank_dimension,\n",
    "    component=\"attention_output\", unit=\"pos\"\n",
    "):\n",
    "    intervening_component = [{\n",
    "        \"layer\": layer, \"component\": component, \"group_key\": 0,\n",
    "        \"intervention_type\": pv.LowRankRotatedSpaceIntervention,\n",
    "        \"low_rank_dimension\": low_rank_dimension,\n",
    "    }]\n",
    "    restoring_components = []\n",
    "    if not component.startswith(\"mlp_\"):\n",
    "        restoring_components += [{\n",
    "            \"layer\": layer, \"component\": \"mlp_output\", \"group_key\": 1,\n",
    "            \"intervention_type\": pv.VanillaIntervention,\n",
    "        }]\n",
    "    for i in range(layer+1, last_layer):\n",
    "        restoring_components += [{\n",
    "            \"layer\": i, \"component\": \"attention_output\", \"group_key\": 1, \n",
    "            \"intervention_type\": pv.VanillaIntervention},{\n",
    "            \"layer\": i, \"component\": \"mlp_output\", \"group_key\": 1,\n",
    "            \"intervention_type\": pv.VanillaIntervention\n",
    "        }]\n",
    "    intervenable_config = pv.IntervenableConfig(\n",
    "        intervening_component + restoring_components)\n",
    "    return intervenable_config, len(restoring_components)\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "pv_config, num_restores = path_patching_with_DAS_config(4, 6, 1)\n",
    "pv_gpt2 = pv.IntervenableModel(pv_config, model=gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be63453e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0694, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "restore_source = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "source = tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")\n",
    "\n",
    "# zero-out grads\n",
    "_ = pv_gpt2.model.eval()\n",
    "for k, v in pv_gpt2.interventions.items():\n",
    "    v.zero_grad()\n",
    "\n",
    "original_outputs, counterfactual_outputs = pv_gpt2(\n",
    "    base, \n",
    "    sources=[source, restore_source],\n",
    "    unit_locations={\n",
    "        \"sources->base\": 4\n",
    "    }\n",
    ")\n",
    "# put gradients on the trainable intervention only\n",
    "counterfactual_outputs[0].sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907a98c",
   "metadata": {},
   "source": [
    "### Intervene on ResNet with Lambda Functions\n",
    "\n",
    "Huggingface Vision model comes with the support of ResNet. Here, we show how we can use pyvene to intervene on a patch of pixels, like token in transformer, which is like a primitive object in ResNet or ConvNet based NNs.\n",
    "\n",
    "**Caveats:** We go with a pretty much hard-coded way here, but you can customize the hook functions as you want. It does not have to be a lambda function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb48112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-18\")\n",
    "resnet = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "base_image = dataset[\"test\"][\"image\"][0]\n",
    "source_image = dataset[\"test\"][\"image\"][0]\n",
    "base_inputs = feature_extractor(base_image, return_tensors=\"pt\")\n",
    "source_inputs = feature_extractor(source_image, return_tensors=\"pt\")\n",
    "source_inputs['pixel_values'] += 0.5*torch.randn(source_inputs['pixel_values'].shape)\n",
    "\n",
    "def create_mask():\n",
    "    _mask = torch.zeros((56, 56))\n",
    "    _mask[56//2:, 56//2:] = 1\n",
    "    return _mask\n",
    "m = create_mask()\n",
    "\n",
    "pv_resnet = pv.IntervenableModel({\n",
    "    \"component\": \"resnet.embedder.pooler.output\", \n",
    "    \"intervention\": lambda b, s: b * (1. - m) + s * m}, \n",
    "    model=resnet\n",
    ")\n",
    "intervened_outputs = pv_resnet(\n",
    "    base_inputs, [source_inputs], return_dict=True, output_original_output=True\n",
    ")\n",
    "(intervened_outputs.intervened_outputs.logits - intervened_outputs.original_outputs.logits).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0aa78",
   "metadata": {},
   "source": [
    "### Intervene on ResNet with Trainable Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d0095f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0068, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-18\")\n",
    "resnet = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
    "\n",
    "dataset = load_dataset(\"huggingface/cats-image\")\n",
    "base_image = dataset[\"test\"][\"image\"][0]\n",
    "source_image = dataset[\"test\"][\"image\"][0]\n",
    "base_inputs = feature_extractor(base_image, return_tensors=\"pt\")\n",
    "source_inputs = feature_extractor(source_image, return_tensors=\"pt\")\n",
    "source_inputs['pixel_values'] += 0.5*torch.randn(source_inputs['pixel_values'].shape)\n",
    "\n",
    "# trainable DAS directions\n",
    "v = torch.nn.utils.parametrizations.orthogonal(\n",
    "    torch.nn.Linear(56, 10))\n",
    "\n",
    "pv_resnet = pv.IntervenableModel({\n",
    "    \"component\": \"resnet.embedder.pooler.output\", \n",
    "    \"intervention\": lambda b, s: b + ((s @ v.weight.T - b @ v.weight.T) @ v.weight)}, \n",
    "    model=resnet\n",
    ")\n",
    "\n",
    "intervened_outputs = pv_resnet(\n",
    "    base_inputs, [source_inputs], return_dict=True, output_original_output=True\n",
    ")\n",
    "(intervened_outputs.intervened_outputs.logits - intervened_outputs.original_outputs.logits).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14694aea-934e-47f3-ab27-6843f6b5dc7a",
   "metadata": {},
   "source": [
    "### Run pyvene on [NDIF](https://ndif.us/) backend with `pv.build_intervenable_model(...)`\n",
    "\n",
    "[NDIF](https://ndif.us/) provides APIs for running intervened model inference calls either locally or remotely, enabling Pyvene to run intervened model calls remotely with shared resources. This is especially useful when the intervened model is large (e.g., Llama 400B).\n",
    "\n",
    "Note that setting `remote=True` is still under-construction for remote intervention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3fc81-8f61-40d2-9e23-8d61c9dc73b6",
   "metadata": {},
   "source": [
    "**Basic activation collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b289caa-6621-4cc1-883d-c9b91a21617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "WARNING:root:We currently have very limited intervention support for ndif backend.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "from transformers import AutoTokenizer\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "# load any huggingface model as a ndif native model object\n",
    "gpt2_ndif = LanguageModel('openai-community/gpt2', device_map='cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/gpt2')\n",
    "\n",
    "# pyvene provides pv.build_intervenable_model as the generic model builder\n",
    "pv_gpt2_ndif = pv.build_intervenable_model({\n",
    "    # based on the module printed above, you can access via string, input means the input to the module\n",
    "    \"component\": \"transformer.h[10].attn.attn_dropout.input\",\n",
    "    # you can also initialize the intervention gpt2_ndif\n",
    "    \"intervention\": pv.CollectIntervention()}, model=gpt2_ndif, remote=False)\n",
    "\n",
    "base = \"When John and Mary went to the shops, Mary gave the bag to\"\n",
    "ndif_collected_attn_w = pv_gpt2_ndif(\n",
    "    base = tokenizer(base, return_tensors=\"pt\"\n",
    "    ), unit_locations={\"base\": [h for h in range(12)]}\n",
    ")[0][-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97c01ee-0904-4e01-8dee-2608d0635964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpt2 helper loading model from HuggingFace\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "    # based on the module printed above, you can access via string, input means the input to the module\n",
    "    \"component\": \"h[10].attn.attn_dropout.input\",\n",
    "    # you can also initialize the intervention outside\n",
    "    \"intervention\": pv.CollectIntervention()}, model=gpt2)\n",
    "\n",
    "base = \"When John and Mary went to the shops, Mary gave the bag to\"\n",
    "collected_attn_w = pv_gpt2(\n",
    "    base = tokenizer(base, return_tensors=\"pt\"\n",
    "    ), unit_locations={\"base\": [h for h in range(12)]}\n",
    ")[0][-1][0]\n",
    "torch.allclose(ndif_collected_attn_w, collected_attn_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463fc3b-684b-4461-b94e-d69ca310e27e",
   "metadata": {},
   "source": [
    "**Interchange intervention (activation swap between two examples)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f02279-5601-4db9-9823-2e4d3bd8b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "WARNING:root:We currently have very limited intervention support for ndif backend.\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "import pyvene as pv\n",
    "from transformers import AutoTokenizer\n",
    "from nnsight import LanguageModel\n",
    "\n",
    "# load any huggingface model as a ndif native model object\n",
    "gpt2_ndif = LanguageModel('openai-community/gpt2', device_map='cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/gpt2')\n",
    "\n",
    "# create with dict-based config\n",
    "pv_config = pv.IntervenableConfig({\n",
    "  \"component\": \"transformer.h[0].attn.output\",\n",
    "  \"intervention\": pv.VanillaIntervention()}\n",
    ")\n",
    "#initialize model\n",
    "pv_gpt2_ndif = pv.build_intervenable_model(\n",
    "  pv_config, model=gpt2_ndif)\n",
    "# run an interchange intervention \n",
    "intervened_outputs = pv_gpt2_ndif(\n",
    "  # the base input\n",
    "  base=tokenizer(\n",
    "    \"The capital of Spain is\", \n",
    "    return_tensors = \"pt\"), \n",
    "  # the source input\n",
    "  sources=tokenizer(\n",
    "    \"The capital of Italy is\", \n",
    "    return_tensors = \"pt\"), \n",
    "  # the location to intervene at (3rd token)\n",
    "  unit_locations={\"sources->base\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4aa11e-49b0-4964-8963-1a677defe975",
   "metadata": {},
   "source": [
    "### Run LoRA with pyvene\n",
    "\n",
    "`pyvene` works just like any other PEFT library out there!  \n",
    "One key difference between LoRA interventions and ours is that our interventions **do not** consume the moduleâ€™s inputs during the intervention.\n",
    "\n",
    "For example, LoRA applies the update  \n",
    "`h' = h + ABx`, where `x` is the input to the module.\n",
    "\n",
    "Our current interventions apply  \n",
    "`h' = h + vector`, which modifies only the moduleâ€™s output.\n",
    "\n",
    "If you want the intervention to use the inputs, simply enable the `as_adaptor` flag during initialization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb75f13-aff4-43d0-8a85-1fd1ad5b4e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyvene as pv\n",
    "\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "class MultiplierIntervention(\n",
    "  pv.ConstantSourceIntervention):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "    def forward(\n",
    "    self, base, source=None, subspaces=None, **kwargs):\n",
    "        print(kwargs)\n",
    "        return base * 99.0\n",
    "# run with new intervention type\n",
    "pv_gpt2 = pv.IntervenableModel({\n",
    "  \"intervention_type\": MultiplierIntervention}, \n",
    "  model=gpt2, as_adaptor=True)\n",
    "intervened_outputs = pv_gpt2(\n",
    "  base = tokenizer(\"The capital of Spain is\", \n",
    "    return_tensors=\"pt\"), \n",
    "  unit_locations={\"base\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf24e597-35cd-477d-b065-6c8892354760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[-0.0470, -0.0333, -0.1626,  ..., -0.1337, -0.0571, -0.1059],\n",
       "          [-1.1896,  0.4001, -0.7318,  ...,  0.2210, -0.5071, -0.0642],\n",
       "          [ 0.2947,  0.2673,  0.0732,  ...,  0.1961, -0.1078,  0.0084],\n",
       "          [ 0.5819,  0.5034, -0.1311,  ...,  0.2396, -0.0102, -0.1639],\n",
       "          [-0.3615,  0.0640, -0.3016,  ...,  0.5314, -0.0221,  0.0457]]]), past_key_values=((tensor([[[[-0.9420,  1.9023,  0.8722,  ..., -1.2703, -0.4792,  1.2469],\n",
       "           [-3.0146,  3.3096,  1.0996,  ..., -2.2146, -2.1526,  0.5765],\n",
       "           [-2.3023,  3.0159,  1.5088,  ..., -0.8810, -1.9270,  2.5491],\n",
       "           [-3.2213,  2.7355,  2.7501,  ..., -1.3716, -2.1882, -0.1227],\n",
       "           [-2.0578,  2.3452,  2.1211,  ..., -1.5913, -2.8834,  2.5706]],\n",
       " \n",
       "          [[ 0.1103,  0.6967, -1.1409,  ..., -0.1243,  1.8249, -0.1592],\n",
       "           [-0.1904, -1.6515, -0.1911,  ..., -1.3672,  3.2098,  2.5890],\n",
       "           [ 0.3824, -0.7853, -1.9578,  ..., -1.4214,  3.0401, -1.8813],\n",
       "           [-0.7084, -1.1716,  0.1323,  ...,  0.9398,  3.9210,  0.1375],\n",
       "           [ 0.7588, -1.3649, -0.0528,  ..., -4.1210,  3.5070,  1.0098]],\n",
       " \n",
       "          [[-0.0985, -0.0323,  0.7536,  ..., -1.1902, -1.6401,  0.6545],\n",
       "           [ 1.2133,  0.6665,  0.2092,  ..., -1.9765, -0.0785,  0.6512],\n",
       "           [ 0.4284, -0.2013,  0.8390,  ..., -2.4298,  0.3961,  1.6482],\n",
       "           [ 0.0608, -0.9931, -0.8837,  ..., -1.3733, -0.3960, -1.3413],\n",
       "           [ 0.5536,  0.2763,  0.0346,  ..., -2.9444,  0.9125,  2.0655]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.6009, -0.0877, -0.2693,  ...,  0.1756,  0.7995,  0.5978],\n",
       "           [-0.0376,  0.3369, -0.8190,  ...,  1.8149, -0.3761, -0.0193],\n",
       "           [ 0.2770, -0.0668,  0.0321,  ...,  0.9905,  0.5637,  0.7412],\n",
       "           [ 0.6483, -0.6205,  0.5676,  ...,  1.1572,  1.0311,  0.0496],\n",
       "           [ 0.1551,  0.0728,  0.0780,  ...,  1.1168,  0.1553,  0.5742]],\n",
       " \n",
       "          [[ 1.4709,  1.5225, -0.4336,  ..., -0.1837,  1.0947, -1.6615],\n",
       "           [ 1.7734,  1.3950, -0.3705,  ..., -1.2752,  0.5891, -0.5716],\n",
       "           [ 0.9645, -0.0836, -0.3905,  ..., -0.9862,  1.0593, -0.6931],\n",
       "           [ 1.2994,  0.3113, -0.6981,  ..., -0.1909,  1.5889, -0.8256],\n",
       "           [ 0.8330,  0.1459, -0.6875,  ..., -1.0877,  0.3500,  0.0682]],\n",
       " \n",
       "          [[ 0.6260,  0.2122,  0.2527,  ..., -0.6377,  0.2275,  1.5142],\n",
       "           [ 0.6494,  1.2678, -0.0235,  ..., -0.0110,  0.2603,  1.8200],\n",
       "           [-0.3191,  0.1185, -0.7928,  ...,  1.5298,  0.9201,  0.4668],\n",
       "           [-0.7346,  0.0910,  0.8859,  ..., -0.5096,  0.9492,  1.4190],\n",
       "           [ 1.0487, -0.3414, -0.0301,  ...,  0.3585,  0.6522,  1.4066]]]]), tensor([[[[-0.0131, -0.0145,  0.1269,  ..., -0.0492,  0.1046,  0.0231],\n",
       "           [ 0.0023,  0.1138,  0.1138,  ...,  0.1687,  0.1167,  0.0194],\n",
       "           [-0.0043, -0.1001, -0.0527,  ..., -0.0167, -0.0511,  0.1925],\n",
       "           [-0.1428, -0.0586, -0.1472,  ...,  0.1854,  0.0360,  0.0493],\n",
       "           [ 0.2624, -0.2693,  0.3042,  ..., -0.0675,  0.0543, -0.1101]],\n",
       " \n",
       "          [[ 0.5901,  0.1005, -0.2072,  ..., -0.6938, -0.2776,  0.2052],\n",
       "           [ 0.2363, -0.1259,  0.1672,  ..., -0.0701,  0.0362, -0.2338],\n",
       "           [ 0.7189, -0.1148, -0.3608,  ...,  0.0268,  0.5420,  0.0916],\n",
       "           [ 0.3324, -0.0179,  0.1153,  ..., -0.0555, -0.0012,  0.0992],\n",
       "           [ 0.6020,  0.1056,  0.0313,  ..., -0.1481,  0.1284,  0.0233]],\n",
       " \n",
       "          [[-0.0284, -0.1145, -0.0217,  ...,  0.0039,  0.0788, -0.0040],\n",
       "           [-0.0233, -0.2613, -0.2375,  ..., -0.0751,  0.1982,  0.2191],\n",
       "           [ 0.2403,  0.3179,  0.5751,  ..., -0.0633,  0.1494, -0.2446],\n",
       "           [ 0.3886, -0.0827,  0.0393,  ..., -0.1763,  0.0589,  0.4323],\n",
       "           [ 0.1910,  0.1173,  0.0859,  ..., -0.0164,  0.0647,  0.0749]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1077, -0.2132, -0.0218,  ..., -0.2321,  0.0213, -0.0665],\n",
       "           [-0.1809,  0.3808,  0.0739,  ...,  0.3097,  0.2036,  0.1364],\n",
       "           [-0.2193, -0.1360,  0.0198,  ..., -0.3389, -0.0581, -0.1202],\n",
       "           [ 0.2084,  0.6459,  0.1954,  ...,  0.4135,  0.0334,  0.0066],\n",
       "           [-0.3330,  0.3262,  0.1770,  ...,  0.1923, -0.4668, -0.0183]],\n",
       " \n",
       "          [[ 0.0932, -0.1040, -0.2110,  ...,  0.1850,  0.2238, -0.0320],\n",
       "           [ 0.2499, -0.0979,  0.3028,  ..., -0.1087, -0.0018,  0.1582],\n",
       "           [ 0.0085,  0.1011, -0.0063,  ..., -0.1190, -0.1674,  0.0995],\n",
       "           [-0.1972, -0.3250,  0.0813,  ...,  0.4875, -0.1596,  0.1451],\n",
       "           [-0.1607,  0.0090, -0.0288,  ..., -0.5601, -0.2406,  0.0027]],\n",
       " \n",
       "          [[-0.0248, -0.3783,  0.1184,  ...,  0.0116, -0.2484, -0.1156],\n",
       "           [ 0.0285,  0.3629, -0.2635,  ...,  0.2260,  0.1068,  0.0685],\n",
       "           [ 0.0572, -0.1604,  0.2133,  ...,  0.1905,  0.2431,  0.2019],\n",
       "           [-0.0762,  0.2012, -0.1561,  ...,  0.4966,  0.0078,  0.0138],\n",
       "           [-0.0398, -0.0934, -0.0887,  ...,  0.0794,  0.3481,  0.0414]]]])), (tensor([[[[-0.3465,  1.8232, -1.4522,  ...,  1.4427, -0.8329,  1.0962],\n",
       "           [ 0.1822,  1.5827,  0.2313,  ..., -0.5253, -0.5913, -0.0937],\n",
       "           [ 0.9332,  1.2611, -1.3495,  ..., -0.3168, -1.9332,  0.3915],\n",
       "           [ 0.1622,  1.5626,  0.1351,  ..., -0.1475, -1.9539, -0.3317],\n",
       "           [ 0.0964,  1.8222, -1.0043,  ..., -0.2769, -1.6120,  0.1407]],\n",
       " \n",
       "          [[-0.8245, -0.3510, -0.5746,  ..., -0.2983,  0.9754, -0.5511],\n",
       "           [-0.7495, -0.2759, -1.4809,  ..., -0.1637,  0.0086, -0.4048],\n",
       "           [ 0.0530,  0.4844, -1.3699,  ..., -0.7844,  1.0184, -0.4922],\n",
       "           [ 0.0173,  0.3330, -1.5147,  ...,  0.1456, -0.2539, -0.2282],\n",
       "           [-0.4447,  0.7996, -1.3696,  ..., -0.4883,  0.6425, -0.3239]],\n",
       " \n",
       "          [[ 0.3444,  0.0273,  0.0736,  ..., -1.2545,  0.2919, -0.1958],\n",
       "           [-0.0196,  0.4030, -0.5876,  ..., -1.1264, -0.4080,  0.4222],\n",
       "           [-0.1017,  0.1874, -0.1315,  ..., -0.7968,  0.0914,  0.2163],\n",
       "           [-0.2894, -0.1483, -0.5651,  ..., -0.9235, -0.1034,  0.2988],\n",
       "           [-0.3098, -0.2193, -0.1633,  ..., -1.0772, -0.0862,  0.3115]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3655, -0.2597, -0.7410,  ..., -0.8024,  0.4248, -0.4208],\n",
       "           [-0.5393,  0.5605,  2.3013,  ...,  1.0038, -0.7680, -1.2599],\n",
       "           [ 0.5982,  1.2983,  1.9673,  ...,  0.6883, -0.4081, -0.3325],\n",
       "           [ 2.1513,  0.4210,  1.5813,  ...,  2.3090,  0.0756,  0.0607],\n",
       "           [-0.0430,  2.5767,  1.0928,  ...,  0.0673, -0.4331,  0.9069]],\n",
       " \n",
       "          [[-1.1789, -2.8546,  0.1095,  ...,  1.7660,  1.5671, -1.5985],\n",
       "           [ 0.0247,  0.9647, -0.4405,  ..., -0.9909,  0.5400, -0.0754],\n",
       "           [ 0.3691,  0.4800, -0.4276,  ..., -0.9614,  0.4549,  0.2289],\n",
       "           [-0.0454,  0.5459, -0.4936,  ..., -0.5970,  0.5011, -0.0696],\n",
       "           [ 0.1103,  0.5295, -0.5871,  ..., -0.3970,  0.4603, -0.2421]],\n",
       " \n",
       "          [[ 1.0171,  1.8497,  0.6378,  ..., -0.8035,  0.1293,  0.6040],\n",
       "           [-0.9623,  0.5917,  1.2047,  ...,  1.2023,  0.3685, -0.4480],\n",
       "           [ 1.0955,  2.4286,  0.6072,  ..., -0.0873, -0.7833, -0.4808],\n",
       "           [ 1.2756,  1.2420, -1.7415,  ...,  2.1568,  0.5522, -1.2187],\n",
       "           [ 1.0872,  1.3860, -0.7576,  ...,  0.9572,  0.5183, -0.9602]]]]), tensor([[[[ 2.8582e-01, -5.7216e-02,  7.6863e-03,  ...,  1.7198e-01,\n",
       "            -2.0384e-01, -1.4674e-02],\n",
       "           [-4.4747e-01, -4.0025e-01,  4.0794e-01,  ...,  5.2725e-01,\n",
       "            -5.0735e-02, -3.8716e-01],\n",
       "           [ 1.8478e-01,  3.7101e-01,  3.1462e-01,  ..., -1.4390e-01,\n",
       "            -2.3741e-01,  5.3202e-01],\n",
       "           [ 4.9635e-01,  4.5952e-01, -1.7326e-01,  ...,  5.2943e-02,\n",
       "             4.2873e-01,  3.0131e-01],\n",
       "           [ 2.0122e-01,  1.1706e-01, -1.8561e-01,  ..., -2.0224e-01,\n",
       "            -4.8635e-01, -1.9328e-01]],\n",
       " \n",
       "          [[ 1.9847e-01, -5.7434e-02, -1.4368e-01,  ...,  4.2654e-02,\n",
       "            -4.2432e-01,  3.0031e-02],\n",
       "           [ 7.1104e-02,  2.3005e-01, -2.5205e-01,  ..., -1.8679e-01,\n",
       "             2.4113e-01,  3.2697e-01],\n",
       "           [ 7.6759e-01,  5.2530e-02,  3.9059e-01,  ..., -1.1043e+00,\n",
       "             2.8510e-02,  3.4794e-02],\n",
       "           [-5.6990e-01,  5.0102e-01, -4.6014e-01,  ...,  8.8625e-01,\n",
       "            -5.4177e-02,  1.5497e-01],\n",
       "           [ 2.0130e-01,  1.9844e-01,  6.4778e-01,  ..., -1.9213e-01,\n",
       "            -1.2697e-01,  4.0932e-01]],\n",
       " \n",
       "          [[ 4.5447e-02, -1.3822e-01, -5.6857e-02,  ..., -5.8098e-01,\n",
       "             7.3407e-02,  3.3327e-02],\n",
       "           [ 3.0201e-01,  6.3540e-01,  1.6973e-01,  ..., -6.7171e-01,\n",
       "            -4.4939e-01,  2.1191e-02],\n",
       "           [ 6.2373e-01,  3.4106e-01,  7.9301e-02,  ..., -4.8496e-01,\n",
       "             3.1987e-01, -3.2880e-01],\n",
       "           [ 5.1426e-01,  3.2462e-01,  1.3362e-01,  ..., -7.2015e-01,\n",
       "            -1.1880e-02, -1.5931e-02],\n",
       "           [ 6.0891e-01,  4.2046e-02,  5.4726e-01,  ..., -7.5805e-01,\n",
       "             1.9401e-02, -3.7392e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.4935e-01,  5.5228e-01, -5.8729e-02,  ...,  1.0577e-01,\n",
       "            -1.1574e+00, -1.3604e-02],\n",
       "           [ 6.6733e-02, -3.4431e-01, -2.8696e-01,  ...,  5.9242e-02,\n",
       "            -7.9925e-01, -2.0226e-01],\n",
       "           [ 1.6712e-01, -8.4471e-01,  1.7569e-01,  ..., -6.4462e-02,\n",
       "            -8.3320e-01, -2.2848e-01],\n",
       "           [-9.0038e-01,  1.9924e-01,  4.6074e-01,  ..., -1.5470e-02,\n",
       "            -2.0705e-01, -9.4468e-01],\n",
       "           [ 5.8050e-02, -1.5725e-01, -6.7284e-03,  ..., -5.4662e-02,\n",
       "            -1.5851e-01, -1.6067e-01]],\n",
       " \n",
       "          [[ 3.3667e-01, -2.2411e-01, -1.9435e-01,  ...,  3.1840e-01,\n",
       "            -3.5641e+00, -1.4767e-01],\n",
       "           [-1.8928e-01,  1.2694e-01,  5.7463e-02,  ...,  2.1068e-01,\n",
       "            -1.5550e-02, -4.8522e-02],\n",
       "           [ 1.2541e-01,  5.3377e-01, -1.0974e-01,  ..., -2.5272e-01,\n",
       "            -2.4840e-02,  1.9627e-03],\n",
       "           [ 3.6985e-01,  3.4800e-01,  1.2615e-01,  ..., -2.6024e-01,\n",
       "             2.4917e-01,  9.9812e-02],\n",
       "           [-7.3198e-02,  1.5009e-02,  1.5320e-01,  ..., -3.8365e-02,\n",
       "             5.9036e-02,  3.5107e-01]],\n",
       " \n",
       "          [[ 1.0385e-01, -6.1643e-02, -8.1606e-02,  ..., -1.9553e-01,\n",
       "             1.6988e-01,  7.9386e-02],\n",
       "           [-2.4832e-01,  2.9153e-01,  2.2959e-01,  ..., -3.8934e-01,\n",
       "             1.1222e-01, -1.2287e-01],\n",
       "           [-4.4692e-02, -7.0313e-03, -2.6825e-03,  ..., -2.5056e-01,\n",
       "             9.6331e-02, -2.3530e-02],\n",
       "           [-3.9922e-01,  8.8819e-03,  4.0053e-01,  ..., -2.9525e-01,\n",
       "             1.6284e-01, -3.4380e-02],\n",
       "           [-4.0336e-02, -2.1723e-02,  1.0619e-01,  ..., -1.1799e-01,\n",
       "             1.8969e-01,  2.6244e-02]]]])), (tensor([[[[-1.1258e-01, -1.1088e+00,  2.8973e-01,  ..., -6.3421e-01,\n",
       "            -1.7726e-01,  3.7837e-03],\n",
       "           [ 6.9951e-01, -2.8904e+00, -3.7850e-01,  ..., -7.5146e-01,\n",
       "            -1.1466e+00, -7.3667e-01],\n",
       "           [ 5.0948e-01, -1.7658e+00,  2.7951e-01,  ...,  5.0054e-01,\n",
       "            -3.8215e-01, -2.6041e-01],\n",
       "           [ 1.1854e+00, -3.2169e+00,  1.1440e+00,  ..., -1.8557e-01,\n",
       "            -5.9398e-01, -1.0551e-02],\n",
       "           [ 1.5661e+00, -8.3602e-01, -1.8927e+00,  ..., -8.3474e-02,\n",
       "            -3.4970e-03, -2.1928e+00]],\n",
       " \n",
       "          [[-5.2778e-01,  3.9466e-01, -3.2121e-01,  ...,  1.1577e+00,\n",
       "            -5.7213e-01, -4.4179e-01],\n",
       "           [-1.8184e+00, -1.1632e+00, -1.9734e+00,  ...,  3.9532e-01,\n",
       "             1.0507e-01, -4.7525e-01],\n",
       "           [-3.3596e-01,  1.0857e+00, -1.7939e+00,  ...,  5.6940e-01,\n",
       "             7.5767e-01, -2.7865e-01],\n",
       "           [-2.9214e-01,  1.1324e-01, -2.1717e+00,  ...,  1.5121e+00,\n",
       "            -5.7666e-01, -4.1139e-01],\n",
       "           [-6.0655e-01, -1.1249e+00, -1.4172e+00,  ...,  1.0187e-01,\n",
       "             1.0900e+00, -2.7516e-02]],\n",
       " \n",
       "          [[ 1.2186e+00,  3.0460e+00,  3.7205e+00,  ...,  6.2533e-01,\n",
       "             1.6636e+00, -7.7160e-01],\n",
       "           [-1.0234e+00,  1.5270e+00, -2.0041e+00,  ..., -1.9377e+00,\n",
       "             2.8435e+00,  7.5866e-01],\n",
       "           [-4.1084e+00,  1.3934e+00, -3.3180e+00,  ..., -3.0163e+00,\n",
       "             2.9905e+00, -9.6444e-02],\n",
       "           [-2.5958e+00,  1.2295e+00, -2.7719e+00,  ..., -2.8621e+00,\n",
       "             1.2129e+00, -3.0135e-01],\n",
       "           [-4.0984e+00,  7.9173e-01, -3.7334e+00,  ..., -3.1657e+00,\n",
       "             3.1477e+00,  2.3056e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3252e+00, -2.7270e+00, -2.7397e+00,  ...,  9.5941e-01,\n",
       "             4.3134e-01,  2.7145e+00],\n",
       "           [-2.2303e+00,  5.9225e-01, -1.2438e-02,  ..., -1.2475e+00,\n",
       "            -1.2908e+00, -6.8976e-01],\n",
       "           [-2.4630e+00,  2.9157e+00,  8.9205e-02,  ..., -1.1748e+00,\n",
       "            -2.0747e+00,  1.3924e-01],\n",
       "           [-1.6113e+00,  1.0298e+00,  5.0252e-01,  ..., -6.0414e-01,\n",
       "            -2.7671e+00, -1.9342e-01],\n",
       "           [-2.1623e+00,  3.8247e+00,  8.3823e-01,  ..., -5.8719e-01,\n",
       "            -3.4882e+00, -4.6938e-02]],\n",
       " \n",
       "          [[ 1.7317e+00,  4.5925e-01,  9.2368e-01,  ...,  2.3702e-02,\n",
       "            -1.0098e+00, -3.0809e-01],\n",
       "           [ 2.0708e+00,  5.8280e-01,  1.3778e+00,  ...,  4.8750e-01,\n",
       "            -1.3727e+00, -1.5013e+00],\n",
       "           [ 2.1568e+00,  7.9922e-01,  1.1464e+00,  ..., -3.7394e-01,\n",
       "            -2.3273e+00, -1.4687e+00],\n",
       "           [ 2.6357e+00,  3.9502e-01,  1.4375e+00,  ...,  2.7342e-01,\n",
       "            -1.1045e+00, -6.3293e-01],\n",
       "           [ 2.2048e+00,  9.5133e-01,  5.3944e-01,  ...,  7.1917e-02,\n",
       "            -1.5179e+00, -1.0417e+00]],\n",
       " \n",
       "          [[-2.5208e-01,  1.5814e-01, -5.6552e-01,  ...,  3.1414e-01,\n",
       "             2.8355e-01,  2.2655e-01],\n",
       "           [-6.6626e-01,  3.2980e-01, -4.5747e-01,  ..., -6.7405e-02,\n",
       "             4.9693e-01, -6.3058e-01],\n",
       "           [ 1.5953e+00,  1.6567e-01,  4.0184e-01,  ..., -6.0993e-02,\n",
       "             3.3773e-01,  1.3465e-01],\n",
       "           [-8.6894e-01,  5.0118e-01, -6.4966e-01,  ..., -1.1028e-01,\n",
       "             7.9959e-01,  1.5892e-01],\n",
       "           [-1.0453e+00, -3.8122e-01,  1.5246e-01,  ...,  3.0993e-01,\n",
       "             4.0535e-01,  1.6465e-01]]]]), tensor([[[[ 0.0042,  0.0508, -0.1229,  ...,  0.0206,  0.0479, -0.5479],\n",
       "           [-0.0894,  0.0865, -0.0662,  ...,  0.0611,  0.7432,  1.1785],\n",
       "           [-0.0073,  0.4151, -0.5679,  ..., -0.0975, -0.1358,  0.8398],\n",
       "           [-0.3585, -0.7052, -0.0562,  ..., -0.3674,  0.9493,  0.2350],\n",
       "           [ 0.4193, -0.1634,  0.0655,  ..., -1.0526, -0.2165,  0.3246]],\n",
       " \n",
       "          [[ 0.0133, -0.0290,  0.0555,  ..., -0.0442,  0.0062,  0.0345],\n",
       "           [ 0.4085,  0.5638,  0.1995,  ...,  0.6187,  0.4993,  0.5036],\n",
       "           [ 0.2744, -0.0044,  0.0430,  ...,  0.0430, -0.0563,  0.0396],\n",
       "           [-1.1154, -0.9854,  0.3389,  ...,  0.6215,  0.0924, -0.5088],\n",
       "           [-0.1425,  0.2993,  0.2439,  ...,  0.0308,  0.1767,  0.0295]],\n",
       " \n",
       "          [[ 0.0140, -0.8073, -0.0366,  ...,  0.0730,  0.0084, -0.0269],\n",
       "           [ 0.0784, -1.6045,  0.6614,  ..., -0.1302,  0.2635,  0.4644],\n",
       "           [-0.5644, -0.7299, -0.6670,  ..., -0.4525,  0.0739, -0.0408],\n",
       "           [-0.1710, -1.3513, -0.0895,  ..., -0.0406,  0.7931, -0.8708],\n",
       "           [-0.0829, -1.4160,  0.1576,  ...,  0.8342, -0.3649,  0.3400]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0142, -0.0709,  1.3435,  ..., -0.0737,  0.2010, -0.0282],\n",
       "           [ 0.1392,  0.2672,  0.8285,  ..., -0.0884,  0.2657,  0.2554],\n",
       "           [-0.3826,  0.1674,  2.6626,  ...,  0.0281, -0.4260,  0.0423],\n",
       "           [-0.2673,  0.1266,  1.1202,  ..., -0.0898,  0.2458,  0.6937],\n",
       "           [ 0.1390, -0.5941,  2.3192,  ...,  0.7997,  0.1736, -0.1705]],\n",
       " \n",
       "          [[-0.0313, -0.0907, -0.1506,  ...,  0.1141,  0.1292,  0.1926],\n",
       "           [ 0.2436,  0.2542, -0.3439,  ...,  0.2510, -0.4744, -0.4987],\n",
       "           [-0.1553,  0.0593,  0.5692,  ...,  1.1155, -0.2025, -0.7274],\n",
       "           [-0.0825, -0.2667,  0.0351,  ...,  0.0223,  0.2548, -0.9717],\n",
       "           [ 0.5381,  0.0739, -0.0766,  ...,  0.2855, -0.7870, -0.0313]],\n",
       " \n",
       "          [[ 0.0199,  0.0075,  0.0261,  ..., -0.0037,  0.2239,  0.0138],\n",
       "           [-0.3690, -0.3595,  0.3462,  ...,  0.1355, -2.0864,  0.6364],\n",
       "           [-0.6152, -0.1459,  0.1215,  ...,  0.0252, -1.5872,  0.1835],\n",
       "           [ 0.0530, -0.0327, -0.4010,  ..., -0.5494, -1.6249,  0.0120],\n",
       "           [ 0.0229, -0.7263, -0.0643,  ...,  0.0959, -1.6298,  0.5182]]]])), (tensor([[[[ 3.0508e-02, -2.2260e-01,  1.5264e-01,  ..., -8.9290e-01,\n",
       "             7.5289e-01, -1.1935e+00],\n",
       "           [ 5.8306e-01,  2.3442e-01, -9.7875e-01,  ..., -8.9975e-01,\n",
       "             9.7143e-01,  2.3219e+00],\n",
       "           [ 1.2383e-01,  2.0491e-01, -3.6695e-01,  ...,  1.3730e+00,\n",
       "             8.6726e-02,  9.6180e-01],\n",
       "           [ 1.2315e+00,  1.1659e+00, -1.8113e+00,  ...,  3.2690e-01,\n",
       "            -2.5243e-01, -3.9492e-01],\n",
       "           [-1.4745e+00,  7.1706e-01, -1.2561e+00,  ..., -3.1125e-01,\n",
       "            -6.0769e-01,  1.1106e+00]],\n",
       " \n",
       "          [[ 8.1046e-01,  1.8663e-01, -6.4914e-03,  ..., -1.5619e-01,\n",
       "            -1.0988e+00, -1.8967e-01],\n",
       "           [ 1.6754e+00,  3.8858e-01, -1.1122e+00,  ..., -1.8080e-01,\n",
       "             4.1472e+00,  1.8681e+00],\n",
       "           [ 1.7680e+00, -1.7319e+00, -6.1079e-01,  ...,  3.2588e-02,\n",
       "             6.3868e+00,  2.8156e+00],\n",
       "           [ 1.1088e+00,  1.5827e-02, -1.4558e+00,  ..., -1.5038e+00,\n",
       "             5.6695e+00,  5.4954e-01],\n",
       "           [-2.2460e-01, -1.5497e+00,  2.7790e-01,  ...,  9.4994e-01,\n",
       "             5.2972e+00,  2.8296e+00]],\n",
       " \n",
       "          [[ 3.4120e-01, -3.7081e-01, -3.0869e-01,  ...,  3.6410e-01,\n",
       "             1.4399e+00,  2.5755e-01],\n",
       "           [ 4.8430e-01, -4.8031e+00, -3.7024e-01,  ..., -2.4640e+00,\n",
       "            -1.8864e+00, -5.5605e+00],\n",
       "           [-1.8774e+00, -7.1201e+00, -1.3958e+00,  ..., -3.5941e+00,\n",
       "            -8.2879e-01, -6.5574e+00],\n",
       "           [-7.6168e-01, -5.0381e+00, -6.7399e-01,  ..., -3.4646e+00,\n",
       "            -4.4442e+00, -6.0864e+00],\n",
       "           [-1.0645e+00, -6.3648e+00, -1.8234e+00,  ..., -4.6732e+00,\n",
       "            -3.2655e+00, -5.1008e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.2782e-01,  1.7694e+00,  5.3587e-01,  ...,  2.5913e-01,\n",
       "             4.6895e-01, -1.6825e+00],\n",
       "           [-1.4985e+00, -3.9900e+00,  7.6924e-01,  ..., -1.9439e+00,\n",
       "            -4.2593e-01,  6.9186e+00],\n",
       "           [-1.0253e+00, -6.3973e+00,  6.5161e-01,  ..., -2.6711e+00,\n",
       "            -2.0643e+00,  7.4991e+00],\n",
       "           [ 3.0518e-01, -4.4367e+00, -5.1208e-02,  ..., -2.8118e+00,\n",
       "            -2.9944e+00,  8.4560e+00],\n",
       "           [ 7.6885e-01, -7.6467e+00,  2.4848e+00,  ..., -1.9727e+00,\n",
       "            -1.5008e+00,  5.5640e+00]],\n",
       " \n",
       "          [[ 5.4848e-02, -2.5668e-02,  1.4165e-01,  ..., -9.0588e-02,\n",
       "            -8.5854e-02, -1.3366e-01],\n",
       "           [ 7.4051e-01, -2.3363e-01,  4.0647e-01,  ..., -1.4937e+00,\n",
       "             6.9093e-01, -9.4267e-01],\n",
       "           [-4.3320e-01, -1.2141e+00,  4.5455e-02,  ..., -3.8337e-01,\n",
       "             4.6637e-01, -6.5386e-02],\n",
       "           [ 6.0224e-01, -5.8733e-01, -2.7440e-01,  ..., -7.2419e-01,\n",
       "             8.9069e-01,  2.0365e-01],\n",
       "           [-8.7710e-01, -1.0705e+00, -4.9010e-01,  ..., -1.0159e+00,\n",
       "             1.3496e+00, -3.2982e-01]],\n",
       " \n",
       "          [[ 3.9688e-01, -6.6984e-02,  1.8968e+00,  ..., -2.4403e-01,\n",
       "            -2.1560e-01, -1.0126e+00],\n",
       "           [ 2.7025e+00, -1.4364e-01, -5.6163e-01,  ...,  9.0947e-01,\n",
       "            -1.7567e+00,  2.6132e+00],\n",
       "           [ 2.6557e+00,  1.9001e+00, -1.4224e+00,  ...,  9.2779e-01,\n",
       "             1.1563e+00,  3.7309e+00],\n",
       "           [ 2.4632e+00, -3.6027e-01, -1.7296e+00,  ...,  8.0576e-01,\n",
       "            -1.9871e-01,  4.0913e+00],\n",
       "           [ 3.1273e+00,  1.9129e+00, -2.8863e+00,  ...,  1.3604e+00,\n",
       "             2.8461e-01,  3.1688e+00]]]]), tensor([[[[ 4.1882e-02,  6.4490e-02, -9.3272e-03,  ...,  1.6030e-02,\n",
       "             1.0052e-01,  3.5980e-02],\n",
       "           [-1.0658e-01, -1.8789e+00, -3.1201e-01,  ...,  5.4878e-01,\n",
       "            -6.5499e-01, -9.2986e-01],\n",
       "           [-1.4231e-01, -9.6594e-01, -3.4852e-01,  ...,  4.4540e-01,\n",
       "            -3.7740e-01,  1.2650e+00],\n",
       "           [ 3.1029e-02, -9.5073e-01,  2.7457e-01,  ..., -3.7799e-01,\n",
       "             2.8727e-02, -4.9579e-01],\n",
       "           [ 7.7901e-02, -5.4501e-01, -2.7080e-01,  ...,  3.2288e-01,\n",
       "            -8.8174e-01, -4.9989e-01]],\n",
       " \n",
       "          [[-3.3985e-02, -1.3487e-03,  8.3480e-02,  ..., -4.4081e-02,\n",
       "            -3.3619e-02, -5.0814e-02],\n",
       "           [-4.8329e-01, -9.2884e-01, -8.2093e-01,  ...,  8.2018e-01,\n",
       "             4.8451e-01,  5.6007e-01],\n",
       "           [ 2.8539e-01, -2.5436e-01,  8.3193e-02,  ...,  2.1035e-01,\n",
       "             2.0626e-01,  5.2752e-02],\n",
       "           [ 1.5308e-01, -1.5377e+00,  1.6198e-01,  ...,  5.3670e-01,\n",
       "             2.3002e-01,  2.0511e-01],\n",
       "           [ 2.3365e-01,  2.5989e-01,  2.1574e-01,  ..., -7.0079e-02,\n",
       "             7.5592e-02,  1.9950e-01]],\n",
       " \n",
       "          [[ 3.5987e-02, -1.0232e-01, -4.4135e-02,  ..., -2.5785e-02,\n",
       "             8.6479e-02, -1.4895e-01],\n",
       "           [ 8.2788e-01, -1.6392e-01,  4.5955e-01,  ...,  1.0996e-01,\n",
       "            -3.4056e-01, -1.9145e-01],\n",
       "           [-3.2095e-01,  6.1435e-02, -4.4360e-01,  ..., -3.9979e-01,\n",
       "             5.2460e-01,  9.2654e-02],\n",
       "           [-6.0368e-03,  3.9183e-01, -1.5770e-02,  ..., -6.5296e-03,\n",
       "             3.1538e-01,  7.8119e-02],\n",
       "           [-1.8652e-01, -6.6657e-01, -6.8900e-01,  ...,  3.1047e-02,\n",
       "             3.6624e-01, -1.6873e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3814e-02,  1.2032e-01, -7.7499e-03,  ..., -2.3475e-02,\n",
       "             5.9122e-02, -4.1239e-02],\n",
       "           [-5.6712e-01, -2.4990e-01, -1.1301e-01,  ...,  6.3210e-01,\n",
       "            -1.0549e-01, -1.4661e-01],\n",
       "           [ 4.5967e-02, -3.4444e-01,  3.5471e-01,  ..., -1.8587e-01,\n",
       "             1.1126e-01, -1.6611e-01],\n",
       "           [ 9.8416e-02, -1.2662e-01, -1.5050e-01,  ...,  3.4584e-01,\n",
       "             5.7007e-01, -1.6188e-01],\n",
       "           [-2.4604e-01, -1.1159e-01,  1.7980e-01,  ..., -1.3044e-01,\n",
       "             1.5965e-02,  6.6325e-02]],\n",
       " \n",
       "          [[-1.5903e-01, -1.2174e-01, -6.9957e-02,  ..., -2.3985e-01,\n",
       "            -1.6513e-02, -3.9757e-02],\n",
       "           [ 6.2611e-01, -4.8878e-01,  1.0486e+00,  ...,  7.9704e-01,\n",
       "             3.0290e-01,  1.6427e+00],\n",
       "           [ 3.3136e-01,  6.4752e-01,  6.4003e-01,  ...,  3.5175e-01,\n",
       "             5.0449e-01,  8.0407e-01],\n",
       "           [-2.4053e-02,  2.1522e-01,  4.9100e-01,  ...,  7.9204e-01,\n",
       "             5.4498e-02,  7.4261e-01],\n",
       "           [ 2.8259e-01,  2.8755e-01,  6.6452e-01,  ...,  3.3258e-01,\n",
       "            -3.8261e-01,  1.0895e+00]],\n",
       " \n",
       "          [[ 1.1859e-01, -8.5552e-02, -2.7463e-02,  ..., -1.7703e-02,\n",
       "            -9.0103e-02, -9.4804e-02],\n",
       "           [-4.2779e-01,  6.9712e-01,  2.5350e-01,  ...,  3.9976e-01,\n",
       "             4.3862e-03,  2.4845e-01],\n",
       "           [-1.5288e-01, -1.6557e-01,  1.4834e-01,  ..., -5.8381e-01,\n",
       "            -1.7189e-02, -1.6265e-01],\n",
       "           [ 4.9126e-02, -1.4518e-02,  6.4540e-01,  ...,  1.4124e-01,\n",
       "             3.4540e-01,  4.3074e-02],\n",
       "           [-3.5310e-02,  3.5797e-01,  2.4629e-01,  ..., -6.1048e-01,\n",
       "            -8.5623e-01,  3.7415e-01]]]])), (tensor([[[[-8.8230e-01, -1.4005e-01,  3.3679e-01,  ..., -9.7407e-01,\n",
       "             1.9440e-02, -2.9572e+00],\n",
       "           [ 5.5669e-01,  1.2525e+00, -1.7374e+00,  ..., -2.7571e+00,\n",
       "            -2.3292e+00,  8.6639e+00],\n",
       "           [ 1.5033e+00, -7.7194e-01, -6.9042e-01,  ..., -9.8373e-01,\n",
       "            -4.4796e+00,  8.0454e+00],\n",
       "           [ 1.3190e+00, -7.6173e-01, -3.0504e+00,  ..., -1.5608e+00,\n",
       "            -2.1106e+00,  9.6023e+00],\n",
       "           [ 7.4410e-01,  5.0200e-01, -3.0042e+00,  ..., -1.5209e+00,\n",
       "            -2.8327e+00,  9.0338e+00]],\n",
       " \n",
       "          [[ 3.7102e-01, -7.1686e-02,  4.7841e-01,  ..., -1.3458e-01,\n",
       "            -6.9245e-02, -2.2292e+00],\n",
       "           [-9.4823e-01,  3.6707e-01,  2.7844e+00,  ...,  9.1085e-02,\n",
       "            -8.6599e-01,  6.5061e+00],\n",
       "           [-8.3290e-01, -7.0899e-01,  3.5889e+00,  ..., -7.9883e-01,\n",
       "            -2.1492e+00,  5.6428e+00],\n",
       "           [-1.1217e+00,  5.7538e-01,  2.5663e+00,  ..., -3.4775e+00,\n",
       "            -5.9514e-01,  6.7881e+00],\n",
       "           [-2.0011e+00,  1.0643e-01,  2.5387e+00,  ..., -4.4797e-02,\n",
       "            -1.8056e+00,  6.6081e+00]],\n",
       " \n",
       "          [[ 1.1640e-01, -6.5411e-01, -2.1746e-01,  ...,  1.4848e-01,\n",
       "             2.7450e-01, -1.7022e-01],\n",
       "           [-1.3001e-01,  3.2331e+00,  1.2340e+00,  ...,  4.5662e-01,\n",
       "             1.0625e+00, -1.9013e+00],\n",
       "           [ 9.2213e-01,  2.5243e+00,  1.4312e-01,  ..., -6.3106e-02,\n",
       "             4.4157e-01, -6.2753e-01],\n",
       "           [-4.0956e-01,  3.7015e+00, -6.0562e-01,  ..., -4.8077e-01,\n",
       "             1.7568e+00, -1.1209e+00],\n",
       "           [ 7.6170e-01,  2.4634e+00,  1.3252e-02,  ...,  6.8425e-01,\n",
       "             7.8558e-01, -3.0534e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.8907e-01,  2.1348e-02,  5.1326e-03,  ...,  1.2555e+00,\n",
       "             6.2963e-02,  1.7806e+00],\n",
       "           [ 4.4941e-01, -3.0768e-01, -2.7112e-02,  ..., -8.4173e-01,\n",
       "            -1.6935e+00, -7.5371e-01],\n",
       "           [ 2.0142e-01, -4.8423e-01, -6.5706e-02,  ..., -2.5547e+00,\n",
       "             4.5174e-01, -2.3888e-01],\n",
       "           [ 7.6887e-01, -1.9800e-01,  1.2626e+00,  ..., -2.1638e+00,\n",
       "            -4.4478e-01,  1.8223e-01],\n",
       "           [ 4.5330e-01, -3.2374e-01, -1.0842e+00,  ..., -2.4467e+00,\n",
       "            -4.5352e-01,  4.8080e-02]],\n",
       " \n",
       "          [[-3.3280e-01, -1.1855e-01,  2.2112e-01,  ...,  2.5834e-01,\n",
       "            -3.4137e-02,  1.9058e-02],\n",
       "           [ 7.0836e-01, -3.5293e-01,  2.2010e-01,  ...,  7.8188e-01,\n",
       "             1.7173e-01,  3.7149e-01],\n",
       "           [ 1.0877e+00, -1.8622e+00,  1.5121e+00,  ...,  3.1538e-01,\n",
       "             2.5162e-02, -1.2080e-01],\n",
       "           [-1.3985e-01, -7.2131e-01, -6.0190e-01,  ...,  1.2130e+00,\n",
       "             8.8855e-01,  8.6559e-01],\n",
       "           [ 4.3522e-01,  2.8029e-01,  1.1698e+00,  ...,  5.2246e-01,\n",
       "             4.5659e-01, -3.2355e-01]],\n",
       " \n",
       "          [[ 3.3855e+00,  2.1669e+00, -2.1247e+00,  ..., -2.8605e+00,\n",
       "            -3.8921e+00, -1.1778e+00],\n",
       "           [-4.2240e+00,  7.3350e-01,  3.2710e+00,  ..., -2.5978e+00,\n",
       "             7.5398e+00, -3.4617e-01],\n",
       "           [-5.0387e+00,  7.6491e-01,  3.1930e+00,  ..., -4.7603e+00,\n",
       "             9.0059e+00,  2.0309e-02],\n",
       "           [-1.2903e+00, -5.9598e-02,  6.5166e+00,  ..., -4.2099e+00,\n",
       "             7.8657e+00,  1.4699e+00],\n",
       "           [-6.6571e+00, -3.2968e+00,  2.9230e+00,  ..., -2.2998e+00,\n",
       "             1.0916e+01,  2.9824e-01]]]]), tensor([[[[-2.8015e-03, -4.2843e-02,  2.1946e-02,  ...,  5.9664e-02,\n",
       "             2.8541e-02,  7.5017e-02],\n",
       "           [ 5.3025e-01,  1.3834e-01, -2.7160e-01,  ..., -6.4559e-01,\n",
       "             3.5717e-01,  4.4155e-01],\n",
       "           [ 5.4153e-01, -9.0060e-02,  1.9153e-01,  ..., -5.5403e-01,\n",
       "            -2.2346e-01,  7.4121e-02],\n",
       "           [ 9.9504e-02, -1.3098e-01, -8.5048e-02,  ..., -7.2329e-02,\n",
       "            -2.8734e-02,  1.5390e-01],\n",
       "           [ 3.1095e-01,  4.5502e-01, -4.2893e-01,  ..., -8.7908e-01,\n",
       "            -2.0555e-01,  2.6366e-01]],\n",
       " \n",
       "          [[-6.7511e-02, -1.7221e-02, -1.4186e-01,  ..., -4.4599e-02,\n",
       "             4.3422e-02, -1.4441e-02],\n",
       "           [-1.2766e+00, -9.9546e-01,  2.5960e-01,  ..., -7.2550e-02,\n",
       "             1.4938e-01, -4.8761e-01],\n",
       "           [ 5.3390e-01, -3.2931e-01, -1.2810e-01,  ..., -2.2844e-01,\n",
       "            -3.2966e-01,  5.1268e-01],\n",
       "           [ 6.2224e-01,  6.0186e-01, -4.9202e-01,  ...,  1.5118e-01,\n",
       "            -1.6719e-01,  1.0402e-01],\n",
       "           [ 1.0385e+00, -3.6440e-01, -1.5572e-01,  ...,  7.6431e-02,\n",
       "            -1.5048e-01, -1.8951e-01]],\n",
       " \n",
       "          [[ 7.0874e-02,  8.7366e-02,  8.0504e-02,  ...,  1.9967e-02,\n",
       "            -8.7679e-02,  1.5890e-03],\n",
       "           [ 4.5028e-01,  5.3193e-01,  2.3513e-02,  ..., -5.9808e-01,\n",
       "             1.5495e+00,  2.1169e-03],\n",
       "           [ 3.7788e-01,  6.5060e-01, -3.7611e-01,  ..., -1.2806e-01,\n",
       "             3.9400e-02,  4.1944e-01],\n",
       "           [-1.7166e-01,  1.9668e-02,  6.3223e-01,  ..., -2.4085e-01,\n",
       "             4.7414e-01, -4.4303e-01],\n",
       "           [-3.9803e-01,  8.2330e-01, -4.3422e-01,  ...,  1.2028e+00,\n",
       "            -9.4627e-01,  6.2064e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.1236e-03,  7.8853e-02, -8.0076e-02,  ...,  4.3391e-02,\n",
       "             4.2254e-02, -1.3848e-01],\n",
       "           [-5.3555e-01, -6.9845e-01,  2.7475e-01,  ..., -1.0804e+00,\n",
       "             7.5623e-01,  4.4429e-01],\n",
       "           [-8.9569e-02,  2.3889e-02,  5.8994e-01,  ..., -2.2877e-01,\n",
       "             1.2025e+00,  6.8608e-01],\n",
       "           [ 1.7028e-01, -2.4828e-01,  4.5743e-01,  ..., -4.7438e-01,\n",
       "            -4.6424e-01, -4.6427e-01],\n",
       "           [ 3.7587e-02,  6.1320e-01, -3.7174e-01,  ..., -8.1671e-01,\n",
       "             5.8021e-02,  5.9788e-01]],\n",
       " \n",
       "          [[-1.2629e-01, -4.8935e-02,  1.1181e-01,  ..., -6.4385e-02,\n",
       "             4.6905e-02, -1.4047e-02],\n",
       "           [ 8.6851e-01,  1.6241e-01, -4.9652e-01,  ...,  1.9281e+00,\n",
       "             7.9707e-01,  7.3916e-01],\n",
       "           [ 3.9157e-01, -1.0925e+00, -1.0503e+00,  ...,  1.0696e+00,\n",
       "            -6.7317e-01,  5.8496e-01],\n",
       "           [-8.5843e-01, -1.3883e+00, -4.9895e-01,  ...,  1.0846e+00,\n",
       "             7.3490e-01,  1.0566e-02],\n",
       "           [-1.9322e-01, -6.9289e-01,  4.0613e-01,  ..., -4.8515e-01,\n",
       "            -9.2507e-02,  8.7073e-01]],\n",
       " \n",
       "          [[-3.7456e-03, -9.2606e-03, -2.4621e-02,  ..., -2.7746e-02,\n",
       "             5.3264e-03, -1.2048e-02],\n",
       "           [-2.9965e-01, -2.1024e-01,  1.9614e-01,  ...,  1.0057e-01,\n",
       "             3.8212e-01,  6.0374e-01],\n",
       "           [-7.1301e-01,  7.9180e-02,  2.5301e-01,  ..., -3.4508e-01,\n",
       "            -3.4513e-01,  8.7280e-01],\n",
       "           [-2.1779e-01, -5.7439e-02, -4.6136e-01,  ..., -1.3800e-01,\n",
       "             7.0813e-01, -3.1731e-03],\n",
       "           [-3.8677e-01, -1.0167e-01, -3.0107e-01,  ..., -4.0740e-01,\n",
       "            -2.1053e-01,  6.3348e-01]]]])), (tensor([[[[ 2.4425e-02, -2.9901e-01,  2.2618e-01,  ...,  1.7002e+00,\n",
       "            -2.1425e-01, -7.5452e-02],\n",
       "           [ 7.6409e-02,  7.6800e-01, -9.4149e-01,  ..., -3.4657e+00,\n",
       "             5.8755e-03, -1.3839e+00],\n",
       "           [-2.4184e+00,  5.0875e-02,  8.9605e-01,  ..., -3.7332e+00,\n",
       "            -1.1796e+00, -2.2431e+00],\n",
       "           [-6.6942e-01,  1.3709e-01, -9.6284e-01,  ..., -3.3398e+00,\n",
       "            -6.5083e-02, -1.6831e+00],\n",
       "           [-8.9994e-01,  3.9540e-01,  1.2609e+00,  ..., -3.5974e+00,\n",
       "             1.6016e-01, -1.2748e+00]],\n",
       " \n",
       "          [[ 1.6053e-01,  9.7512e-01, -1.4212e+00,  ..., -1.1826e-01,\n",
       "             2.6721e-01,  9.2271e-01],\n",
       "           [-1.5615e+00, -5.2424e+00,  1.6155e+00,  ...,  3.8623e-01,\n",
       "             5.1099e-01, -3.2132e+00],\n",
       "           [ 1.6080e+00, -5.9601e+00,  3.8213e+00,  ...,  2.1178e+00,\n",
       "            -7.1775e-01, -3.5193e+00],\n",
       "           [ 2.1922e-01, -3.1121e+00,  8.7918e-01,  ...,  1.8345e-01,\n",
       "             1.3474e+00, -2.4130e+00],\n",
       "           [ 2.8908e+00, -3.7160e+00,  4.0378e+00,  ..., -1.5735e-01,\n",
       "             3.7319e-01, -2.6246e+00]],\n",
       " \n",
       "          [[-6.6854e-01,  2.4147e-01, -4.0604e-02,  ...,  1.7321e-01,\n",
       "             3.9602e-02, -2.9668e-01],\n",
       "           [ 1.4706e+00, -8.3091e-01, -4.5922e-01,  ..., -7.2517e-01,\n",
       "             7.3935e-01, -3.1308e-01],\n",
       "           [ 1.7049e+00, -8.3476e-01, -6.5948e-01,  ..., -1.4744e+00,\n",
       "            -1.2016e+00, -8.0566e-01],\n",
       "           [ 2.0205e+00, -7.7694e-01, -3.1789e-01,  ...,  2.2895e-01,\n",
       "             2.0698e+00,  7.4116e-02],\n",
       "           [-1.8137e-01,  1.1476e-01, -4.4089e-01,  ..., -2.1057e+00,\n",
       "             5.1824e-02,  4.0010e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.9694e-02,  1.2897e-01,  1.5171e-01,  ..., -1.0306e-01,\n",
       "             2.4162e-02,  1.6164e-01],\n",
       "           [ 1.0572e+00, -3.9030e-02, -8.3610e-01,  ...,  8.2959e-01,\n",
       "             6.5680e-01, -2.0426e+00],\n",
       "           [ 7.6581e-02,  1.3806e+00, -1.1791e+00,  ...,  6.6788e-01,\n",
       "             6.5813e-01,  3.4426e-01],\n",
       "           [ 1.4063e+00, -3.0605e-01, -3.6716e-01,  ...,  8.7264e-01,\n",
       "             1.2596e-01,  5.6582e-02],\n",
       "           [ 3.2398e-02,  1.1391e-01, -8.7922e-01,  ...,  7.5776e-01,\n",
       "             1.2946e+00,  3.9539e-01]],\n",
       " \n",
       "          [[-3.0105e+00,  4.0288e-01, -3.0686e-02,  ..., -4.7620e-01,\n",
       "            -3.6181e-01,  1.2402e+00],\n",
       "           [ 4.6099e+00,  8.6163e-01,  6.6850e-01,  ..., -1.8183e-01,\n",
       "             7.4470e-01, -1.5230e+00],\n",
       "           [ 4.7651e+00,  3.7334e-01,  4.2410e-01,  ..., -7.1080e-01,\n",
       "             9.2342e-01, -1.4508e+00],\n",
       "           [ 5.1659e+00,  1.0360e+00, -1.6138e+00,  ..., -2.5151e-01,\n",
       "            -1.4092e+00, -8.0733e-01],\n",
       "           [ 4.6807e+00,  8.4301e-01,  4.3325e-01,  ..., -1.3749e+00,\n",
       "             9.5950e-02, -4.0212e-01]],\n",
       " \n",
       "          [[-1.0533e-02, -2.4607e-01,  2.7443e-03,  ..., -1.7876e-01,\n",
       "             3.2764e-01,  8.2148e-02],\n",
       "           [ 4.2024e-02, -6.9874e-01, -5.8538e-01,  ..., -1.0378e+00,\n",
       "             5.3997e-01, -2.0877e+00],\n",
       "           [-1.8855e+00, -1.0206e+00,  1.2008e-01,  ...,  3.0703e-01,\n",
       "             1.1462e+00, -1.8275e+00],\n",
       "           [ 1.8004e+00, -1.4076e+00, -4.6401e-01,  ..., -3.0267e-02,\n",
       "            -1.4987e+00,  3.8294e-02],\n",
       "           [ 3.3739e-01, -1.4285e+00,  6.1646e-01,  ...,  8.0817e-01,\n",
       "             1.9368e-01, -9.8813e-01]]]]), tensor([[[[-2.6042e-02, -2.0056e-02,  8.9556e-03,  ..., -6.2775e-03,\n",
       "            -3.4326e-02,  3.5222e-01],\n",
       "           [ 9.3665e-01,  1.5271e-01,  1.6208e+00,  ..., -4.9399e-01,\n",
       "             1.4107e-01, -2.5163e-01],\n",
       "           [-4.8458e-01, -2.2237e+00,  4.0794e-01,  ...,  7.2618e-01,\n",
       "             3.5914e-01, -7.3375e-01],\n",
       "           [ 2.1066e-01,  3.7697e-01,  3.6516e-01,  ..., -8.4879e-01,\n",
       "             2.2904e-01, -1.0118e+00],\n",
       "           [-2.9579e-01, -1.1458e+00,  1.7747e-01,  ...,  8.6092e-01,\n",
       "            -1.1495e-01, -5.1739e-01]],\n",
       " \n",
       "          [[-4.1108e-03, -1.3543e-02,  1.8266e-02,  ..., -2.1517e-02,\n",
       "             2.3074e-02,  1.0844e-02],\n",
       "           [ 2.2783e-01, -2.8594e-01, -4.1709e-01,  ...,  5.2550e-01,\n",
       "             1.3853e+00, -1.7759e+00],\n",
       "           [ 3.9397e-01, -1.0690e+00,  1.4671e-01,  ..., -6.2414e-01,\n",
       "             1.3045e+00, -2.6188e-01],\n",
       "           [ 2.0308e+00,  2.8112e-01, -7.9054e-02,  ..., -1.3155e+00,\n",
       "            -3.1591e-01, -7.1337e-01],\n",
       "           [ 8.9292e-01, -5.4800e-01,  7.7871e-01,  ..., -2.4036e-03,\n",
       "             1.2671e+00, -4.1177e-01]],\n",
       " \n",
       "          [[-5.6640e-02,  9.0555e-03, -3.9321e-02,  ..., -4.0667e-02,\n",
       "             5.0538e-03, -8.1821e-02],\n",
       "           [ 8.9798e-01, -9.3714e-01, -2.5704e-01,  ..., -3.4953e-01,\n",
       "             3.1028e-01, -4.6246e-01],\n",
       "           [-7.7675e-01, -5.0045e-01, -5.3730e-01,  ..., -5.1863e-01,\n",
       "            -1.6679e-01,  4.9321e-01],\n",
       "           [ 5.0556e-02,  4.4528e-02,  1.6873e-01,  ..., -6.3544e-01,\n",
       "             4.3952e-03, -5.7769e-02],\n",
       "           [-2.4063e-01, -8.6159e-01, -3.9051e-02,  ..., -4.8668e-01,\n",
       "            -4.0348e-01,  7.2057e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.3237e-01, -1.9035e-01, -7.2797e-02,  ..., -4.8474e-01,\n",
       "             2.2028e-01,  1.0196e-01],\n",
       "           [ 3.1047e+00, -2.0428e+00,  5.8737e-01,  ...,  9.4627e-01,\n",
       "            -1.1160e+00,  2.0188e+00],\n",
       "           [ 1.8567e+00, -3.0300e+00,  9.4198e-01,  ...,  2.1219e+00,\n",
       "             1.2029e+00,  7.3798e-01],\n",
       "           [ 1.2600e+00, -1.1727e+00, -1.5678e-01,  ...,  1.6963e+00,\n",
       "             9.1625e-01, -1.7367e-01],\n",
       "           [ 8.4441e-01, -2.7783e+00, -2.6734e-01,  ...,  8.1932e-01,\n",
       "            -4.8300e-01, -4.6558e-01]],\n",
       " \n",
       "          [[-8.0519e-02, -1.3379e-01, -4.3315e-02,  ..., -1.8866e-01,\n",
       "            -1.3982e-01,  1.2565e-01],\n",
       "           [-3.2193e-01,  1.8075e-02, -6.6388e-01,  ...,  1.2633e+00,\n",
       "             3.4545e-01, -3.2221e-01],\n",
       "           [-9.0544e-02, -1.2279e-01,  1.9595e-01,  ...,  4.3322e-01,\n",
       "             3.3467e-01,  6.8591e-01],\n",
       "           [-8.9317e-01, -5.9331e-02,  7.0287e-01,  ..., -3.9205e-01,\n",
       "             5.1671e-01, -1.9300e-01],\n",
       "           [-3.0471e-01,  3.0542e-01, -3.6351e-01,  ...,  8.6160e-01,\n",
       "            -1.9915e-01, -6.6009e-02]],\n",
       " \n",
       "          [[-2.8296e-02, -3.7022e-02,  9.1191e-02,  ...,  7.8479e-02,\n",
       "            -4.1196e-02,  1.2295e-02],\n",
       "           [-3.5521e-01,  6.0350e-01,  1.5412e+00,  ..., -1.3419e+00,\n",
       "            -8.8367e-01, -2.5779e-01],\n",
       "           [-3.4646e-01,  5.9249e-01,  2.8656e-01,  ...,  2.6376e-02,\n",
       "             2.4254e-01, -4.2536e-01],\n",
       "           [-3.3463e-02, -5.0482e-01,  9.0712e-01,  ..., -1.1892e+00,\n",
       "             1.0789e+00, -2.1662e-01],\n",
       "           [-8.3269e-02,  4.8490e-01,  4.2374e-03,  ..., -4.4220e-01,\n",
       "            -2.2406e-01, -2.6836e-01]]]])), (tensor([[[[-3.3578e-01,  8.6494e-01, -1.5782e-01,  ...,  1.1243e+00,\n",
       "            -1.7831e-01,  1.3638e-01],\n",
       "           [-2.3212e-01, -3.7103e+00,  1.5083e+00,  ..., -4.2631e+00,\n",
       "            -9.7429e-01,  1.2628e+00],\n",
       "           [-8.7726e-01, -3.9670e+00,  9.5781e-01,  ..., -3.8073e+00,\n",
       "             1.0488e+00,  8.3892e-01],\n",
       "           [-1.7048e-01, -5.6075e+00,  2.3238e+00,  ..., -6.5757e+00,\n",
       "            -5.0694e-01,  1.2394e+00],\n",
       "           [-3.2249e-01, -4.1583e+00,  4.0781e-01,  ..., -4.4795e+00,\n",
       "             6.5279e-01,  7.5854e-01]],\n",
       " \n",
       "          [[ 6.0723e-02,  8.6226e-01, -6.4320e-01,  ..., -4.2258e-02,\n",
       "             2.9290e-01,  8.5186e-03],\n",
       "           [ 1.0915e+00,  2.1069e-02,  7.5588e-02,  ...,  1.6181e-01,\n",
       "             4.1697e-02,  3.7497e-01],\n",
       "           [ 1.1304e+00,  4.0444e-01,  3.0444e-01,  ...,  7.2484e-01,\n",
       "             4.1252e-01, -6.1902e-01],\n",
       "           [-7.5880e-01,  6.1769e-01,  1.0397e+00,  ...,  1.3012e+00,\n",
       "             5.2258e-01, -6.5924e-01],\n",
       "           [ 1.0963e+00, -2.5779e-01,  9.0263e-01,  ...,  1.9957e+00,\n",
       "             1.0586e+00, -5.2579e-01]],\n",
       " \n",
       "          [[-3.1530e-01,  1.2470e-01, -9.8533e-01,  ..., -3.5174e-01,\n",
       "            -6.0202e-02, -1.3882e-01],\n",
       "           [-7.2556e-01, -6.7369e-01,  4.5135e+00,  ...,  9.3662e-01,\n",
       "             3.4733e-01,  4.4493e-01],\n",
       "           [ 1.8324e-02,  9.2619e-01,  3.0806e+00,  ..., -9.8755e-01,\n",
       "             5.9963e-01, -6.8951e-01],\n",
       "           [-3.1292e-01, -4.2186e-01,  4.5207e+00,  ...,  1.5953e+00,\n",
       "             2.4159e-01,  7.0006e-01],\n",
       "           [-2.7357e-01, -1.1352e-01,  3.6467e+00,  ..., -7.4206e-01,\n",
       "            -5.0280e-01, -4.2795e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.8411e-01,  8.0610e-02, -7.7487e-02,  ..., -3.1953e-02,\n",
       "             2.1622e-01,  1.0605e-02],\n",
       "           [-5.1169e-01, -6.1173e-01, -1.0611e+00,  ..., -1.7747e+00,\n",
       "             2.1943e-01, -3.2810e-01],\n",
       "           [-4.4645e-01, -7.4124e-01, -3.7724e+00,  ..., -2.1449e+00,\n",
       "            -1.1012e+00, -1.0423e+00],\n",
       "           [ 1.3785e-02, -8.3531e-01, -1.7432e-01,  ..., -1.3340e+00,\n",
       "            -5.1678e-02,  3.5860e-03],\n",
       "           [-7.6727e-01,  9.2055e-01, -1.2874e+00,  ..., -1.5878e+00,\n",
       "            -2.0718e-01,  1.1104e+00]],\n",
       " \n",
       "          [[ 2.0019e-01,  6.5883e-02,  3.2484e-01,  ...,  4.1552e-01,\n",
       "             1.3110e-02,  2.2381e-01],\n",
       "           [ 1.0629e+00,  8.3993e-01,  6.1248e-01,  ..., -1.8284e+00,\n",
       "            -4.4511e-01,  1.1643e+00],\n",
       "           [ 7.8798e-01, -2.9148e-01,  9.2428e-01,  ..., -9.9191e-01,\n",
       "            -2.1754e-01,  2.4879e-01],\n",
       "           [ 1.8184e+00,  9.2008e-01,  2.7761e-01,  ..., -1.1904e+00,\n",
       "            -1.8146e+00,  1.0771e+00],\n",
       "           [ 1.4717e+00,  9.0591e-01,  3.8335e-01,  ..., -1.0730e+00,\n",
       "            -1.0929e-01,  1.4620e+00]],\n",
       " \n",
       "          [[-3.0144e+00,  5.5559e-01,  5.5824e-01,  ..., -9.2879e-01,\n",
       "             3.1234e-01,  2.1565e-01],\n",
       "           [ 7.7353e+00, -1.7442e+00, -2.0879e+00,  ...,  1.2794e+00,\n",
       "            -9.0917e-01, -3.6397e-01],\n",
       "           [ 7.6938e+00, -1.3827e+00, -8.8995e-01,  ...,  2.8724e+00,\n",
       "            -1.0209e+00,  1.9366e-01],\n",
       "           [ 1.0140e+01, -2.1569e+00, -3.2449e+00,  ...,  3.4638e+00,\n",
       "             4.8914e-01, -6.7355e-01],\n",
       "           [ 9.7587e+00,  7.2058e-01, -1.3629e+00,  ...,  2.1456e+00,\n",
       "            -1.0528e+00, -7.1323e-01]]]]), tensor([[[[ 0.0511, -0.0439,  0.0104,  ..., -0.0707,  0.0040, -0.0878],\n",
       "           [-0.6925, -1.0542, -0.5742,  ..., -0.0472, -1.0413,  0.3355],\n",
       "           [-0.4940, -0.3420, -0.3367,  ...,  0.1863,  0.2760, -0.8595],\n",
       "           [-0.1199, -0.4606, -0.6362,  ...,  0.1921,  0.6242,  0.2705],\n",
       "           [-0.1924,  0.1064, -0.3049,  ..., -0.0948, -0.4272, -1.2937]],\n",
       " \n",
       "          [[ 0.0699,  0.0190, -0.0264,  ..., -0.0281,  0.0086, -0.0089],\n",
       "           [ 1.4371, -0.1864, -0.3611,  ..., -0.8254, -1.0759,  1.9052],\n",
       "           [ 0.5936,  0.8464, -0.1053,  ..., -0.3665, -1.8904,  0.7139],\n",
       "           [ 0.1267,  0.5145,  0.0538,  ..., -0.6784, -1.6538,  0.1597],\n",
       "           [ 0.9659, -0.1976, -1.3671,  ..., -0.1335, -1.3056,  0.6063]],\n",
       " \n",
       "          [[ 0.0782,  0.0124,  0.0039,  ...,  0.0251, -0.0705, -0.0617],\n",
       "           [-0.0911,  1.7792,  0.2072,  ..., -1.0666, -0.4472,  0.8503],\n",
       "           [-1.0804,  1.1983, -0.0320,  ..., -1.2570, -0.1324, -1.1971],\n",
       "           [-0.2841, -0.3006, -0.2575,  ..., -0.3545, -0.1416, -0.8115],\n",
       "           [-0.1985, -0.0786, -0.4044,  ..., -0.4134,  0.5922,  0.7443]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0047,  0.0254,  0.0173,  ..., -0.0733, -0.0199,  0.0139],\n",
       "           [-1.5127,  0.3684,  0.9665,  ...,  0.6067,  0.7405, -0.9814],\n",
       "           [-1.1236, -1.1006,  0.2612,  ...,  0.1182, -0.7372,  0.3911],\n",
       "           [-1.1242,  0.8199,  0.0735,  ..., -0.0069, -0.4597, -1.2443],\n",
       "           [-0.2069, -0.3188,  0.3948,  ...,  1.0414,  0.1535,  0.2349]],\n",
       " \n",
       "          [[ 0.0457, -0.0140,  0.0214,  ...,  0.0313, -0.0080,  0.0027],\n",
       "           [-0.6514,  0.0934, -0.0763,  ..., -0.9206, -0.5693, -1.1382],\n",
       "           [-1.6145,  1.6045, -1.6719,  ..., -0.9407, -0.9207, -0.0959],\n",
       "           [-0.1987,  1.0179, -0.2112,  ..., -0.0317, -0.6006,  0.0966],\n",
       "           [-2.0513,  0.8048, -0.0220,  ..., -0.0118, -0.0829, -0.8606]],\n",
       " \n",
       "          [[ 0.0727, -0.1984, -0.0725,  ..., -0.0317,  0.1917, -0.0472],\n",
       "           [-0.1412, -0.5086,  0.4468,  ..., -0.1006,  0.5895,  0.5338],\n",
       "           [-0.8033,  0.0502,  1.0292,  ...,  0.1372,  0.1652,  0.0709],\n",
       "           [-0.0650, -0.7569, -0.3314,  ..., -0.4759,  0.2435,  0.1295],\n",
       "           [-0.5154, -0.4137, -0.0533,  ..., -0.1783, -0.8395, -0.0536]]]])), (tensor([[[[ 1.0499e+00, -2.6094e-01, -1.4624e-01,  ...,  6.4066e-01,\n",
       "             7.3481e-01, -3.1200e-01],\n",
       "           [-5.7890e+00, -1.7413e+00,  2.9292e-01,  ...,  4.6389e-01,\n",
       "            -4.9524e+00,  9.1307e-01],\n",
       "           [-5.8786e+00, -2.8489e+00,  2.5024e-01,  ...,  6.3024e-01,\n",
       "            -5.6629e+00,  1.7572e-01],\n",
       "           [-7.5091e+00, -2.1926e+00,  3.7470e-01,  ..., -1.3713e+00,\n",
       "            -7.7538e+00, -6.2580e-01],\n",
       "           [-7.2634e+00, -4.0670e+00,  1.3098e+00,  ...,  9.2663e-01,\n",
       "            -4.0072e+00,  5.1120e-01]],\n",
       " \n",
       "          [[-1.4052e-01, -6.4056e-02,  1.6708e-01,  ..., -5.0385e-02,\n",
       "            -8.8839e-01, -1.9052e-01],\n",
       "           [-5.9415e-01,  7.4288e-01,  7.2057e-01,  ..., -1.9685e+00,\n",
       "             1.7725e-01,  1.0160e+00],\n",
       "           [-1.3339e+00, -6.5266e-02, -3.3884e-01,  ..., -5.9409e-01,\n",
       "            -3.9337e-01,  6.3114e-01],\n",
       "           [-3.2379e-01,  1.4244e+00, -4.2502e-01,  ..., -4.9243e-01,\n",
       "            -5.0526e-01,  1.6173e+00],\n",
       "           [ 4.7706e-01,  3.7960e-01, -4.7835e-01,  ..., -5.7608e-01,\n",
       "            -1.1128e+00,  1.3993e+00]],\n",
       " \n",
       "          [[ 1.9705e-01,  3.1511e-01,  1.1296e+00,  ..., -4.5656e-01,\n",
       "             4.3585e-01, -4.9803e-01],\n",
       "           [-8.8770e-01, -2.2029e+00, -4.9268e-01,  ..., -6.1851e-01,\n",
       "            -1.6877e+00,  1.9681e+00],\n",
       "           [-2.0773e+00, -9.3479e-01, -2.0899e+00,  ...,  2.6125e-01,\n",
       "            -8.6784e-01,  1.5641e+00],\n",
       "           [ 1.1151e+00, -1.6579e+00, -1.7340e+00,  ...,  1.5332e-02,\n",
       "            -1.6186e+00,  2.7873e+00],\n",
       "           [-1.9495e+00, -5.3528e-01, -1.8742e+00,  ..., -6.5109e-01,\n",
       "            -4.2540e-01,  1.7431e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.5123e-01,  7.1820e-02, -2.2811e-01,  ...,  4.1858e-04,\n",
       "             1.5596e-01,  2.9428e-02],\n",
       "           [-2.2146e+00,  2.9070e-01,  3.3711e-01,  ...,  2.0434e+00,\n",
       "             4.4936e-01,  4.3313e-01],\n",
       "           [-1.0946e+00,  1.1820e+00,  2.1303e-01,  ...,  2.2552e+00,\n",
       "            -1.9131e-01, -2.0022e-01],\n",
       "           [-3.0461e+00, -2.0195e-01,  1.4801e+00,  ...,  9.8783e-01,\n",
       "             5.1547e-01, -8.5144e-01],\n",
       "           [-2.1700e+00,  7.6478e-01, -3.9063e-01,  ...,  1.8350e+00,\n",
       "            -7.3088e-01, -3.2727e-02]],\n",
       " \n",
       "          [[-3.5156e-01, -2.1933e+00,  1.1372e-01,  ..., -8.6831e-02,\n",
       "            -4.2204e-02,  9.1871e-01],\n",
       "           [ 1.9498e+00,  1.4381e+00,  1.9286e-01,  ...,  2.8746e-01,\n",
       "            -1.0219e+00,  1.2979e+00],\n",
       "           [-5.9086e-01,  3.6022e+00, -1.0309e+00,  ...,  8.5210e-01,\n",
       "            -3.0698e-01,  7.0992e-01],\n",
       "           [ 1.0901e+00,  3.4021e+00, -4.2079e-01,  ...,  8.1269e-01,\n",
       "            -1.3765e+00,  1.0311e+00],\n",
       "           [-3.0364e-01,  3.1792e+00, -1.6522e+00,  ...,  1.6933e+00,\n",
       "            -5.7283e-01,  1.9118e+00]],\n",
       " \n",
       "          [[ 3.6793e-01,  7.5982e-02, -1.3786e-01,  ...,  6.4646e-01,\n",
       "             1.3555e-01,  2.5748e-01],\n",
       "           [ 1.0689e-01, -6.4250e-01, -9.4887e-01,  ..., -6.2919e-01,\n",
       "             8.9190e-01, -9.7596e-01],\n",
       "           [-5.0077e-01,  2.1461e-01, -9.0097e-01,  ..., -8.3265e-01,\n",
       "             1.0279e+00, -1.3733e+00],\n",
       "           [-9.3137e-01,  3.0899e-01, -8.6246e-01,  ..., -2.5067e+00,\n",
       "             1.0355e-01,  6.2560e-01],\n",
       "           [-8.0052e-01,  4.1125e-01, -2.8654e-01,  ..., -1.0493e+00,\n",
       "             1.0434e-01,  2.1948e-01]]]]), tensor([[[[-3.6090e-02,  5.8404e-02, -4.7430e-02,  ..., -1.6448e-02,\n",
       "             6.5290e-03,  2.0813e-02],\n",
       "           [ 2.7891e-01,  2.9188e-01, -4.8968e-01,  ...,  4.0035e-01,\n",
       "            -3.2764e-01,  5.3072e-01],\n",
       "           [ 5.3293e-01,  3.1930e-01,  2.3404e-01,  ...,  1.0329e+00,\n",
       "             5.4787e-01, -8.5597e-02],\n",
       "           [-8.5239e-02, -5.3411e-01, -6.7868e-01,  ...,  4.0462e-01,\n",
       "            -1.4926e-01,  3.0082e-01],\n",
       "           [ 6.0465e-01, -2.1018e-01,  3.9040e-01,  ...,  9.2761e-02,\n",
       "             1.3624e-01, -6.5853e-01]],\n",
       " \n",
       "          [[ 1.0002e-02, -2.6317e-02,  2.8788e-02,  ...,  2.0878e-02,\n",
       "            -5.0190e-02,  1.7778e-02],\n",
       "           [-4.7705e-01,  9.3587e-02, -9.5067e-01,  ..., -1.0128e+00,\n",
       "             3.3266e-01,  2.0978e-01],\n",
       "           [-2.6931e-01,  1.0265e+00, -2.1987e+00,  ...,  4.4124e-01,\n",
       "             1.2656e+00, -7.0135e-01],\n",
       "           [ 6.3717e-01, -4.1253e-01, -5.4030e-01,  ..., -3.4801e-01,\n",
       "             6.4111e-01, -1.5174e+00],\n",
       "           [-2.3127e-01, -6.8341e-02, -1.7399e+00,  ..., -4.5175e-02,\n",
       "             1.7737e+00, -6.7914e-01]],\n",
       " \n",
       "          [[ 2.8050e-02, -3.8394e-02,  4.2667e-02,  ...,  1.8323e-02,\n",
       "            -7.2851e-03,  6.6779e-03],\n",
       "           [-1.0695e+00, -8.5129e-01,  1.6559e-01,  ..., -9.1547e-01,\n",
       "             5.1709e-01, -7.1973e-01],\n",
       "           [-1.4520e-01,  4.0050e-01, -2.6026e-01,  ...,  4.5429e-01,\n",
       "            -7.5866e-03,  6.2628e-01],\n",
       "           [-8.0367e-01, -7.1469e-02,  1.6038e+00,  ...,  1.0355e+00,\n",
       "             1.4764e+00,  2.2627e+00],\n",
       "           [-6.7027e-01,  2.2001e+00, -8.6234e-02,  ..., -9.7923e-01,\n",
       "             5.7563e-01, -5.3153e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.8594e-01,  9.0682e-02,  4.9690e-02,  ...,  4.3440e-02,\n",
       "             3.8206e-02, -1.2885e-01],\n",
       "           [-4.3551e-01,  3.0158e-01,  3.1460e-01,  ...,  3.6899e-01,\n",
       "            -1.2331e+00, -4.3834e-01],\n",
       "           [ 7.4305e-01,  1.8296e-01,  2.5812e-01,  ...,  4.1448e-01,\n",
       "            -1.6152e+00, -1.4927e+00],\n",
       "           [-1.1039e+00, -9.9151e-01,  7.7860e-01,  ...,  1.4602e+00,\n",
       "             2.2643e-01, -5.2519e-01],\n",
       "           [ 3.0363e-01, -3.6477e-01,  4.5000e-01,  ..., -3.7565e-01,\n",
       "             4.7561e-01, -1.1268e+00]],\n",
       " \n",
       "          [[-5.9095e-01, -5.1092e-03,  4.9711e-02,  ..., -6.8233e-03,\n",
       "             1.0263e-02, -1.0583e-03],\n",
       "           [-2.2687e+00,  4.7976e-01, -1.3320e+00,  ..., -1.1163e+00,\n",
       "            -5.5156e-01, -8.5924e-01],\n",
       "           [-1.5324e+00,  6.6089e-01,  3.6770e-01,  ...,  2.7258e-01,\n",
       "            -1.1643e+00,  1.6755e-01],\n",
       "           [-1.3159e+00,  1.2460e+00, -1.0396e+00,  ...,  5.1382e-01,\n",
       "            -1.9117e-02, -1.2854e+00],\n",
       "           [-1.9412e+00,  4.0452e-02, -4.7895e-01,  ..., -2.9557e-01,\n",
       "             1.5068e-01,  7.6320e-01]],\n",
       " \n",
       "          [[ 4.1802e-03,  8.6289e-02, -4.7156e-02,  ...,  6.4784e-02,\n",
       "             3.7624e-02, -3.6941e-02],\n",
       "           [-1.4381e-01,  6.6147e-02,  7.1365e-01,  ..., -1.0479e+00,\n",
       "            -1.9087e+00,  8.5137e-02],\n",
       "           [ 4.0390e-02, -5.2821e-01,  3.0273e-02,  ..., -9.1636e-01,\n",
       "            -1.8137e+00, -4.0669e-01],\n",
       "           [-6.0107e-01,  8.0179e-01, -5.1953e-01,  ...,  5.6110e-01,\n",
       "            -2.3746e+00,  1.4864e+00],\n",
       "           [ 3.0775e-01, -2.7929e-02, -2.7402e-02,  ..., -1.1215e+00,\n",
       "            -1.0955e+00,  7.0848e-01]]]])), (tensor([[[[-0.0268, -2.3484,  0.1738,  ..., -0.2339, -0.1850,  0.0804],\n",
       "           [ 0.1388,  4.5815, -0.9669,  ..., -0.6112, -0.5326,  0.5400],\n",
       "           [-1.5145,  5.2745,  0.7600,  ..., -0.7025, -0.9820,  0.6823],\n",
       "           [-2.4722,  6.8715, -0.7147,  ..., -0.7563, -0.5254, -0.3900],\n",
       "           [-0.7793,  5.1099,  0.5638,  ..., -0.0628, -0.7492, -0.6073]],\n",
       " \n",
       "          [[-0.8116,  0.2276,  0.4685,  ..., -0.5214,  1.0647,  1.1201],\n",
       "           [ 0.9995, -0.0315, -0.5146,  ..., -0.1559,  2.0375, -1.7316],\n",
       "           [ 1.3905,  0.0454, -1.3493,  ..., -0.2864,  1.8571, -0.7349],\n",
       "           [ 0.7958,  0.8768,  0.1708,  ..., -0.4971,  2.6703, -0.6747],\n",
       "           [-0.0119,  0.7373, -0.3107,  ..., -0.8354,  2.3294, -0.6138]],\n",
       " \n",
       "          [[-0.8658,  0.4789,  0.0214,  ...,  0.4886, -0.2292,  1.1553],\n",
       "           [ 0.9647,  0.1613,  0.7401,  ...,  0.6823,  0.6432,  0.0383],\n",
       "           [ 2.0381,  0.9360,  0.7828,  ...,  0.3342,  0.4996,  0.6505],\n",
       "           [ 1.9495, -0.3483,  2.0074,  ...,  1.9670,  1.4174,  0.4167],\n",
       "           [ 0.8040,  0.3371,  1.0913,  ..., -0.0123,  0.9733, -0.4697]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.3004, -0.1312,  0.1413,  ...,  0.1929,  1.7425, -2.8649],\n",
       "           [-0.9606, -0.7099, -1.3032,  ..., -1.0593, -4.8865,  4.1858],\n",
       "           [-0.8862, -0.9787,  0.1423,  ..., -1.1325, -5.5776,  4.2337],\n",
       "           [-1.0878, -0.9956,  0.1673,  ..., -0.4866, -6.5000,  7.0008],\n",
       "           [-0.6206, -0.5047,  0.0824,  ..., -1.0671, -5.1885,  4.9431]],\n",
       " \n",
       "          [[ 0.1853,  0.3700,  0.2141,  ..., -0.2157,  0.0307, -0.1397],\n",
       "           [-0.3522, -2.2983,  0.4630,  ..., -0.2753,  0.8290,  1.8693],\n",
       "           [-1.3253, -1.3627,  0.1328,  ..., -0.3211, -0.3284,  2.5235],\n",
       "           [-0.9152, -2.3291, -0.2241,  ..., -0.5528, -0.1633,  1.3084],\n",
       "           [-0.9402, -1.0928,  0.2344,  ...,  0.1224, -0.2422,  2.2953]],\n",
       " \n",
       "          [[ 0.3703,  0.1178,  0.6143,  ...,  0.5201,  0.5804, -0.3314],\n",
       "           [-0.1534,  1.3555, -0.6274,  ..., -2.5394, -3.4800,  1.0391],\n",
       "           [-1.4422,  0.1856,  0.2544,  ..., -0.6511, -4.9898,  0.5849],\n",
       "           [-0.3204, -0.1365, -1.1324,  ..., -2.8917, -7.1562,  0.3930],\n",
       "           [ 0.9679,  0.7910, -0.3623,  ..., -1.5680, -4.9041,  0.5486]]]]), tensor([[[[ 6.5136e-02, -1.0029e-02, -2.2108e-02,  ...,  1.1689e-01,\n",
       "            -7.1039e-02, -3.8524e-02],\n",
       "           [-1.1994e+00,  3.9710e-01,  9.0775e-01,  ..., -7.8855e-02,\n",
       "            -8.2943e-01,  8.4599e-01],\n",
       "           [-1.0016e+00, -5.1266e-01,  3.2316e-01,  ..., -6.2812e-02,\n",
       "             4.1123e-02,  6.9242e-01],\n",
       "           [-9.8786e-01,  1.5539e+00, -1.0792e+00,  ...,  9.1389e-01,\n",
       "            -1.3046e+00,  7.3147e-01],\n",
       "           [-6.3518e-01, -4.9315e-02,  2.1492e-01,  ...,  2.1781e-01,\n",
       "             3.7708e-01,  1.2175e-01]],\n",
       " \n",
       "          [[ 1.1602e-02,  2.9395e-02,  5.1380e-02,  ..., -4.0431e-04,\n",
       "             5.4506e-03, -5.0795e-03],\n",
       "           [-1.3015e+00,  5.9549e-01, -2.3893e-01,  ..., -4.3059e-01,\n",
       "            -5.1986e-01, -1.2385e+00],\n",
       "           [ 1.2336e-01, -1.7101e-01, -1.1125e-01,  ...,  1.7730e-01,\n",
       "             5.4245e-01, -1.2927e+00],\n",
       "           [-2.1743e+00, -2.1881e+00,  6.4877e-01,  ...,  1.0233e+00,\n",
       "             1.4118e-01, -1.2912e+00],\n",
       "           [-1.5066e+00, -6.6605e-01,  1.1712e-04,  ..., -1.9601e+00,\n",
       "            -5.8780e-01, -9.8956e-01]],\n",
       " \n",
       "          [[ 5.2304e-02, -3.7324e-02,  6.3114e-02,  ...,  5.8532e-02,\n",
       "            -6.3338e-02, -5.8268e-02],\n",
       "           [-5.3880e-01,  2.6904e-01, -4.1903e-01,  ...,  7.2808e-01,\n",
       "             5.3161e-01, -6.4746e-02],\n",
       "           [-7.0182e-01,  2.3740e-01, -2.0365e-01,  ..., -1.1819e+00,\n",
       "             9.4918e-01,  5.4753e-01],\n",
       "           [-8.4305e-01,  1.7818e+00,  3.9558e-02,  ..., -2.9359e-01,\n",
       "            -1.0073e-01,  8.9636e-01],\n",
       "           [-8.3215e-01, -5.8910e-02, -4.3805e-01,  ...,  3.9287e-01,\n",
       "             9.4259e-01,  8.0323e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.0498e-02, -4.4621e-02,  4.2299e-02,  ..., -9.2541e-02,\n",
       "             3.0748e-02,  1.1883e-02],\n",
       "           [ 7.9608e-01, -3.5990e-01,  2.7253e-01,  ...,  1.1563e+00,\n",
       "             4.0975e-01,  1.0109e+00],\n",
       "           [-6.3194e-01,  6.0815e-01,  7.3890e-02,  ..., -6.3997e-01,\n",
       "             7.4333e-01,  7.9898e-01],\n",
       "           [ 3.6420e-01,  6.9468e-01, -1.0829e+00,  ...,  7.3823e-01,\n",
       "             9.8405e-01,  6.0738e-01],\n",
       "           [-7.1289e-01, -1.8521e-01,  1.0992e+00,  ...,  4.0916e-01,\n",
       "             7.9474e-01,  8.0095e-01]],\n",
       " \n",
       "          [[ 1.4738e-01, -6.2497e-02,  1.3729e-01,  ...,  6.0634e-02,\n",
       "             3.2148e-02, -1.2945e-01],\n",
       "           [ 8.0080e-01,  4.8899e-01,  3.4387e-01,  ...,  2.1468e+00,\n",
       "             6.7483e-01,  9.9821e-01],\n",
       "           [ 4.4923e-01,  1.0000e-01,  9.6035e-02,  ...,  2.9190e-01,\n",
       "             5.2111e-01,  1.0018e-01],\n",
       "           [-1.8894e-01,  1.7195e+00, -2.8543e-01,  ...,  1.0602e+00,\n",
       "            -1.4900e-01,  2.4676e-01],\n",
       "           [ 9.9243e-01,  6.4225e-01,  2.1845e-01,  ...,  1.5559e+00,\n",
       "             6.5644e-01, -5.8910e-01]],\n",
       " \n",
       "          [[ 2.0906e-01, -4.6573e-02, -6.0253e-02,  ...,  3.5716e-02,\n",
       "             4.1975e-02,  2.2183e-02],\n",
       "           [ 4.2789e-01, -1.0359e+00, -1.0022e+00,  ...,  7.6253e-01,\n",
       "            -3.8272e-01, -3.3447e-01],\n",
       "           [ 7.4903e-01, -4.6310e-03,  1.3703e+00,  ...,  1.1612e-01,\n",
       "            -9.9810e-01,  2.0541e-01],\n",
       "           [ 3.1292e+00,  8.2206e-01, -1.3466e-01,  ..., -5.1920e-01,\n",
       "             1.4128e-01,  1.1392e+00],\n",
       "           [ 4.7068e-02, -4.9496e-01,  4.2699e-01,  ...,  5.6061e-01,\n",
       "            -5.3792e-01,  2.4845e-01]]]])), (tensor([[[[ 2.5910e-02, -2.6886e-01, -4.6291e-01,  ...,  2.9839e-01,\n",
       "             3.2603e-01,  3.5748e-01],\n",
       "           [ 7.4043e-02,  4.5789e-02, -1.4928e+00,  ..., -1.3178e-01,\n",
       "            -1.3072e+00, -9.8141e-01],\n",
       "           [ 1.1960e+00,  1.3387e-02, -6.9468e-01,  ..., -1.0085e-01,\n",
       "            -1.6388e-01,  3.8162e-01],\n",
       "           [ 1.6722e+00, -1.7714e+00,  7.0345e-04,  ..., -3.8169e-02,\n",
       "            -5.5099e-01,  1.7823e+00],\n",
       "           [ 1.2425e-01, -7.9417e-01, -5.1729e-01,  ...,  5.3012e-01,\n",
       "            -1.1320e+00,  3.7656e-01]],\n",
       " \n",
       "          [[-2.8813e-01,  1.6128e-01,  1.1108e-01,  ...,  5.3097e-02,\n",
       "            -1.1501e+00, -1.5568e-01],\n",
       "           [ 1.5934e+00,  3.4091e-01, -1.5022e+00,  ..., -7.5628e-01,\n",
       "            -6.1376e-01, -3.0825e-01],\n",
       "           [ 1.1957e-01,  7.5987e-01, -9.6103e-01,  ..., -5.0441e-01,\n",
       "            -1.6894e-01, -9.4202e-01],\n",
       "           [-2.0233e+00,  9.0359e-01, -2.2660e+00,  ...,  2.0552e+00,\n",
       "             8.3635e-01,  2.0012e+00],\n",
       "           [ 1.6388e-02,  2.8470e-01, -9.3453e-01,  ..., -1.0277e+00,\n",
       "             1.6010e-01,  1.2759e-01]],\n",
       " \n",
       "          [[-1.2375e+00, -1.2080e-01,  5.5275e-01,  ..., -6.6115e-01,\n",
       "             4.6177e-01, -2.7181e-01],\n",
       "           [ 7.2443e-01,  7.5674e-01, -5.6928e-01,  ...,  1.9894e+00,\n",
       "             2.4628e-01, -2.7563e-01],\n",
       "           [ 1.2451e+00, -7.9849e-01, -1.3928e-01,  ...,  1.6119e+00,\n",
       "            -8.3982e-01,  6.1884e-01],\n",
       "           [ 2.7141e+00,  2.6189e+00,  1.6056e-01,  ...,  7.8623e-01,\n",
       "            -7.8107e-01,  3.4331e-01],\n",
       "           [ 7.7462e-01,  7.4434e-01,  3.0196e-01,  ...,  2.2859e+00,\n",
       "             5.4384e-01, -1.9451e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.9977e-01, -9.0907e-01, -3.9427e-01,  ..., -1.0356e+00,\n",
       "            -4.3145e-01,  4.9180e-01],\n",
       "           [ 2.1122e+00,  6.0559e-01, -1.4014e+00,  ...,  1.0709e+00,\n",
       "            -2.2777e-01, -1.9090e+00],\n",
       "           [ 1.5736e+00, -1.0441e+00,  2.0001e-01,  ...,  3.2477e+00,\n",
       "            -6.6794e-02, -1.5784e+00],\n",
       "           [ 1.0402e+00, -6.7949e-01, -1.6430e+00,  ...,  1.1360e+00,\n",
       "            -9.9863e-02, -1.1458e+00],\n",
       "           [ 1.5760e+00, -1.4567e-01, -4.7452e-01,  ...,  2.6055e+00,\n",
       "             1.0400e+00, -1.0608e+00]],\n",
       " \n",
       "          [[-8.9759e-01,  2.5559e+00,  3.0324e-01,  ...,  3.4015e-01,\n",
       "             1.9589e+00, -5.4084e-01],\n",
       "           [ 1.3040e-01, -1.6887e+00, -3.1883e-01,  ..., -7.2578e-01,\n",
       "            -3.4075e+00,  6.1481e-01],\n",
       "           [ 8.9065e-01, -2.3784e+00, -1.6161e+00,  ..., -5.0397e-01,\n",
       "            -4.7393e+00,  6.0094e-01],\n",
       "           [ 8.6485e-01, -4.0273e+00,  9.8973e-01,  ..., -4.8867e-01,\n",
       "            -7.0723e+00,  2.7741e-01],\n",
       "           [-6.3641e-01, -4.1652e+00, -4.6412e-01,  ..., -4.3096e-01,\n",
       "            -4.8379e+00,  8.6569e-01]],\n",
       " \n",
       "          [[-2.0290e+00, -3.6629e-01, -1.1161e+00,  ..., -4.0021e-01,\n",
       "             6.4893e-02,  2.4993e-01],\n",
       "           [ 1.7145e+00,  1.8454e+00,  8.6611e-01,  ...,  3.1520e-01,\n",
       "            -6.6109e-01,  1.1091e-01],\n",
       "           [ 3.1734e+00, -1.6789e-01,  5.2767e-01,  ...,  5.9542e-01,\n",
       "             1.7386e-01,  1.1351e+00],\n",
       "           [ 3.3293e+00,  5.7241e-01,  4.3524e+00,  ...,  4.3583e-01,\n",
       "             1.4642e+00, -4.5446e-01],\n",
       "           [ 1.9903e+00,  3.1996e-01,  1.7639e+00,  ...,  3.2953e-01,\n",
       "             1.9708e-01,  5.0455e-01]]]]), tensor([[[[-4.9252e-02, -8.7662e-02,  1.9245e-02,  ...,  1.1583e-01,\n",
       "            -2.2480e-02,  2.4090e-02],\n",
       "           [ 1.0258e+00, -1.0015e+00, -4.6918e-01,  ...,  6.9411e-01,\n",
       "             3.7130e-01, -8.3191e-01],\n",
       "           [ 8.2010e-01,  7.8641e-02, -7.8992e-02,  ...,  7.2212e-01,\n",
       "            -1.8455e-01, -1.3202e-01],\n",
       "           [ 8.0512e-01,  2.8068e-02,  7.0142e-02,  ..., -9.5686e-01,\n",
       "            -7.5492e-02, -6.5858e-01],\n",
       "           [-3.1248e-02,  1.3693e-01,  1.0664e+00,  ...,  4.2347e-01,\n",
       "             9.6525e-03,  5.8914e-01]],\n",
       " \n",
       "          [[ 1.7039e-02,  1.7426e-02, -3.8615e-02,  ...,  3.8622e-02,\n",
       "             1.0783e-02,  3.5067e-02],\n",
       "           [ 5.4532e-01,  1.1140e+00, -1.2954e+00,  ..., -6.1934e-01,\n",
       "            -4.1965e-01,  1.3734e-01],\n",
       "           [ 7.0438e-01,  1.6406e-01, -1.6855e-01,  ...,  8.8859e-01,\n",
       "            -8.1334e-01,  1.5645e-01],\n",
       "           [-5.7052e-01, -5.6448e-01,  9.0948e-01,  ..., -1.2677e+00,\n",
       "             3.2639e+00,  1.9290e-01],\n",
       "           [-2.2824e-01, -1.0144e+00, -6.0918e-01,  ...,  1.2182e+00,\n",
       "            -3.7317e-01,  5.3078e-02]],\n",
       " \n",
       "          [[ 3.8827e-02,  3.3008e-02, -8.3370e-02,  ...,  2.5783e-03,\n",
       "            -1.6268e-02,  9.1887e-04],\n",
       "           [ 1.2031e+00,  1.5186e+00,  1.3688e+00,  ...,  1.0105e+00,\n",
       "            -8.7194e-01,  1.0273e+00],\n",
       "           [ 7.2928e-01, -1.3360e-01,  7.5243e-01,  ..., -8.0170e-03,\n",
       "            -6.6694e-01,  4.9840e-01],\n",
       "           [ 1.8962e-01,  8.2924e-01, -1.1443e+00,  ...,  2.3796e-01,\n",
       "            -9.6447e-01,  9.4074e-01],\n",
       "           [ 6.0477e-01,  1.3706e-01,  6.2097e-01,  ...,  1.9329e-01,\n",
       "            -7.6489e-01,  2.7889e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.6492e-02,  2.4856e-02, -1.0858e-02,  ..., -1.9138e-02,\n",
       "            -1.6549e-02,  2.3261e-02],\n",
       "           [ 2.5711e-01, -3.6527e-01, -6.9447e-01,  ...,  5.6083e-01,\n",
       "            -1.6145e+00, -5.8163e-01],\n",
       "           [-3.5065e-01,  3.8092e-01, -2.2951e-01,  ...,  1.7585e-01,\n",
       "             3.9108e-02,  5.3813e-01],\n",
       "           [-1.5116e+00,  1.9764e-01, -8.2281e-01,  ..., -3.3763e-01,\n",
       "             3.7458e-01, -5.5708e-01],\n",
       "           [ 2.5058e-01,  9.1728e-01, -2.4921e-01,  ...,  6.8231e-01,\n",
       "             5.1315e-02,  3.5520e-01]],\n",
       " \n",
       "          [[-6.4021e-02, -3.2721e-02,  2.4496e-02,  ...,  2.8996e-03,\n",
       "            -5.4889e-02, -1.0845e-01],\n",
       "           [-2.9774e-02,  1.6665e+00,  1.5670e-01,  ..., -4.6556e-01,\n",
       "             8.5905e-01, -2.2211e-01],\n",
       "           [ 5.6742e-01,  3.6654e-01,  5.4637e-01,  ..., -5.9347e-01,\n",
       "             9.3978e-01, -9.5003e-02],\n",
       "           [-1.0586e+00,  1.0596e+00, -1.0187e+00,  ..., -9.2707e-01,\n",
       "             1.4436e-01, -4.3325e-01],\n",
       "           [ 4.9225e-02,  1.1783e+00, -4.4303e-01,  ..., -4.5238e-01,\n",
       "             6.2023e-01, -9.1208e-01]],\n",
       " \n",
       "          [[-3.9009e-04,  4.5721e-02, -4.4665e-02,  ..., -1.7350e-02,\n",
       "             1.0824e-02,  2.1425e-03],\n",
       "           [ 5.8817e-01, -2.8529e-01,  1.0152e+00,  ...,  2.8608e-01,\n",
       "             1.1777e+00, -5.9500e-01],\n",
       "           [-1.6830e-01, -9.4220e-01,  4.8764e-01,  ...,  7.1909e-01,\n",
       "            -1.7766e-01, -6.0373e-01],\n",
       "           [-1.9361e-01, -6.3465e-01,  1.6443e-01,  ..., -1.3457e+00,\n",
       "            -1.2609e+00,  2.4262e+00],\n",
       "           [ 7.2775e-02, -4.3437e-01, -1.0324e-01,  ...,  2.2475e-01,\n",
       "            -7.5352e-02,  2.6049e-02]]]])), (tensor([[[[-0.5113,  0.4863, -0.8478,  ..., -1.0067, -1.3222,  0.2112],\n",
       "           [ 0.2581,  0.6252,  0.5610,  ...,  2.4833, -1.4922,  0.3342],\n",
       "           [ 1.8726,  1.0948,  2.6647,  ...,  3.3223,  0.0445, -0.5175],\n",
       "           [ 0.7709,  1.5895, -0.0701,  ...,  4.9906, -0.8865,  1.0899],\n",
       "           [ 0.8210,  0.1654,  1.8759,  ...,  3.5902,  0.1105, -0.8073]],\n",
       " \n",
       "          [[ 0.8578, -2.0592,  0.1552,  ...,  0.2365, -2.4501, -0.4252],\n",
       "           [ 1.1039,  0.5796,  0.8606,  ...,  0.9534, -1.5875, -1.4158],\n",
       "           [ 1.6026,  1.8279,  0.0073,  ...,  0.7679,  1.8171,  1.3790],\n",
       "           [ 3.5731,  4.1471,  1.1229,  ...,  2.2445,  1.2283, -0.5172],\n",
       "           [ 1.7514,  1.6552, -1.0006,  ...,  0.4482,  1.9001,  0.2327]],\n",
       " \n",
       "          [[ 1.0126,  0.3729, -0.1703,  ..., -0.8086, -1.4068, -0.3650],\n",
       "           [-0.5880, -0.9481,  0.4509,  ...,  1.3936, -1.2569, -0.1012],\n",
       "           [-0.4279, -0.8228, -0.3292,  ...,  1.7836, -1.0293, -0.4596],\n",
       "           [-1.7680,  0.3175, -0.9727,  ...,  3.1105, -2.3557,  1.0674],\n",
       "           [-0.4376, -0.3146,  0.4497,  ...,  0.7542, -1.3190,  0.1282]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.2134, -0.5814,  0.4874,  ..., -0.6810,  1.0950,  0.3049],\n",
       "           [-0.7196,  0.3125, -2.2091,  ..., -2.0303, -1.5128,  0.6353],\n",
       "           [-0.7869,  1.1606, -0.8255,  ..., -3.2361,  0.9948,  0.0275],\n",
       "           [-4.9323,  1.7960, -5.8187,  ..., -4.7557, -3.5053,  1.7454],\n",
       "           [-1.6429,  1.1854, -2.0281,  ..., -3.0455, -0.3600,  0.7217]],\n",
       " \n",
       "          [[ 0.2561,  0.5523,  0.5580,  ...,  0.7246,  0.0652,  0.8349],\n",
       "           [-2.4196, -0.7495,  1.4411,  ...,  0.5911,  0.3374,  1.6350],\n",
       "           [-0.0110,  0.6024,  2.3124,  ...,  0.3561,  0.0298, -0.1170],\n",
       "           [-1.3876, -0.6927,  1.9869,  ..., -0.9599,  2.1948,  2.7845],\n",
       "           [-0.2288,  1.5565,  1.3083,  ...,  0.1106, -0.5638, -0.3715]],\n",
       " \n",
       "          [[-0.7296,  0.3057, -1.5837,  ..., -0.3948,  0.2267, -1.3335],\n",
       "           [-0.5836,  0.2318, -1.1066,  ...,  1.5463,  0.3724, -0.2810],\n",
       "           [-0.8453,  1.1365, -1.3294,  ...,  0.9761,  1.6909, -0.0406],\n",
       "           [ 0.6128,  0.8691, -0.3700,  ..., -0.0632,  0.0833,  1.8709],\n",
       "           [-1.1919,  0.3742, -1.4556,  ...,  1.2541,  1.9624, -1.1741]]]]), tensor([[[[-3.1460e-03,  4.0217e-02, -7.3887e-02,  ...,  5.2969e-02,\n",
       "            -2.6784e-02, -8.3422e-02],\n",
       "           [ 2.5757e-01,  7.7405e-01, -1.4784e+00,  ..., -6.6112e-01,\n",
       "             6.0834e-01,  6.9106e-01],\n",
       "           [ 8.8324e-01, -6.1188e-02, -1.1025e-01,  ...,  3.4728e-01,\n",
       "             5.9921e-01, -2.4194e-01],\n",
       "           [-2.1266e-01, -5.3103e-01,  7.4972e-01,  ...,  1.8405e+00,\n",
       "             8.5996e-01, -1.2754e+00],\n",
       "           [ 1.6104e-01, -1.1620e-01,  3.1792e-01,  ...,  5.3705e-01,\n",
       "             1.5009e+00,  3.0144e-02]],\n",
       " \n",
       "          [[ 4.5011e-02,  1.3549e-02,  2.6805e-02,  ..., -3.5686e-02,\n",
       "            -3.5387e-02, -4.4578e-03],\n",
       "           [ 3.1826e-01, -6.7191e-01, -1.6448e+00,  ...,  1.2436e-01,\n",
       "            -3.7368e-01,  1.4734e+00],\n",
       "           [ 5.1103e-02,  8.6705e-01, -5.2601e-01,  ..., -6.6340e-02,\n",
       "            -1.7356e-01,  5.3770e-01],\n",
       "           [-7.2806e-01,  6.2756e-01,  5.1120e-01,  ..., -7.8485e-01,\n",
       "             1.2289e+00,  3.7648e-01],\n",
       "           [ 1.3023e+00,  1.4293e-01, -6.4567e-01,  ..., -2.4414e-01,\n",
       "             9.7247e-02, -1.3578e-01]],\n",
       " \n",
       "          [[ 3.8630e-03,  2.0467e-02, -4.0017e-02,  ..., -1.7781e-03,\n",
       "             3.0812e-02,  5.9422e-02],\n",
       "           [ 9.3086e-01, -3.9403e-01,  6.3453e-01,  ..., -2.5685e-01,\n",
       "            -4.8803e-01,  4.6024e-02],\n",
       "           [ 4.1776e-01,  1.4501e+00,  1.0571e+00,  ...,  8.7926e-01,\n",
       "            -1.9327e-01,  4.1687e-01],\n",
       "           [-9.5880e-01,  4.5641e-01, -7.7537e-01,  ..., -1.4300e+00,\n",
       "            -2.0507e+00, -5.7583e-01],\n",
       "           [ 8.7750e-01,  9.6495e-01, -4.3077e-01,  ...,  1.0531e+00,\n",
       "             9.3789e-01, -1.0087e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.9160e-02,  4.4159e-02, -7.4542e-03,  ..., -4.1528e-02,\n",
       "            -1.3703e-02,  1.0209e-02],\n",
       "           [-6.9417e-02, -1.5217e+00,  4.8709e-01,  ...,  9.1383e-01,\n",
       "            -1.1732e+00,  9.4306e-01],\n",
       "           [ 4.3443e-01, -1.0415e+00,  6.6440e-01,  ...,  6.6708e-01,\n",
       "            -1.6750e+00,  1.5627e-01],\n",
       "           [-3.7663e-01,  6.9184e-01,  5.7008e-01,  ...,  7.3964e-01,\n",
       "            -1.1131e+00,  7.1802e-02],\n",
       "           [-1.8068e-01, -9.0069e-01,  3.3957e-01,  ...,  9.7732e-01,\n",
       "            -4.1812e-01, -7.5843e-01]],\n",
       " \n",
       "          [[ 7.4462e-02,  1.1415e-02,  6.6753e-02,  ...,  2.6585e-02,\n",
       "             5.9258e-02,  2.8430e-02],\n",
       "           [ 7.5139e-01, -1.1638e+00,  1.2286e+00,  ..., -6.4202e-01,\n",
       "             6.4338e-01,  8.7599e-01],\n",
       "           [ 1.0492e+00,  2.6643e-01,  1.6625e+00,  ...,  7.3445e-03,\n",
       "             1.0506e+00, -1.4770e+00],\n",
       "           [ 1.0945e+00,  7.0871e-01, -2.0941e+00,  ..., -1.0365e-01,\n",
       "            -1.5706e+00,  1.0905e-01],\n",
       "           [ 5.4091e-01,  2.3460e-01,  1.8358e+00,  ..., -9.0164e-01,\n",
       "             1.4026e+00, -1.3295e+00]],\n",
       " \n",
       "          [[-1.0551e-01,  3.7056e-02, -5.2910e-02,  ..., -8.2814e-02,\n",
       "             8.1320e-02, -1.1580e-02],\n",
       "           [-8.5048e-01, -1.0459e+00,  1.3366e+00,  ..., -1.1279e+00,\n",
       "             1.4376e+00, -1.2916e+00],\n",
       "           [ 6.9728e-01, -7.1541e-01, -2.1802e-01,  ...,  2.8351e-01,\n",
       "             5.0765e-02, -9.1491e-01],\n",
       "           [-3.3737e-01,  6.6677e-02, -4.1648e-01,  ..., -1.1609e+00,\n",
       "             2.1420e+00,  1.1502e-01],\n",
       "           [-1.4345e-01, -8.9809e-01,  1.1049e+00,  ..., -4.5156e-01,\n",
       "             1.5249e-01, -1.0820e+00]]]])), (tensor([[[[-1.7171e+00, -3.1678e-01, -2.9777e-01,  ...,  1.6374e-01,\n",
       "             3.3939e-01, -5.0405e-01],\n",
       "           [ 1.0005e+00, -7.4353e-02, -3.1591e-01,  ...,  9.8546e-01,\n",
       "             3.8694e-01,  1.9397e-01],\n",
       "           [ 5.3557e-01, -2.7873e-01, -5.6496e-01,  ...,  8.7203e-01,\n",
       "             1.1084e-01, -8.4657e-02],\n",
       "           [ 3.1081e+00,  1.1192e+00, -5.8824e-01,  ..., -9.0599e-01,\n",
       "            -3.1936e-01,  3.1806e+00],\n",
       "           [-6.6281e-03, -3.1040e-01, -6.8736e-01,  ...,  5.8992e-02,\n",
       "             1.9067e-01, -3.4684e-01]],\n",
       " \n",
       "          [[ 1.1250e-01, -7.2020e-02,  2.2769e+00,  ...,  2.4112e-01,\n",
       "             7.9086e-02, -1.8682e-01],\n",
       "           [ 7.2027e-01, -3.2937e-01, -4.6188e-01,  ...,  2.2720e-01,\n",
       "             7.8823e-01,  1.5677e-01],\n",
       "           [ 1.2093e+00, -1.0736e-02, -1.3633e+00,  ..., -5.6439e-01,\n",
       "             7.4414e-01,  1.2345e-01],\n",
       "           [-1.5804e+00, -2.4209e-01, -5.2448e+00,  ..., -4.9587e-01,\n",
       "             7.6918e-01, -9.8388e-01],\n",
       "           [ 8.0094e-01,  8.5176e-02, -9.5735e-01,  ..., -7.0594e-01,\n",
       "             8.4204e-01,  3.7261e-01]],\n",
       " \n",
       "          [[-1.9710e-01,  1.0731e+00,  4.7097e-01,  ..., -5.3347e-01,\n",
       "             3.1728e-01, -1.0987e-01],\n",
       "           [-9.4280e-01,  9.3761e-01,  7.2004e-01,  ...,  5.6934e-01,\n",
       "             6.8291e-01, -9.0123e-01],\n",
       "           [-7.4189e-01, -5.7103e-02, -1.1436e+00,  ...,  1.0133e+00,\n",
       "             6.0794e-01, -5.0811e-01],\n",
       "           [-3.7141e+00,  1.4054e+00,  1.3469e+00,  ...,  2.6687e+00,\n",
       "            -2.8678e-01,  3.5959e-01],\n",
       "           [-3.4240e-01,  7.2197e-01, -1.4423e+00,  ...,  1.4138e+00,\n",
       "             6.9340e-02, -7.1226e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.5143e-01,  9.7703e-01, -8.5336e-01,  ..., -7.2737e-01,\n",
       "             6.9814e-01,  8.4353e-01],\n",
       "           [ 4.1859e-01,  7.1564e-01, -4.4094e-01,  ..., -1.2582e+00,\n",
       "             1.8282e+00,  6.6282e-01],\n",
       "           [-5.5937e-01,  4.7720e-01, -5.3998e-01,  ..., -1.3797e+00,\n",
       "             7.0006e-01, -7.5652e-03],\n",
       "           [-2.0969e+00,  4.1300e-01,  2.0748e+00,  ...,  4.9166e-01,\n",
       "            -6.6140e-01,  9.5985e-01],\n",
       "           [-2.9217e-01,  3.6847e-03, -7.7922e-02,  ..., -1.3481e+00,\n",
       "             7.7208e-01,  5.2298e-01]],\n",
       " \n",
       "          [[-4.1725e-01,  3.7354e-01,  3.4923e-01,  ...,  7.0215e-01,\n",
       "             2.0028e-02, -8.7374e-02],\n",
       "           [-2.2576e-01,  6.3022e-01, -1.6284e+00,  ...,  1.2455e+00,\n",
       "            -4.6162e-01, -1.2088e+00],\n",
       "           [-4.2737e-01,  1.4039e+00, -1.5148e+00,  ...,  4.4990e-01,\n",
       "            -2.7958e-01, -1.5009e-01],\n",
       "           [ 1.2690e+00,  1.4763e+00, -2.1361e+00,  ...,  5.5861e+00,\n",
       "            -2.4465e-01,  7.3573e-01],\n",
       "           [-6.2571e-01,  1.2827e+00, -1.4346e+00,  ...,  1.1543e+00,\n",
       "             5.4066e-01,  1.2211e+00]],\n",
       " \n",
       "          [[-7.2856e-01, -1.6945e-02,  4.3632e-01,  ..., -1.0156e-01,\n",
       "             1.4942e-02, -7.3517e-02],\n",
       "           [-8.8899e-01, -4.6633e-03,  1.4251e+00,  ...,  2.0434e-01,\n",
       "            -1.9716e+00,  6.7383e-01],\n",
       "           [-1.5857e-01, -7.1316e-02,  2.7450e-01,  ...,  1.3536e-01,\n",
       "            -1.3390e+00, -1.2668e-01],\n",
       "           [ 1.6838e-01,  6.2272e-01,  1.3128e+00,  ...,  7.9262e-01,\n",
       "            -5.7912e+00,  1.5786e+00],\n",
       "           [-2.6919e-01, -4.1152e-01, -2.0124e-01,  ..., -6.7689e-01,\n",
       "            -1.8812e+00,  9.9507e-01]]]]), tensor([[[[ 8.6463e-02, -1.3589e-01, -2.0528e-01,  ..., -2.7072e-01,\n",
       "             2.5288e-01, -1.4601e-01],\n",
       "           [ 2.2503e-01, -2.5975e+00, -4.8081e-01,  ...,  1.8046e+00,\n",
       "            -9.1344e-02,  9.3143e-01],\n",
       "           [ 1.9451e+00, -4.8441e-01,  4.1701e-01,  ...,  1.7170e+00,\n",
       "            -2.9507e+00,  2.3385e+00],\n",
       "           [-8.7038e-02, -2.2654e-01, -7.1110e-01,  ..., -8.7948e-01,\n",
       "             6.3717e-01, -1.8888e+00],\n",
       "           [ 1.9278e+00, -7.9783e-01,  6.2015e-01,  ...,  2.4127e+00,\n",
       "            -1.6722e+00,  1.3932e+00]],\n",
       " \n",
       "          [[ 8.4597e-02, -3.0458e-02,  4.1542e-02,  ..., -3.1874e-02,\n",
       "            -9.8648e-02,  1.6476e-01],\n",
       "           [-3.9442e-01,  1.8922e+00, -1.1529e+00,  ...,  5.0149e-01,\n",
       "            -1.0266e-01, -8.4586e-02],\n",
       "           [ 4.8550e-01, -1.2669e-02,  6.7550e-01,  ..., -1.1192e+00,\n",
       "             5.3913e-01, -6.2828e-01],\n",
       "           [-1.5967e+00,  1.2983e-01,  6.6246e-01,  ..., -1.5381e+00,\n",
       "             2.2341e+00, -6.0530e-01],\n",
       "           [ 4.0758e-01,  7.8607e-01,  6.3889e-01,  ..., -3.1637e-01,\n",
       "            -2.8247e-01, -8.2128e-01]],\n",
       " \n",
       "          [[-1.1752e-03,  2.7713e-02, -4.8585e-02,  ...,  4.0026e-02,\n",
       "             2.4395e-02,  5.1549e-02],\n",
       "           [-2.5244e+00,  4.8999e-01, -1.1787e+00,  ..., -1.3184e+00,\n",
       "            -1.2382e+00,  1.4722e-01],\n",
       "           [ 9.9843e-01, -4.2480e-01,  9.2013e-02,  ...,  1.1565e+00,\n",
       "             2.2450e-01, -1.5873e+00],\n",
       "           [-3.4990e+00, -1.5609e+00, -6.6879e+00,  ...,  3.7021e+00,\n",
       "             1.2570e+00, -3.4917e+00],\n",
       "           [ 1.6451e+00, -2.2633e-01, -1.3038e+00,  ...,  1.0642e+00,\n",
       "             2.6839e-01, -1.0582e+00]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.7204e-04, -5.6054e-03,  1.0676e-01,  ...,  7.0169e-02,\n",
       "            -1.8888e-02,  4.3763e-02],\n",
       "           [ 1.4256e-01,  1.8212e+00, -1.8898e+00,  ..., -1.0257e+00,\n",
       "            -1.9548e+00,  3.4638e-01],\n",
       "           [-6.4543e-01, -1.6021e-01, -3.1049e-01,  ...,  8.6457e-01,\n",
       "            -4.1231e-01, -1.4698e-01],\n",
       "           [ 1.3392e+00,  1.9414e+00,  5.4899e-01,  ..., -2.2720e+00,\n",
       "             5.9458e-01,  5.9801e-01],\n",
       "           [ 9.2600e-01,  8.3989e-01, -1.3084e-01,  ...,  5.1821e-01,\n",
       "            -7.1731e-01, -8.6038e-02]],\n",
       " \n",
       "          [[-2.0099e-01, -6.8959e-02,  7.5206e-02,  ..., -5.4001e-02,\n",
       "             4.2309e-02, -9.4743e-02],\n",
       "           [-2.5956e-01,  4.8328e-01,  3.5923e-01,  ...,  8.2185e-01,\n",
       "             7.6528e-01, -5.2308e-01],\n",
       "           [-1.2425e+00,  4.9312e-01,  6.3124e-01,  ..., -7.8125e-01,\n",
       "             4.9892e-01,  1.2023e-01],\n",
       "           [ 4.6455e-01,  3.9884e-01, -1.4366e+00,  ...,  1.7852e+00,\n",
       "            -2.0424e+00,  7.7446e-01],\n",
       "           [ 2.7460e-01,  2.7180e-01,  3.0302e-01,  ..., -2.4904e-01,\n",
       "             9.3368e-02,  1.6478e-01]],\n",
       " \n",
       "          [[ 1.0339e-01, -1.4692e-01,  1.6582e-01,  ..., -1.4900e-01,\n",
       "            -1.5749e-02, -1.8594e-01],\n",
       "           [-6.1961e-01, -4.4437e-01,  2.6243e-01,  ..., -1.4660e+00,\n",
       "             1.1299e+00, -5.5467e-01],\n",
       "           [-5.2097e-01, -7.7995e-01, -1.6498e-01,  ...,  2.2042e-01,\n",
       "            -6.1201e-01, -5.9761e-02],\n",
       "           [ 1.9113e+00, -2.1915e+00, -1.2300e+00,  ...,  7.9450e-01,\n",
       "             2.8137e-01, -2.4989e+00],\n",
       "           [-3.7991e-01, -5.8215e-01, -6.7041e-02,  ..., -2.1524e-01,\n",
       "            -6.3887e-01, -1.0283e+00]]]]))), hidden_states=None, attentions=None, cross_attentions=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervened_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6eb49d",
   "metadata": {},
   "source": [
    "### The End\n",
    "Now you are graduating from pyvene entry level course! Feel free to take a look at our tutorials for more challenging interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77d2cb-a8c3-4c7e-b369-e63aece154f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
