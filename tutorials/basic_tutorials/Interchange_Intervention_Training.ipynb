{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df77cec3",
   "metadata": {},
   "source": [
    "## Tutorial of Interchange Intervention Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d54c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Zhengxuan Wu\"\n",
    "__version__ = \"01/11/2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301516cb",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "[Interchange Intervention Training](https://arxiv.org/abs/2112.00826) (IIT) is a technique to train neural networks to be interpretable in a data-driven fashion. As it says in its name, it leverages intervention signals to train a neural network. As a result, the network's activations are highly interpretable in a sense that we can intervene them at inference time to get interpretable counterfactual behaviors.\n",
    "\n",
    "This library supports IIT as it is essentially a vanilla intervention plus enabling gradients for all the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b2f9c",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c2bae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     # This library is our indicator that the required installs\n",
    "#     # need to be done.\n",
    "#     import pyvene\n",
    "\n",
    "# except ModuleNotFoundError:\n",
    "#     !pip install git+https://github.com/frankaging/pyvene.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c4fa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-12 02:39:07,117] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from pyvene.models.basic_utils import (\n",
    "    embed_to_distrib,\n",
    "    top_vals,\n",
    "    format_token,\n",
    "    count_parameters\n",
    ")\n",
    "\n",
    "from pyvene.models.gpt2.modelings_intervenable_gpt2 import create_gpt2\n",
    "\n",
    "from pyvene.models.intervenable_base import IntervenableModel\n",
    "from pyvene.models.interventions import VanillaIntervention\n",
    "from pyvene.models.interventions import RotatedSpaceIntervention\n",
    "\n",
    "from pyvene.models.configuration_intervenable_model import (\n",
    "    IntervenableConfig, IntervenableRepresentationConfig, VanillaIntervention\n",
    ")\n",
    "\n",
    "config, tokenizer, gpt = create_gpt2(cache_dir=\"../../../.huggingface_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264bad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervenable_config = IntervenableConfig(\n",
    "    intervenable_model_type=type(gpt),\n",
    "    intervenable_representations=[\n",
    "        IntervenableRepresentationConfig(\n",
    "            2,\n",
    "            \"mlp_activation\",\n",
    "            \"pos\",\n",
    "            1,\n",
    "        ),\n",
    "    ],\n",
    "    intervenable_interventions_type=VanillaIntervention,\n",
    ")\n",
    "intervenable = IntervenableModel(intervenable_config, gpt)\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "sources = [\n",
    "    tokenizer(\"The capital of Italy is\", return_tensors=\"pt\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4641910d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervenable.count_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7d8f0",
   "metadata": {},
   "source": [
    "We just need to turn on gradients on all the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cedb63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124439808"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervenable.enable_model_gradients()\n",
    "intervenable.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a62cc234",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_outputs, counterfactual_outputs = intervenable(\n",
    "    base, sources, {\"sources->base\": ([[[3]]], [[[3]]])}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2ae690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1292, -0.0520,  0.1511,  ..., -0.1309,  0.0113,  0.0342],\n",
       "         [ 0.0603, -0.7758,  0.1832,  ...,  0.2912,  0.2868,  0.2893],\n",
       "         [-0.5429, -0.3998,  0.0891,  ..., -0.3754,  0.1311,  0.2489],\n",
       "         [ 0.2532,  0.1299,  0.0409,  ..., -0.2040, -0.1513,  0.3049],\n",
       "         [ 0.1114,  0.1318,  0.4405,  ...,  0.1814,  0.2783,  0.0206]]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counterfactual_outputs.last_hidden_state - base_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa21d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_outputs.last_hidden_state.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a948fc5",
   "metadata": {},
   "source": [
    "check any model grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "057e8dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7394e-01, -9.8538e-03,  2.1004e-02,  ..., -1.9908e-02,\n",
       "         -3.4756e-02, -8.5781e-02],\n",
       "        [-1.3462e-01, -1.8148e-03, -2.9549e-02,  ..., -5.2381e-02,\n",
       "         -1.0547e-01,  1.9281e-01],\n",
       "        [ 1.4480e-01,  9.1471e-04, -1.4906e-02,  ...,  2.0330e-02,\n",
       "          3.9505e-02, -6.6796e-02],\n",
       "        ...,\n",
       "        [ 2.4939e-01, -2.0916e-03, -3.0832e-03,  ...,  2.0648e-02,\n",
       "         -1.5234e-02, -1.5796e-04],\n",
       "        [-5.5724e-02, -9.8790e-03,  5.5369e-02,  ...,  1.8155e-02,\n",
       "          2.2969e-02, -4.6784e-02],\n",
       "        [ 1.6450e-01,  1.9703e-02, -2.0497e-02,  ...,  2.5583e-02,\n",
       "         -1.5143e-02, -2.4821e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.h[0].mlp.c_fc.weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
