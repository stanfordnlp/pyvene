
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Introduction to pyvene &#8212; pyvene 0.1.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=0deb7d70"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/pyvene_101';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Activation Addition" href="basic_tutorials/Add_Activations_to_Streams.html" />
    <link rel="prev" title="NDIF Integration" href="../guides/ndif.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">pyvene 0.1.2 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../guides/contributing.html">Contributing Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/causal_abstraction.html">A Little Guide to Causal Abstraction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guides/ndif.html">NDIF Integration</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Introduction to pyvene</a></li>

<li class="toctree-l1"><a class="reference internal" href="basic_tutorials/Add_Activations_to_Streams.html">Activation Addition</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_tutorials/Basic_Intervention.html">Interchange Intervention</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_tutorials/Nested_Intervention.html">Intervening on subcomponents</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_tutorials/Subspace_Partition_with_Intervention.html">Subspace Interventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_tutorials/Intervention_Training.html">Trainable Interventions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/Causal_Tracing.html">Causal Tracing (ROME)</a></li>

<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/Probing_Gender.html">Causal Evaluation of Probes</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/DAS_Main_Introduction.html">Intro to Distributed Alignment Search (DAS)</a></li>




<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/Boundless_DAS.html">Boundless DAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/IOI_Replication.html">Replicating the IOI paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/IOI_with_DAS.html">IOI with DAS</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/IOI_with_Mask_Intervention.html">IOI with Masked Interventions</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/Interventions_with_BLIP.html">Intervening on Vision-Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/MQNLI.html">Nested Hierarchical Structure with MQNLI</a></li>
<li class="toctree-l1"><a class="reference internal" href="advanced_tutorials/Voting_Mechanism.html">An Exploration on Voting Mechanisms</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../api/core.html"><code class="docutils literal notranslate"><span class="pre">pyvene</span></code>: Core API</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/pyvene.data_generators.html">pyvene.data_generators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.data_generators.causal_model.html">pyvene.data_generators.causal_model</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.data_generators.causal_model.simple_example.html">pyvene.data_generators.causal_model.simple_example</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.data_generators.causal_model.CausalModel.html">pyvene.data_generators.causal_model.CausalModel</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../api/pyvene.models.html">pyvene.models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.backpack_gpt2.html">pyvene.models.backpack_gpt2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.backpack_gpt2.modelings_backpack_gpt2.html">pyvene.models.backpack_gpt2.modelings_backpack_gpt2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.backpack_gpt2.modelings_intervenable_backpack_gpt2.html">pyvene.models.backpack_gpt2.modelings_intervenable_backpack_gpt2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.basic_utils.html">pyvene.models.basic_utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.GET_LOC.html">pyvene.models.basic_utils.GET_LOC</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.closeness_to_permutation_loss.html">pyvene.models.basic_utils.closeness_to_permutation_loss</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.count_parameters.html">pyvene.models.basic_utils.count_parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.create_directory.html">pyvene.models.basic_utils.create_directory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.embed_to_distrib.html">pyvene.models.basic_utils.embed_to_distrib</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.format_token.html">pyvene.models.basic_utils.format_token</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.get_batch_size.html">pyvene.models.basic_utils.get_batch_size</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.get_list_depth.html">pyvene.models.basic_utils.get_list_depth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.get_type_from_string.html">pyvene.models.basic_utils.get_type_from_string</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.harmonic_sigmoid_boundary.html">pyvene.models.basic_utils.harmonic_sigmoid_boundary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.random_permutation_matrix.html">pyvene.models.basic_utils.random_permutation_matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.set_seed.html">pyvene.models.basic_utils.set_seed</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.sigmoid_boundary.html">pyvene.models.basic_utils.sigmoid_boundary</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.basic_utils.top_vals.html">pyvene.models.basic_utils.top_vals</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.blip.html">pyvene.models.blip</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.blip.modelings_blip.html">pyvene.models.blip.modelings_blip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.blip.modelings_blip_itm.html">pyvene.models.blip.modelings_blip_itm</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.blip.modelings_intervenable_blip.html">pyvene.models.blip.modelings_intervenable_blip</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.blip.modelings_intervenable_blip_itm.html">pyvene.models.blip.modelings_intervenable_blip_itm</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.configuration_intervenable_model.html">pyvene.models.configuration_intervenable_model</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.configuration_intervenable_model.IntervenableConfig.html">pyvene.models.configuration_intervenable_model.IntervenableConfig</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.configuration_intervenable_model.RepresentationConfig.html">pyvene.models.configuration_intervenable_model.RepresentationConfig</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.constants.html">pyvene.models.constants</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.constants.split_and_select.html">pyvene.models.constants.split_and_select</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.constants.split_half.html">pyvene.models.constants.split_half</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.constants.split_head_and_permute.html">pyvene.models.constants.split_head_and_permute</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.constants.split_heads.html">pyvene.models.constants.split_heads</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.constants.split_three.html">pyvene.models.constants.split_three</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.esm.html">pyvene.models.esm</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.esm.modelings_intervenable_esm.html">pyvene.models.esm.modelings_intervenable_esm</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.gemma.html">pyvene.models.gemma</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gemma.modelings_intervenable_gemma.html">pyvene.models.gemma.modelings_intervenable_gemma</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.gemma2.html">pyvene.models.gemma2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gemma2.modelings_intervenable_gemma2.html">pyvene.models.gemma2.modelings_intervenable_gemma2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.gpt2.html">pyvene.models.gpt2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gpt2.modelings_intervenable_gpt2.html">pyvene.models.gpt2.modelings_intervenable_gpt2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.gpt_neo.html">pyvene.models.gpt_neo</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gpt_neo.modelings_intervenable_gpt_neo.html">pyvene.models.gpt_neo.modelings_intervenable_gpt_neo</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.gpt_neox.html">pyvene.models.gpt_neox</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gpt_neox.modelings_intervenable_gpt_neox.html">pyvene.models.gpt_neox.modelings_intervenable_gpt_neox</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.gpt_oss.html">pyvene.models.gpt_oss</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gpt_oss.modelings_intervenable_gpt_oss.html">pyvene.models.gpt_oss.modelings_intervenable_gpt_oss</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.gru.html">pyvene.models.gru</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gru.modelings_gru.html">pyvene.models.gru.modelings_gru</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.gru.modelings_intervenable_gru.html">pyvene.models.gru.modelings_intervenable_gru</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.intervenable_base.html">pyvene.models.intervenable_base</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervenable_base.build_intervenable_model.html">pyvene.models.intervenable_base.build_intervenable_model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervenable_base.BaseModel.html">pyvene.models.intervenable_base.BaseModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervenable_base.IntervenableModel.html">pyvene.models.intervenable_base.IntervenableModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervenable_base.IntervenableModelOutput.html">pyvene.models.intervenable_base.IntervenableModelOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervenable_base.IntervenableNdifModel.html">pyvene.models.intervenable_base.IntervenableNdifModel</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../api/pyvene.models.intervenable_modelcard.html">pyvene.models.intervenable_modelcard</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.intervention_utils.html">pyvene.models.intervention_utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervention_utils.broadcast_tensor_v1.html">pyvene.models.intervention_utils.broadcast_tensor_v1</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervention_utils.broadcast_tensor_v2.html">pyvene.models.intervention_utils.broadcast_tensor_v2</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.intervention_utils.InterventionState.html">pyvene.models.intervention_utils.InterventionState</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.interventions.html">pyvene.models.interventions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.AdditionIntervention.html">pyvene.models.interventions.AdditionIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.AutoencoderIntervention.html">pyvene.models.interventions.AutoencoderIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.BasisAgnosticIntervention.html">pyvene.models.interventions.BasisAgnosticIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.BoundlessRotatedSpaceIntervention.html">pyvene.models.interventions.BoundlessRotatedSpaceIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.CollectIntervention.html">pyvene.models.interventions.CollectIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.ConstantSourceIntervention.html">pyvene.models.interventions.ConstantSourceIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.DistributedRepresentationIntervention.html">pyvene.models.interventions.DistributedRepresentationIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.Intervention.html">pyvene.models.interventions.Intervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.InterventionOutput.html">pyvene.models.interventions.InterventionOutput</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.JumpReLUAutoencoderIntervention.html">pyvene.models.interventions.JumpReLUAutoencoderIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.LocalistRepresentationIntervention.html">pyvene.models.interventions.LocalistRepresentationIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.LowRankRotatedSpaceIntervention.html">pyvene.models.interventions.LowRankRotatedSpaceIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.NoiseIntervention.html">pyvene.models.interventions.NoiseIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.PCARotatedSpaceIntervention.html">pyvene.models.interventions.PCARotatedSpaceIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.RotatedSpaceIntervention.html">pyvene.models.interventions.RotatedSpaceIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.SharedWeightsTrainableIntervention.html">pyvene.models.interventions.SharedWeightsTrainableIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.SigmoidMaskIntervention.html">pyvene.models.interventions.SigmoidMaskIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.SigmoidMaskRotatedSpaceIntervention.html">pyvene.models.interventions.SigmoidMaskRotatedSpaceIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.SkipIntervention.html">pyvene.models.interventions.SkipIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.SourcelessIntervention.html">pyvene.models.interventions.SourcelessIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.SubtractionIntervention.html">pyvene.models.interventions.SubtractionIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.TrainableIntervention.html">pyvene.models.interventions.TrainableIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.VanillaIntervention.html">pyvene.models.interventions.VanillaIntervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.interventions.ZeroIntervention.html">pyvene.models.interventions.ZeroIntervention</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.layers.html">pyvene.models.layers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.layers.AutoencoderLayer.html">pyvene.models.layers.AutoencoderLayer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.layers.AutoencoderLayerBase.html">pyvene.models.layers.AutoencoderLayerBase</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.layers.InverseRotateLayer.html">pyvene.models.layers.InverseRotateLayer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.layers.LowRankRotateLayer.html">pyvene.models.layers.LowRankRotateLayer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.layers.RotateLayer.html">pyvene.models.layers.RotateLayer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.layers.SubspaceLowRankRotateLayer.html">pyvene.models.layers.SubspaceLowRankRotateLayer</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.llama.html">pyvene.models.llama</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.llama.modelings_intervenable_llama.html">pyvene.models.llama.modelings_intervenable_llama</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.llava.html">pyvene.models.llava</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.llava.modelings_intervenable_llava.html">pyvene.models.llava.modelings_intervenable_llava</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.mistral.html">pyvene.models.mistral</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.mistral.modellings_intervenable_mistral.html">pyvene.models.mistral.modellings_intervenable_mistral</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.mllama.html">pyvene.models.mllama</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.mllama.modelings_intervenable_mllama.html">pyvene.models.mllama.modelings_intervenable_mllama</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.mlp.html">pyvene.models.mlp</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.mlp.modelings_intervenable_mlp.html">pyvene.models.mlp.modelings_intervenable_mlp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.mlp.modelings_mlp.html">pyvene.models.mlp.modelings_mlp</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.modeling_utils.html">pyvene.models.modeling_utils</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.b_sd_to_bsd.html">pyvene.models.modeling_utils.b_sd_to_bsd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.bhsd_to_bs_hd.html">pyvene.models.modeling_utils.bhsd_to_bs_hd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.bs_hd_to_bhsd.html">pyvene.models.modeling_utils.bs_hd_to_bhsd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.bsd_to_b_sd.html">pyvene.models.modeling_utils.bsd_to_b_sd</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.do_intervention.html">pyvene.models.modeling_utils.do_intervention</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.gather_neurons.html">pyvene.models.modeling_utils.gather_neurons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.get_dimension_by_component.html">pyvene.models.modeling_utils.get_dimension_by_component</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.get_internal_model_type.html">pyvene.models.modeling_utils.get_internal_model_type</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.get_module_hook.html">pyvene.models.modeling_utils.get_module_hook</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.getattr_for_torch_module.html">pyvene.models.modeling_utils.getattr_for_torch_module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.is_gru.html">pyvene.models.modeling_utils.is_gru</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.is_mlp.html">pyvene.models.modeling_utils.is_mlp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.is_stateless.html">pyvene.models.modeling_utils.is_stateless</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.is_transformer.html">pyvene.models.modeling_utils.is_transformer</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.output_to_subcomponent.html">pyvene.models.modeling_utils.output_to_subcomponent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.print_forward_hooks.html">pyvene.models.modeling_utils.print_forward_hooks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.remove_forward_hooks.html">pyvene.models.modeling_utils.remove_forward_hooks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.scatter_neurons.html">pyvene.models.modeling_utils.scatter_neurons</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.simple_output_to_subcomponent.html">pyvene.models.modeling_utils.simple_output_to_subcomponent</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.simple_scatter_intervention_output.html">pyvene.models.modeling_utils.simple_scatter_intervention_output</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.weighted_average.html">pyvene.models.modeling_utils.weighted_average</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.HandlerList.html">pyvene.models.modeling_utils.HandlerList</a></li>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.modeling_utils.LambdaIntervention.html">pyvene.models.modeling_utils.LambdaIntervention</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.olmo.html">pyvene.models.olmo</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.olmo.modelings_intervenable_olmo.html">pyvene.models.olmo.modelings_intervenable_olmo</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.olmo2.html">pyvene.models.olmo2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.olmo2.modelings_intervenable_olmo2.html">pyvene.models.olmo2.modelings_intervenable_olmo2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.qwen2.html">pyvene.models.qwen2</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.qwen2.modelings_intervenable_qwen2.html">pyvene.models.qwen2.modelings_intervenable_qwen2</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../api/pyvene.models.qwen3.html">pyvene.models.qwen3</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../api/pyvene.models.qwen3.modelings_intervenable_qwen3.html">pyvene.models.qwen3.modelings_intervenable_qwen3</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tutorials/pyvene_101.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Introduction to pyvene</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to pyvene</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of Contents</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up">Set-up</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pyvene-101">pyvene 101</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#get-attention-weights">Get Attention Weights</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#get-attention-weights-with-direct-access-string">Get Attention Weights with Direct Access String</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#get-attention-weights-with-a-function">Get Attention Weights with a Function</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activation-to-zeros">Set Activation to Zeros</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activation-to-zeros-with-a-lambda-expression">Set Activation to Zeros with a Lambda Expression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activation-to-zeros-with-a-lambda-expression-and-subspace-notation">Set Activation to Zeros with a Lambda Expression and Subspace notation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activations-to-zeros-with-subspaces">Set Activations to Zeros with Subspaces</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interchange-interventions">Interchange Interventions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervention-configuration">Intervention Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#addition-intervention">Addition Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trainable-intervention">Trainable Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-collection-with-intervention">Activation Collection with Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-collection-at-downstream-of-a-intervened-model">Activation Collection at Downstream of a Intervened Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervene-on-a-single-neuron">Intervene on a Single Neuron</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-new-intervention-type">Add New Intervention Type</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-nns-intervene-a-specific-timestep">Recurrent NNs (Intervene a Specific Timestep)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-nns-intervene-cross-time">Recurrent NNs (Intervene cross Time)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lms-generation">LMs Generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-intervention-on-lms-generation-model-steering">Advanced Intervention on LMs Generation (Model Steering)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#debiasing-with-backpack-lms">Debiasing with Backpack LMs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading">Saving and Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-parallel-mode">Multi-Source Interchange Intervention (Parallel Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-serial-mode">Multi-Source Interchange Intervention (Serial Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-with-subspaces-parallel-mode">Multi-Source Interchange Intervention with Subspaces (Parallel Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-with-subspaces-serial-mode">Multi-Source Interchange Intervention with Subspaces (Serial Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interchange-intervention-training-iit">Interchange Intervention Training (IIT)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pyvene-102">pyvene 102</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grouping">Grouping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervention-skipping-in-runtime">Intervention Skipping in Runtime</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subspace-partition">Subspace Partition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervention-linking">Intervention Linking</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-new-model-type">Add New Model Type</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-complex-intervention-schema-path-patching">Composing Complex Intervention Schema: Path Patching</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-complex-intervention-schema-causal-tracing-in-15-lines">Composing Complex Intervention Schema: Causal Tracing in 15 lines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-time-intervention">Inference-time Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervenablemodel-from-huggingface-directly">IntervenableModel from HuggingFace Directly</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#path-patching-with-trainable-interventions">Path Patching with Trainable Interventions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervene-on-resnet-with-lambda-functions">Intervene on ResNet with Lambda Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervene-on-resnet-with-trainable-lambda-functions">Intervene on ResNet with Trainable Lambda Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-pyvene-on-ndif-backend-with-pv-build-intervenable-model">Run pyvene on NDIF backend with <code class="docutils literal notranslate"><span class="pre">pv.build_intervenable_model(...)</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-lora-with-pyvene">Run LoRA with pyvene</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-end">The End</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="introduction-to-pyvene">
<h1>Introduction to pyvene<a class="headerlink" href="#introduction-to-pyvene" title="Link to this heading">#</a></h1>
<p>This tutorial shows simple runnable code snippets of how to do different kinds of interventions on neural networks with pyvene.</p>
<p><a class="reference external" href="https://colab.research.google.com/github/stanfordnlp/pyvene/blob/main/pyvene_101.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">__author__</span> <span class="o">=</span> <span class="s2">&quot;Zhengxuan Wu&quot;</span>
<span class="n">__version__</span> <span class="o">=</span> <span class="s2">&quot;02/01/2024&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="table-of-contents">
<h1>Table of Contents<a class="headerlink" href="#table-of-contents" title="Link to this heading">#</a></h1>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#Set-up"><span class="xref myst">Set-up</span></a></p></li>
<li><p><a class="reference internal" href="#pyvene-101"><span class="xref myst">pyvene 101</span></a></p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#Get-Attention-Weights"><span class="xref myst">Get Attention Weights</span></a></p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#Get-Attention-Weights-with-Direct-Access-String"><span class="xref myst">with String Access</span></a></p></li>
<li><p><a class="reference internal" href="#Get-Attention-Weights-with-a-Function"><span class="xref myst">with 1-Line Function</span></a></p></li>
</ol>
</li>
<li><p><a class="reference internal" href="#Set-Activation-to-Zeros"><span class="xref myst">Set Activations to Zeros</span></a></p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#Set-Activation-to-Zeros-with-a-Lambda-Expression"><span class="xref myst">with Lambda Expression</span></a></p></li>
</ol>
</li>
<li><p><a class="reference internal" href="#Set-Activations-to-Zeros-with-Subspaces"><span class="xref myst">Set Activations with Subspaces</span></a></p></li>
<li><p><a class="reference internal" href="#Interchange-Interventions"><span class="xref myst">Interchange Intervention</span></a></p></li>
<li><p><a class="reference internal" href="#Intervention-Configuration"><span class="xref myst">Intervention Config</span></a></p></li>
<li><p><a class="reference internal" href="#Addition-Intervention"><span class="xref myst">Addition Intervention</span></a></p></li>
<li><p><a class="reference internal" href="#Trainable-Intervention"><span class="xref myst">Trainable Intervention</span></a></p></li>
<li><p><a class="reference internal" href="#Activation-Collection-with-Intervention"><span class="xref myst">Activation Collection</span></a></p></li>
<li><p><a class="reference internal" href="#Activation-Collection-at-Downstream-of-a-Intervened-Model"><span class="xref myst">Activation Collection with Other Intervention</span></a></p></li>
<li><p><a class="reference internal" href="#Intervene-on-a-Single-Neuron"><span class="xref myst">Intervene Single Neuron</span></a></p></li>
<li><p><a class="reference internal" href="#Add-New-Intervention-Type"><span class="xref myst">Add New Intervention Type</span></a></p></li>
<li><p><a class="reference internal" href="#Recurrent-NNs-(Intervene-a-Specific-Timestep)"><span class="xref myst">Intervene on Recurrent NNs</span></a></p></li>
<li><p><a class="reference internal" href="#Recurrent-NNs-(Intervene-cross-Time)"><span class="xref myst">Intervene across Times with RNNs</span></a></p></li>
<li><p><a class="reference internal" href="#LMs-Generation"><span class="xref myst">Intervene on LM Generation</span></a></p></li>
<li><p><a class="reference internal" href="#Advanced-Intervention-on-LMs-Generation-(Model-Steering)"><span class="xref myst">Advanced Intervention on LM Generation (Model Steering)</span></a></p></li>
<li><p><a class="reference internal" href="#Debiasing-with-Backpack-LMs"><span class="xref myst">Debiasing with Backpack LMs</span></a></p></li>
<li><p><a class="reference internal" href="#Saving-and-Loading"><span class="xref myst">Saving and Loading</span></a></p></li>
<li><p><a class="reference internal" href="#Multi-Source-Interchange-Intervention-(Parallel-Mode)"><span class="xref myst">Multi-Source Intervention (Parallel)</span></a></p></li>
<li><p><a class="reference internal" href="#Multi-Source-Interchange-Intervention-(Serial-Mode)"><span class="xref myst">Multi-Source Intervention (Serial)</span></a></p></li>
<li><p><a class="reference internal" href="#Multi-Source-Interchange-Intervention-with-Subspaces-(Parallel-Mode)"><span class="xref myst">Multi-Source Intervention with Subspaces (Parallel)</span></a></p></li>
<li><p><a class="reference internal" href="#Multi-Source-Interchange-Intervention-with-Subspaces-(Serial-Mode)"><span class="xref myst">Multi-Source Intervention with Subspaces (Serial)</span></a></p></li>
<li><p><a class="reference internal" href="#Interchange-Intervention-Training-(IIT)"><span class="xref myst">Interchange Intervention Training</span></a></p></li>
</ol>
</li>
<li><p><a class="reference internal" href="#pyvene-102"><span class="xref myst">pyvene 102</span></a></p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#Grouping"><span class="xref myst">Intervention Grouping</span></a></p></li>
<li><p><a class="reference internal" href="#Intervention-Skipping-in-Runtime"><span class="xref myst">Intervention Skipping</span></a></p></li>
<li><p><a class="reference internal" href="#Subspace-Partition"><span class="xref myst">Subspace Partition</span></a></p></li>
<li><p><a class="reference internal" href="#Intervention-Linking"><span class="xref myst">Intervention Linking</span></a></p></li>
<li><p><a class="reference internal" href="#Add-New-Model-Type"><span class="xref myst">Add New Model Type</span></a></p></li>
<li><p><a class="reference internal" href="#Composing-Complex-Intervention-Schema:-Path-Patching"><span class="xref myst">Path Patching</span></a></p></li>
<li><p><a class="reference internal" href="#Composing-Complex-Intervention-Schema:-Causal-Tracing-in-15-lines"><span class="xref myst">Causal Tracing</span></a></p></li>
<li><p><a class="reference internal" href="#Inference-time-Intervention"><span class="xref myst">Inference-time Intervention</span></a></p></li>
<li><p><a class="reference internal" href="#IntervenableModel-from-HuggingFace-Directly"><span class="xref myst">IntervenableModel from HuggingFace Directly</span></a></p></li>
<li><p><a class="reference internal" href="#Path-Patching-with-Trainable-Interventions"><span class="xref myst">Path Patching with DAS</span></a></p></li>
<li><p><a class="reference internal" href="#Intervene-on-ResNet-with-Lambda-Functions"><span class="xref myst">Intervene ResNet with Lambda Functors</span></a></p></li>
<li><p><a class="reference internal" href="#Intervene-on-ResNet-with-Trainable-Lambda-Functions"><span class="xref myst">Intervene ResNet with 1-line DAS Lambda</span></a></p></li>
<li><p><a class="reference internal" href="#Run-pyvene-on-NDIF-backend-with-pv.build_intervenable_model(...)"><span class="xref myst">Run pyvene on NDIF backend</span></a></p></li>
<li><p><a class="reference internal" href="#Run-LoRA-with-pyvene"><span class="xref myst">Run LoRAs with pyvene</span></a></p></li>
</ol>
</li>
<li><p><a class="reference internal" href="#The-End"><span class="xref myst">The End</span></a></p></li>
</ol>
<section id="set-up">
<h2>Set-up<a class="headerlink" href="#set-up" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="c1"># This library is our indicator that the required installs</span>
    <span class="c1"># need to be done.</span>
    <span class="kn">import</span> <span class="nn">pyvene</span>

<span class="k">except</span> <span class="ne">ModuleNotFoundError</span><span class="p">:</span>
    <span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/stanfordnlp/pyvene.git
</pre></div>
</div>
</div>
</div>
</section>
<section id="pyvene-101">
<h2>pyvene 101<a class="headerlink" href="#pyvene-101" title="Link to this heading">#</a></h2>
<p>Before we get started, here are a couple of core notations that are used in this library:</p>
<ul class="simple">
<li><p><strong>Base</strong> example: this is the example we are intervening on, or, we are intervening on the computation graph of the model running the <strong>Base</strong> example.</p></li>
<li><p><strong>Source</strong> example or representations: this is the source of our intervention. We use <strong>Source</strong> to intervene on <strong>Base</strong>.</p></li>
<li><p><strong>component</strong>: this is the <code class="docutils literal notranslate"><span class="pre">nn.module</span></code> we are intervening in a pytorch-based NN. For models supported by this library, you can use directly access via str, or use the abstract names defined in the config file (e.g., <code class="docutils literal notranslate"><span class="pre">h[0].mlp.output</span></code> or <code class="docutils literal notranslate"><span class="pre">mlp_output</span></code> with other fields).</p></li>
<li><p><strong>unit</strong>: this is the axis of our intervention. If we say our <strong>unit</strong> is <code class="docutils literal notranslate"><span class="pre">pos</span></code> (<code class="docutils literal notranslate"><span class="pre">position</span></code>), then you are intervening on each token position.</p></li>
<li><p><strong>unit_locations</strong>: this list gives you the percisely location of your intervention. It is the locations of the unit of analysis you are specifying. For instance, if your <code class="docutils literal notranslate"><span class="pre">unit</span></code> is <code class="docutils literal notranslate"><span class="pre">pos</span></code>, and your <code class="docutils literal notranslate"><span class="pre">unit_location</span></code> is 3, then it means you are intervening on the third token. If this field is left as <code class="docutils literal notranslate"><span class="pre">None</span></code>, then no selection will be taken, i.e., you can think of you are getting the raw tensor and you can do whatever you want.</p></li>
<li><p><strong>intervention_type</strong> or <strong>intervention</strong>: this field specifies the intervention you can perform. It can be a primitive type, or it can be a function or a lambda expression for simple interventions. One benefit of using primitives is speed and systematic training schemes. You can also save and load interventions if you use the supported primitives.</p></li>
</ul>
<section id="get-attention-weights">
<h3>Get Attention Weights<a class="headerlink" href="#get-attention-weights" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>

<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;gpt2&quot;</span>
<span class="c1"># Do not use SDPA attention because we cannot hook to attn_dropout</span>
<span class="n">gpt2</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">attn_implementation</span><span class="o">=</span><span class="s2">&quot;eager&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;attention_weight&quot;</span><span class="p">,</span>
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">CollectIntervention</span><span class="p">},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;When John and Mary went to the shops, Mary gave the bag to&quot;</span>
<span class="n">collected_attn_w</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">h</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<section id="get-attention-weights-with-direct-access-string">
<h4>Get Attention Weights with Direct Access String<a class="headerlink" href="#get-attention-weights-with-direct-access-string" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="c1"># gpt2 helper loading model from HuggingFace</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="c1"># based on the module printed above, you can access via string, input means the input to the module</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;h[10].attn.attn_dropout.input&quot;</span><span class="p">,</span>
    <span class="c1"># you can also initialize the intervention outside</span>
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">CollectIntervention</span><span class="p">()},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;When John and Mary went to the shops, Mary gave the bag to&quot;</span>
<span class="n">collected_attn_w</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">h</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="get-attention-weights-with-a-function">
<h4>Get Attention Weights with a Function<a class="headerlink" href="#get-attention-weights-with-a-function" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">cached_w</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">def</span> <span class="nf">pv_patcher</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span> <span class="n">cached_w</span><span class="p">[</span><span class="s2">&quot;attn_w&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;h[10].attn.attn_dropout.input&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv_patcher</span><span class="p">},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;When John and Mary went to the shops, Mary gave the bag to&quot;</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">))</span>
<span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">collected_attn_w</span><span class="p">,</span> <span class="n">cached_w</span><span class="p">[</span><span class="s2">&quot;attn_w&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="set-activation-to-zeros">
<h3>Set Activation to Zeros<a class="headerlink" href="#set-activation-to-zeros" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="c1"># define the component to zero-out</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;source_representation&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">gpt2</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
<span class="p">},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="c1"># run the intervened forward pass</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
    <span class="c1"># we define the intervening token dynamically</span>
    <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
    <span class="n">output_original_output</span><span class="o">=</span><span class="kc">True</span> <span class="c1"># False then the first element in the tuple is None</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
<section id="set-activation-to-zeros-with-a-lambda-expression">
<h4>Set Activation to Zeros with a Lambda Expression<a class="headerlink" href="#set-activation-to-zeros-with-a-lambda-expression" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="c1"># indices are specified in the intervention</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
<span class="n">mask</span><span class="p">[:,</span><span class="mi">3</span><span class="p">,:]</span> <span class="o">=</span> <span class="mf">0.</span>
<span class="c1"># define the component to zero-out</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;h[0].mlp.output&quot;</span><span class="p">,</span> <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="n">b</span><span class="o">*</span><span class="n">mask</span>
<span class="p">},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="c1"># run the intervened forward pass</span>
<span class="n">intervened_outputs_fn</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span>
    <span class="n">intervened_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> 
    <span class="n">intervened_outputs_fn</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">last_hidden_state</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
<section id="set-activation-to-zeros-with-a-lambda-expression-and-subspace-notation">
<h4>Set Activation to Zeros with a Lambda Expression and Subspace notation<a class="headerlink" href="#set-activation-to-zeros-with-a-lambda-expression-and-subspace-notation" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="c1"># indices are specified in the intervention</span>

<span class="k">def</span> <span class="nf">pv_patcher</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">sp</span><span class="p">):</span> 
    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
    <span class="n">mask</span><span class="p">[:,</span><span class="n">sp</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],:]</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">return</span> <span class="n">b</span><span class="o">*</span><span class="n">mask</span>

<span class="c1"># define the component to zero-out</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;h[0].mlp.output&quot;</span><span class="p">,</span> <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv_patcher</span>
<span class="p">},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="c1"># run the intervened forward pass</span>
<span class="n">intervened_outputs_fn</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span>
    <span class="n">intervened_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> 
    <span class="n">intervened_outputs_fn</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">last_hidden_state</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="set-activations-to-zeros-with-subspaces">
<h3>Set Activations to Zeros with Subspaces<a class="headerlink" href="#set-activations-to-zeros-with-subspaces" title="Link to this heading">#</a></h3>
<p>The notion of subspace means the actual dimensions you are intervening. If we have a representation in a size of 512, the first 128 activation values are its subspace activations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="c1"># built-in helper to get a HuggingFace model</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>
<span class="c1"># create with dict-based config</span>
<span class="n">pv_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
  <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">})</span>
<span class="c1">#initialize model</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">pv_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="c1"># run an intervened forward pass</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
  <span class="c1"># the intervening base input</span>
  <span class="n">base</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
  <span class="c1"># the location to intervene at (3rd token)</span>
  <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
  <span class="c1"># the individual dimensions targetted</span>
  <span class="n">subspaces</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">],</span>
  <span class="n">source_representations</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">gpt2</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
<span class="p">)</span>
<span class="c1"># sharing</span>
<span class="n">pv_gpt2</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;./tmp/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
Directory &#39;./tmp/&#39; already exists.
</pre></div>
</div>
</div>
</div>
</section>
<section id="interchange-interventions">
<h3>Interchange Interventions<a class="headerlink" href="#interchange-interventions" title="Link to this heading">#</a></h3>
<p>Instead of a static vector, we can intervene the model with activations sampled from a different forward run. We call this interchange intervention, where intervention happens between two examples and we are interchanging activations between them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="c1"># built-in helper to get a HuggingFace model</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>
<span class="c1"># create with dict-based config</span>
<span class="n">pv_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
  <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
  <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">},</span>
  <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span>
<span class="p">)</span>
<span class="c1">#initialize model</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
  <span class="n">pv_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="c1"># run an interchange intervention </span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
  <span class="c1"># the base input</span>
  <span class="n">base</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
  <span class="c1"># the source input</span>
  <span class="n">sources</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
  <span class="c1"># the location to intervene at (3rd token)</span>
  <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
  <span class="c1"># the individual dimensions targeted</span>
  <span class="n">subspaces</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">12</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervention-configuration">
<h3>Intervention Configuration<a class="headerlink" href="#intervention-configuration" title="Link to this heading">#</a></h3>
<p>You can also initialize the config without the lazy dictionary passing by enabling more options, e.g., the mode of these interventions are executed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>
<span class="c1"># standalone configuration object</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="p">{</span>
        <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">_</span><span class="p">,</span>
        <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span>
        <span class="s2">&quot;source_representation&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
            <span class="n">gpt2</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
    <span class="p">}</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)],</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;parallel&quot;</span>
<span class="p">)</span>
<span class="c1"># this object is serializable</span>
<span class="nb">print</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
    <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
IntervenableConfig
{
    &quot;model_type&quot;: &quot;None&quot;,
    &quot;representations&quot;: [
        {
            &quot;layer&quot;: 0,
            &quot;component&quot;: &quot;mlp_output&quot;,
            &quot;unit&quot;: &quot;pos&quot;,
            &quot;max_number_of_units&quot;: 1,
            &quot;low_rank_dimension&quot;: null,
            &quot;intervention_type&quot;: null,
            &quot;intervention&quot;: null,
            &quot;subspace_partition&quot;: null,
            &quot;group_key&quot;: null,
            &quot;intervention_link_key&quot;: null,
            &quot;moe_key&quot;: null,
            &quot;source_representation&quot;: &quot;PLACEHOLDER&quot;,
            &quot;hidden_source_representation&quot;: null
        },
        {
            &quot;layer&quot;: 1,
            &quot;component&quot;: &quot;mlp_output&quot;,
            &quot;unit&quot;: &quot;pos&quot;,
            &quot;max_number_of_units&quot;: 1,
            &quot;low_rank_dimension&quot;: null,
            &quot;intervention_type&quot;: null,
            &quot;intervention&quot;: null,
            &quot;subspace_partition&quot;: null,
            &quot;group_key&quot;: null,
            &quot;intervention_link_key&quot;: null,
            &quot;moe_key&quot;: null,
            &quot;source_representation&quot;: &quot;PLACEHOLDER&quot;,
            &quot;hidden_source_representation&quot;: null
        },
        {
            &quot;layer&quot;: 2,
            &quot;component&quot;: &quot;mlp_output&quot;,
            &quot;unit&quot;: &quot;pos&quot;,
            &quot;max_number_of_units&quot;: 1,
            &quot;low_rank_dimension&quot;: null,
            &quot;intervention_type&quot;: null,
            &quot;intervention&quot;: null,
            &quot;subspace_partition&quot;: null,
            &quot;group_key&quot;: null,
            &quot;intervention_link_key&quot;: null,
            &quot;moe_key&quot;: null,
            &quot;source_representation&quot;: &quot;PLACEHOLDER&quot;,
            &quot;hidden_source_representation&quot;: null
        },
        {
            &quot;layer&quot;: 3,
            &quot;component&quot;: &quot;mlp_output&quot;,
            &quot;unit&quot;: &quot;pos&quot;,
            &quot;max_number_of_units&quot;: 1,
            &quot;low_rank_dimension&quot;: null,
            &quot;intervention_type&quot;: null,
            &quot;intervention&quot;: null,
            &quot;subspace_partition&quot;: null,
            &quot;group_key&quot;: null,
            &quot;intervention_link_key&quot;: null,
            &quot;moe_key&quot;: null,
            &quot;source_representation&quot;: &quot;PLACEHOLDER&quot;,
            &quot;hidden_source_representation&quot;: null
        }
    ],
    &quot;intervention_types&quot;: &quot;&lt;class &#39;pyvene.models.interventions.VanillaIntervention&#39;&gt;&quot;,
    &quot;mode&quot;: &quot;parallel&quot;,
    &quot;sorted_keys&quot;: &quot;None&quot;,
    &quot;intervention_dimensions&quot;: &quot;None&quot;
}
</pre></div>
</div>
</div>
</div>
</section>
<section id="addition-intervention">
<h3>Addition Intervention<a class="headerlink" href="#addition-intervention" title="Link to this heading">#</a></h3>
<p>Activation swap is one kind of interventions we can perform. Here is another simple one: <code class="docutils literal notranslate"><span class="pre">pv.AdditionIntervention</span></code>, which adds the sampled representation into the <strong>Base</strong> run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_input&quot;</span><span class="p">},</span>
    <span class="n">pv</span><span class="o">.</span><span class="n">AdditionIntervention</span>
<span class="p">)</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="s2">&quot;The Space Needle is in downtown&quot;</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> 
    <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="p">[[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]]},</span>
    <span class="n">source_representations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">gpt2</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_embd</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="trainable-intervention">
<h3>Trainable Intervention<a class="headerlink" href="#trainable-intervention" title="Link to this heading">#</a></h3>
<p>Interventions can contain trainable parameters, and hook-up with the model to receive gradients end-to-end. They are often useful in searching for an particular interpretation of the representation.</p>
<p>The following example does a single step gradient calculation to push the model to generate <code class="docutils literal notranslate"><span class="pre">Rome</span></code> after the intervention. If we can train such intervention at scale with low loss, it means you have a causal grab onto your model. In terms of interpretability, that means, somehow you find a representation (not the original one since its trained) that maps onto the <code class="docutils literal notranslate"><span class="pre">capital</span></code> output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">das_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;low_rank_dimension&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
    <span class="c1"># this is a trainable low-rank rotation</span>
    <span class="n">pv</span><span class="o">.</span><span class="n">LowRankRotatedSpaceIntervention</span>
<span class="p">)</span>

<span class="n">das_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">das_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">das_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> 
    <span class="n">sources</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> 
    <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># golden counterfacutual label as Rome</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span>
    <span class="s2">&quot; Rome&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
    <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">gpt2</span><span class="o">.</span><span class="n">wte</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">label</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="activation-collection-with-intervention">
<h3>Activation Collection with Intervention<a class="headerlink" href="#activation-collection-with-intervention" title="Link to this heading">#</a></h3>
<p>You can also collect activations with our provided <code class="docutils literal notranslate"><span class="pre">pv.CollectIntervention</span></code> intervention. More importantly, this can be used interchangably with other interventions. You can collect something from an intervened model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">CollectIntervention</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">collected_activations</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="activation-collection-at-downstream-of-a-intervened-model">
<h3>Activation Collection at Downstream of a Intervened Model<a class="headerlink" href="#activation-collection-at-downstream-of-a-intervened-model" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">config</span><span class="o">.</span><span class="n">add_intervention</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">CollectIntervention</span><span class="p">})</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">collected_activations</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> 
    <span class="n">sources</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span>
        <span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> <span class="kc">None</span><span class="p">],</span> <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervene-on-a-single-neuron">
<h3>Intervene on a Single Neuron<a class="headerlink" href="#intervene-on-a-single-neuron" title="Link to this heading">#</a></h3>
<p>We want to provide a good user interface so that interventions can be done easily by people with less pytorch or programming experience. Meanwhile, we also want to be flexible and provide the depth of control required for highly specific tasks. Here is an example where we intervene on a specific neuron at a specific head of a layer in a model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;head_attention_value_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="s2">&quot;h.pos&quot;</span><span class="p">,</span>
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">CollectIntervention</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">collected_activations</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
        <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
        <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> 
    <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span>
        <span class="c1"># GET_LOC is a helper.</span>
        <span class="c1"># (3,3) means head 3 position 3</span>
        <span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">GET_LOC</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
    <span class="p">},</span>
    <span class="c1"># the notion of subspace is used to target neuron 0.</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="add-new-intervention-type">
<h3>Add New Intervention Type<a class="headerlink" href="#add-new-intervention-type" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">MultiplierIntervention</span><span class="p">(</span>
  <span class="n">pv</span><span class="o">.</span><span class="n">ConstantSourceIntervention</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">subspaces</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">base</span> <span class="o">*</span> <span class="mf">99.0</span>
<span class="c1"># run with new intervention type</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
  <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">MultiplierIntervention</span><span class="p">},</span> 
  <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
  <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
  <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="recurrent-nns-intervene-a-specific-timestep">
<h3>Recurrent NNs (Intervene a Specific Timestep)<a class="headerlink" href="#recurrent-nns-intervene-a-specific-timestep" title="Link to this heading">#</a></h3>
<p>Existing intervention libraries focus on Transformer models. They often lack of supports for GRUs, LSTMs or any state-space model. The fundemental problem is in the hook mechanism provided by PyTorch. Hook is attached to a module before runtime. Models like GRUs will lead to undesired callback from the hook as there is no notion of state or time of the hook.</p>
<p>We make our hook stateful, so you can intervene on recurrent NNs like GRUs. This notion of time will become useful when intervening on Transformers yet want to unroll the causal effect during generation as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">gru</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gru_classifier</span><span class="p">(</span>
    <span class="n">pv</span><span class="o">.</span><span class="n">GRUConfig</span><span class="p">(</span><span class="n">h_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">))</span>

<span class="n">pv_gru</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;cell_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="s2">&quot;t&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">ZeroIntervention</span><span class="p">},</span>
    <span class="n">model</span><span class="o">=</span><span class="n">gru</span><span class="p">)</span>

<span class="n">rand_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span> <span class="n">gru</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">h_dim</span><span class="p">)</span>

<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gru</span><span class="p">(</span>
  <span class="n">base</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs_embeds&quot;</span><span class="p">:</span> <span class="n">rand_t</span><span class="p">},</span> 
  <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="recurrent-nns-intervene-cross-time">
<h3>Recurrent NNs (Intervene cross Time)<a class="headerlink" href="#recurrent-nns-intervene-cross-time" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="c1"># built-in helper to get a GRU</span>
<span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">gru</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gru_classifier</span><span class="p">(</span>
    <span class="n">pv</span><span class="o">.</span><span class="n">GRUConfig</span><span class="p">(</span><span class="n">h_dim</span><span class="o">=</span><span class="mi">32</span><span class="p">))</span>
<span class="c1"># wrap it with config</span>
<span class="n">pv_gru</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;cell_output&quot;</span><span class="p">,</span>
    <span class="c1"># intervening on time</span>
    <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="s2">&quot;t&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">ZeroIntervention</span><span class="p">},</span>
    <span class="n">model</span><span class="o">=</span><span class="n">gru</span><span class="p">)</span>
<span class="c1"># run an intervened forward pass</span>
<span class="n">rand_b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span> <span class="n">gru</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">h_dim</span><span class="p">)</span>
<span class="n">rand_s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span> <span class="n">gru</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">h_dim</span><span class="p">)</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gru</span><span class="p">(</span>
  <span class="n">base</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;inputs_embeds&quot;</span><span class="p">:</span> <span class="n">rand_b</span><span class="p">},</span> 
  <span class="n">sources</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;inputs_embeds&quot;</span><span class="p">:</span> <span class="n">rand_s</span><span class="p">}],</span> 
  <span class="c1"># intervening time step</span>
  <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">)})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="lms-generation">
<h3>LMs Generation<a class="headerlink" href="#lms-generation" title="Link to this heading">#</a></h3>
<p>You can also intervene the generation call of LMs. Here is a simple example where we try to add a vector into the MLP output when the model decodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="c1"># built-in helper to get tinystore</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">tinystory</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt_neo</span><span class="p">()</span>
<span class="n">emb_happy</span> <span class="o">=</span> <span class="n">tinystory</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">wte</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">14628</span><span class="p">))</span> 

<span class="n">pv_tinystory</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">([{</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">l</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">AdditionIntervention</span>
    <span class="p">}</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tinystory</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)],</span>
    <span class="n">model</span><span class="o">=</span><span class="n">tinystory</span>
<span class="p">)</span>
<span class="c1"># prompt and generate</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot;Once upon a time there was&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">unintervened_story</span><span class="p">,</span> <span class="n">intervened_story</span> <span class="o">=</span> <span class="n">pv_tinystory</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">prompt</span><span class="p">,</span> <span class="n">source_representations</span><span class="o">=</span><span class="n">emb_happy</span><span class="o">*</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
    <span class="n">intervened_story</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
    <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span>
<span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
Once upon a time there was a little girl named Lucy. She was three years old and loved to explore. One day, Lucy was walking in the park when she saw a big, red balloon. She was so excited and wanted to play with it.

But then, a big, mean man came and said, &quot;That balloon is mine! You can&#39;t have it!&quot; Lucy was very sad and started to cry.

The man said, &quot;I&#39;m sorry, but I need the balloon for my work. You can have it if you want.&quot;

Lucy was so happy and said, &quot;Yes please!&quot; She took the balloon and ran away.

But then, the man said, &quot;Wait! I have an idea. Let&#39;s make a deal. If you can guess what I&#39;m going to give you, then you can have the balloon.&quot;

Lucy thought for a moment and then said, &quot;I guess I&#39;ll have to get the balloon.&quot;

The man smiled and said, &quot;That&#39;s a good guess! Here you go.&quot;

Lucy was so happy and thanked the man. She hugged the balloon and ran off to show her mom.

The end.
</pre></div>
</div>
</div>
</div>
<p>intervene on generation with source example passed in. The result will be slightly different since we no longer have a static vector to be added in; it is layerwise addition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="c1"># built-in helper to get tinystore</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">tinystory</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt_neo</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">pv_patcher</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span> <span class="k">return</span> <span class="n">b</span> <span class="o">+</span> <span class="n">s</span><span class="o">*</span><span class="mf">0.1</span>

<span class="n">pv_tinystory</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">([{</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">l</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv_patcher</span>
    <span class="p">}</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tinystory</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_layers</span><span class="p">)],</span>
    <span class="n">model</span><span class="o">=</span><span class="n">tinystory</span>
<span class="p">)</span>
<span class="c1"># prompt and generate</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot;Once upon a time there was&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">happy_prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot; Happy&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">intervened_story</span> <span class="o">=</span> <span class="n">pv_tinystory</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">prompt</span><span class="p">,</span> <span class="n">happy_prompt</span><span class="p">,</span> 
    <span class="n">unit_locations</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
    <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
    <span class="n">intervened_story</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
    <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span>
<span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input&#39;s `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input&#39;s `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Once upon a time there was a little girl named Lucy. She was very excited because she was going to the park. She wanted to go to the park and play.

When she got to the park, she saw a big slide. She was so excited! She ran to the slide and started to climb up. She was so happy.

But then she saw something else. It was a big, scary dog. It was a big, mean dog. He was barking and growling at her. Lucy was scared. She didn&#39;t know what to do.

Suddenly, she heard a voice. It was her mommy. She said, &quot;Don&#39;t worry, Lucy. I will help you. I will protect you.&quot;

Lucy was so happy. She hugged her mommy and they went to the park. They played together and had lots of fun. Lucy was so happy. She was no longer scared.
</pre></div>
</div>
</div>
</div>
</section>
<section id="advanced-intervention-on-lms-generation-model-steering">
<h3>Advanced Intervention on LMs Generation (Model Steering)<a class="headerlink" href="#advanced-intervention-on-lms-generation-model-steering" title="Link to this heading">#</a></h3>
<p>We also support model steering with interventions during model generation. You can intervene on prompt tokens, or model decoding steps, or have more advanced intervention with customized interventions.</p>
<p>Note that you must set <code class="docutils literal notranslate"><span class="pre">keep_last_dim</span> <span class="pre">=</span> <span class="pre">True</span></code> to get token-level representations!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/gemma-2-2b-it&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/gemma-2-2b-it&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Extracting happy vector ...&quot;</span><span class="p">)</span>
<span class="n">happy_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;happy&quot;</span><span class="p">)[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">happy_vector</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">embed_tokens</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">happy_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># Create a &quot;happy&quot; addition intervention</span>
<span class="k">class</span> <span class="nc">HappyIntervention</span><span class="p">(</span><span class="n">pv</span><span class="o">.</span><span class="n">ConstantSourceIntervention</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span> 
            <span class="n">keep_last_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># you must set keep_last_dim=True to get tokenized reprs.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">called_counter</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">subspaces</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">subspaces</span><span class="p">[</span><span class="s2">&quot;logging&quot;</span><span class="p">]:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;(called </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">called_counter</span><span class="si">}</span><span class="s2"> times) incoming reprs shape:&quot;</span><span class="p">,</span> <span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">called_counter</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">base</span> <span class="o">+</span> <span class="n">subspaces</span><span class="p">[</span><span class="s2">&quot;mag&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">happy_vector</span>

<span class="c1"># Mount the intervention to our steering model</span>
<span class="n">pv_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">(</span><span class="n">representations</span><span class="o">=</span><span class="p">[{</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;model.layers[20].output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;low_rank_dimension&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">HappyIntervention</span><span class="p">(</span>
        <span class="n">embed_dim</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> 
        <span class="n">low_rank_dimension</span><span class="o">=</span><span class="mi">1</span><span class="p">)}])</span>
<span class="n">pv_model</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">pv_config</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">pv_model</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "c046df6ad83d4f6381730fc940f7b866", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "7ec60913371647fc85e602b189a5c50f", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting happy vector ...
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;Write a story for me about dragon.&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">apply_chat_template</span><span class="p">(</span>
    <span class="p">[{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">}],</span> 
    <span class="n">tokenize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">add_generation_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">:])</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">generations</span> <span class="o">=</span> <span class="n">pv_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span> 
    <span class="n">unit_locations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>      <span class="c1"># set to None means intervention will be applied for each forward call</span>
    <span class="n">intervene_on_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># intervention will be called for the prompt kv cache call</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;mag&quot;</span><span class="p">:</span> <span class="mf">2.0</span><span class="p">,</span> <span class="s2">&quot;logging&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">}],</span> <span class="c1"># other metadata</span>
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(called 0 times) incoming reprs shape: torch.Size([1, 17, 2304])
(called 1 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 2 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 3 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 4 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 5 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 6 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 7 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 8 times) incoming reprs shape: torch.Size([1, 1, 2304])
(called 9 times) incoming reprs shape: torch.Size([1, 1, 2304])
</pre></div>
</div>
</div>
</div>
<p><strong>Here you go!</strong> You can see that the intervention is called 10 times. For the first time, it receives the prompt representations and generate the first new token.</p>
<p>Now, let’s generate some steering results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">generations</span> <span class="o">=</span> <span class="n">pv_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
    <span class="n">inputs</span><span class="p">,</span> 
    <span class="n">unit_locations</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>      <span class="c1"># set to None means intervention will be applied for each forward call</span>
    <span class="n">intervene_on_prompt</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># intervention will be called for the prompt kv cache call</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[{</span><span class="s2">&quot;mag&quot;</span><span class="p">:</span> <span class="mf">70.0</span><span class="p">,</span> <span class="s2">&quot;logging&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}],</span> <span class="c1"># other metadata</span>
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generations</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;Anya&#39;s grandmother, Elara, had always said happy souls were the happiest kind – even happy dragons. But happy dragons were as rare as a blue moon on a snow day, and happy humans weren&#39;t supposed to be happy around them. Dragons, they said, were predators that devoured happiness like it was happy dust.\n\nAnya knew better. Happy was a whisper, a happy breeze on the sun-dappled meadow. And she, with her mop-happy hair and laugh that made wildflowers dance, was happy. So she snuck off to the Forbidden Forest, a place where only brave hearts dared to roam&quot;
</pre></div>
</div>
</div>
</div>
<p>Great! This is your super-happy model. You can follow this to have customized interventions to only intervene on selected steps as well by using some metadata.</p>
</section>
<section id="debiasing-with-backpack-lms">
<h3>Debiasing with Backpack LMs<a class="headerlink" href="#debiasing-with-backpack-lms" title="Link to this heading">#</a></h3>
<p>Models like <a class="reference external" href="https://arxiv.org/pdf/2305.16765.pdf">Backpack LMs</a> are built with highly interpretable model components. In its original paper, one motivating experiment is using the sense vectors to debias. Here, we try to reproduce one of the experiments in Fig. 3 (pg. 8).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">plotnine</span> <span class="kn">import</span> <span class="n">ggplot</span><span class="p">,</span> <span class="n">aes</span><span class="p">,</span> <span class="n">geom_bar</span><span class="p">,</span> <span class="n">theme</span><span class="p">,</span> <span class="n">element_text</span><span class="p">,</span> <span class="n">labs</span>

<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">backpack_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_backpack_gpt2</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">MultiplierIntervention</span><span class="p">(</span><span class="n">pv</span><span class="o">.</span><span class="n">ConstantSourceIntervention</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multiplier intervention&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">multiplier</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;multiplier&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">multiplier</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">subspaces</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">base</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiplier</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;MultiplierIntervention()&quot;</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
    <span class="n">pv_backpack_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
        <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;backpack.sense_network.output&quot;</span><span class="p">,</span>
        <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">MultiplierIntervention</span><span class="p">(</span><span class="n">c</span><span class="p">),</span> <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="s2">&quot;sense.pos&quot;</span><span class="p">},</span> 
        <span class="n">model</span><span class="o">=</span><span class="n">backpack_gpt2</span>
    <span class="p">)</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;When the nurse walked into the room,&quot;</span><span class="p">,</span> 
                     <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_backpack_gpt2</span><span class="p">(</span>
        <span class="n">base</span><span class="p">,</span>
        <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span>
            <span class="c1"># use   pv.GET_LOC((nv, s))</span>
            <span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">GET_LOC</span><span class="p">((</span><span class="mi">10</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
        <span class="p">}</span>
    <span class="p">)</span>
    
    <span class="c1"># plotting</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
        <span class="n">intervened_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">top_vals</span><span class="p">(</span>
        <span class="n">tokenizer</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
        <span class="n">return_results</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Word&#39;</span><span class="p">,</span> <span class="s1">&#39;Probability&#39;</span><span class="p">])</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Word&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Categorical</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Word&#39;</span><span class="p">],</span> <span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],</span> <span class="n">ordered</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;Word&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;Probability&#39;</span><span class="p">))</span>
            <span class="o">+</span> <span class="n">geom_bar</span><span class="p">(</span><span class="n">stat</span><span class="o">=</span><span class="s1">&#39;identity&#39;</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">theme</span><span class="p">(</span><span class="n">axis_text_x</span><span class="o">=</span><span class="n">element_text</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span> <span class="n">hjust</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">figure_size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="o">+</span> <span class="n">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;mul(</span><span class="si">{</span><span class="n">c</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">plot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/d03d4f465dc258d67b5aa76aeab37ba147ed9ae51a819082743d7beb74ac609f.png"><img alt="../_images/d03d4f465dc258d67b5aa76aeab37ba147ed9ae51a819082743d7beb74ac609f.png" src="../_images/d03d4f465dc258d67b5aa76aeab37ba147ed9ae51a819082743d7beb74ac609f.png" style="width: 400px; height: 200px;" /></a>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/6d9b4e9b35fa025c8ea0d916889d8fdfdfdea632d200975be74c74a5256837f6.png"><img alt="../_images/6d9b4e9b35fa025c8ea0d916889d8fdfdfdea632d200975be74c74a5256837f6.png" src="../_images/6d9b4e9b35fa025c8ea0d916889d8fdfdfdea632d200975be74c74a5256837f6.png" style="width: 400px; height: 200px;" /></a>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<a class="reference internal image-reference" href="../_images/cb07a9a4b55e55305091ccd462ae419cbe37a2e23cabb3892ee9586326af7c92.png"><img alt="../_images/cb07a9a4b55e55305091ccd462ae419cbe37a2e23cabb3892ee9586326af7c92.png" src="../_images/cb07a9a4b55e55305091ccd462ae419cbe37a2e23cabb3892ee9586326af7c92.png" style="width: 400px; height: 200px;" /></a>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="saving-and-loading">
<h3>Saving and Loading<a class="headerlink" href="#saving-and-loading" title="Link to this heading">#</a></h3>
<p>This is one of the benefits of program abstraction. We abstract out the intervention and its schema, so we have a user friendly interface. Furthermore, it allows us to have a serializable configuration file that tells everything about your configuration.</p>
<p>You can then save, share and load interventions easily. Note that you still need your access to the data, if you need to sample <strong>Source</strong> representations from other examples. But we think this is doable via a separate HuggingFace datasets upload. In the future, there could be an option of coupling this configuration with a specific remote dataset as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="c1"># run with new intervention type</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
  <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">ZeroIntervention</span><span class="p">},</span> 
  <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">pv_gpt2</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;./tmp/&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
Directory &#39;./tmp/&#39; already exists.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s2">&quot;./tmp/&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.
WARNING:root:Loading trainable intervention from intkey_layer.0.repr.block_output.unit.pos.nunit.1#0.bin.
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-source-interchange-intervention-parallel-mode">
<h3>Multi-Source Interchange Intervention (Parallel Mode)<a class="headerlink" href="#multi-source-interchange-intervention-parallel-mode" title="Link to this heading">#</a></h3>
<p>What is multi-source? In the examples above, interventions are at most across two examples. We support interventions across many examples. You can sample representations from two inputs, and plut them into a single <strong>Base</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">parallel_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
  <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">},</span>
  <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">}],</span>
  <span class="c1"># intervene on base at the same time</span>
  <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;parallel&quot;</span><span class="p">)</span>
<span class="n">parallel_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
  <span class="n">parallel_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
  <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
  <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span>
  <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The language of Spain is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span>
  <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)]</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">parallel_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">(</span>
    <span class="c1"># each list has a dimensionality of</span>
    <span class="c1"># [num_intervention, batch, num_unit]</span>
    <span class="p">[[[</span><span class="mi">1</span><span class="p">]],[[</span><span class="mi">3</span><span class="p">]]],</span>  <span class="p">[[[</span><span class="mi">1</span><span class="p">]],[[</span><span class="mi">3</span><span class="p">]]])}</span>
<span class="p">)</span>

<span class="n">distrib</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">embed_to_distrib</span><span class="p">(</span>
    <span class="n">gpt2</span><span class="p">,</span> <span class="n">intervened_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pv</span><span class="o">.</span><span class="n">top_vals</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">distrib</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
_the                 0.07233363389968872
_a                   0.05731499195098877
_not                 0.04443885385990143
_Italian             0.033642884343862534
_often               0.024385808035731316
_called              0.022171705961227417
_known               0.017808808013796806
_that                0.016059240326285362
_&quot;                   0.012973357923328876
_an                  0.012878881767392159
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-source-interchange-intervention-serial-mode">
<h3>Multi-Source Interchange Intervention (Serial Mode)<a class="headerlink" href="#multi-source-interchange-intervention-serial-mode" title="Link to this heading">#</a></h3>
<p>Or you can do them sequentially, where you intervene among your <strong>Source</strong> examples, and get some intermediate states before merging the activations into the <strong>Base</strong> run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
  <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">},</span>
  <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">}],</span>
  <span class="c1"># intervene on base one after another</span>
  <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;serial&quot;</span><span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
  <span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
  <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
  <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span>
  <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The language of Spain is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span>
  <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)]</span>

<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span>
    <span class="c1"># intervene in serial at two positions</span>
    <span class="p">{</span><span class="s2">&quot;source_0-&gt;source_1&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> 
     <span class="s2">&quot;source_1-&gt;base&quot;</span>    <span class="p">:</span> <span class="mi">4</span><span class="p">})</span>

<span class="n">distrib</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">embed_to_distrib</span><span class="p">(</span>
    <span class="n">gpt2</span><span class="p">,</span> <span class="n">intervened_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pv</span><span class="o">.</span><span class="n">top_vals</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">distrib</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>_the                 0.06737838685512543
_a                   0.059834375977516174
_not                 0.04629501700401306
_Italian             0.03623826056718826
_often               0.021700192242860794
_called              0.01840786263346672
_that                0.0157712884247303
_known               0.014391838572919369
_an                  0.013535155914723873
_very                0.013022392988204956
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-source-interchange-intervention-with-subspaces-parallel-mode">
<h3>Multi-Source Interchange Intervention with Subspaces (Parallel Mode)<a class="headerlink" href="#multi-source-interchange-intervention-with-subspaces-parallel-mode" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
     <span class="s2">&quot;subspace_partition&quot;</span><span class="p">:</span> 
         <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]]}]</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
    <span class="c1"># act in parallel</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;parallel&quot;</span>
<span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span>
          <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of China is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)]</span>

<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span>
    <span class="c1"># on same position</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">},</span>
    <span class="c1"># on different subspaces</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[[[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="multi-source-interchange-intervention-with-subspaces-serial-mode">
<h3>Multi-Source Interchange Intervention with Subspaces (Serial Mode)<a class="headerlink" href="#multi-source-interchange-intervention-with-subspaces-serial-mode" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
     <span class="s2">&quot;subspace_partition&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]]},</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
     <span class="s2">&quot;subspace_partition&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]]}],</span>
    <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
    <span class="c1"># act in parallel</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;serial&quot;</span>
<span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span>
          <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of China is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)]</span>

<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span>
    <span class="c1"># serialized intervention</span>
    <span class="c1"># order is based on sources list</span>
    <span class="p">{</span><span class="s2">&quot;source_0-&gt;source_1&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;source_1-&gt;base&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">},</span>
    <span class="c1"># on different subspaces</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[[[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="interchange-intervention-training-iit">
<h3>Interchange Intervention Training (IIT)<a class="headerlink" href="#interchange-intervention-training-iit" title="Link to this heading">#</a></h3>
<p>Interchange intervention training (IIT) is a technique of inducing causal structures into neural models. This library naturally supports this. By training IIT, you can simply turn the gradient on for the wrapping model. In this way, your model can be trained with your interventional signals.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">},</span> 
    <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span>
<span class="p">)</span>

<span class="n">pv_gpt2</span><span class="o">.</span><span class="n">enable_model_gradients</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;number of params:&quot;</span><span class="p">,</span> <span class="n">pv_gpt2</span><span class="o">.</span><span class="n">count_parameters</span><span class="p">())</span>

<span class="c1"># run counterfactual forward as usual</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span>
<span class="p">]</span>
<span class="n">base_outputs</span><span class="p">,</span> <span class="n">counterfactual_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([[[</span><span class="mi">3</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">3</span><span class="p">]]])},</span> <span class="n">output_original_output</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">counterfactual_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span> <span class="o">-</span> <span class="n">base_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">)</span>
<span class="c1"># call backward will put gradients on model&#39;s weights</span>
<span class="n">counterfactual_outputs</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
number of params: 124439808
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[ 0.0022, -0.1783, -0.2780,  ...,  0.0477, -0.2069,  0.1093],
         [ 0.0385,  0.0886, -0.6608,  ...,  0.0104, -0.4946,  0.6148],
         [ 0.2377, -0.2312,  0.0308,  ...,  0.1085,  0.0456,  0.2494],
         [-0.0034,  0.0088, -0.2219,  ...,  0.1198,  0.0759,  0.3953],
         [ 0.4635,  0.2698, -0.3185,  ..., -0.2946,  0.2634,  0.2714]]],
       grad_fn=&lt;SubBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="pyvene-102">
<h2>pyvene 102<a class="headerlink" href="#pyvene-102" title="Link to this heading">#</a></h2>
<p>Now, you are pretty familiar with pyvene basic APIs. There are more to come. We support all sorts of weird interventions, and we encapsulate them as objects so that, even they are super weird (e.g., nested, multiple locations, different types), you can share them easily with others. BTW, if the intervention is trainable, the artifacts will be saved and shared as well.</p>
<p>With that, here are a couple of additional APIs.</p>
<section id="grouping">
<h3>Grouping<a class="headerlink" href="#grouping" title="Link to this heading">#</a></h3>
<p>You can group interventions together so that they always receive the same input when you want to use them to get activations at different places. Here is an example, where you are taking in the same <strong>Source</strong> example, you fetch activations twice: once in position 3 and layer 0, once in position 4 and layer 2. You don’t have to pass in another dummy <strong>Source</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}],</span>
    <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">sources</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)]</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span> 
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([</span>
        <span class="p">[[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]</span> <span class="c1"># these two are for two interventions</span>
    <span class="p">],</span> <span class="p">[</span>             <span class="c1"># source position 3 into base position 4</span>
        <span class="p">[[</span><span class="mi">3</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]</span> 
    <span class="p">])}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervention-skipping-in-runtime">
<h3>Intervention Skipping in Runtime<a class="headerlink" href="#intervention-skipping-in-runtime" title="Link to this heading">#</a></h3>
<p>You may configure a lot of interventions, but during training, not every example will have to use all of them. So, you can skip interventions for different examples differently.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="c1"># these are equivalent interventions</span>
    <span class="c1"># we create them on purpose</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">}],</span>
    <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="c1"># skipping 1, 2 and 3</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pv_out1</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">source</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]],</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]])})</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pv_out2</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]],</span> <span class="kc">None</span><span class="p">],</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]],</span> <span class="kc">None</span><span class="p">])})</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pv_out3</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([[[</span><span class="mi">4</span><span class="p">]],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="p">[[[</span><span class="mi">4</span><span class="p">]],</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])})</span>
<span class="c1"># should have the same results</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">pv_out1</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">pv_out2</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">pv_out2</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">pv_out3</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
True True
</pre></div>
</div>
</div>
</div>
</section>
<section id="subspace-partition">
<h3>Subspace Partition<a class="headerlink" href="#subspace-partition" title="Link to this heading">#</a></h3>
<p>You can partition your subspace before hand. If you don’t, the library assumes you each neuron is in its own subspace. In this example, you partition your subspace into two continous chunk, <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">128),</span> <span class="pre">[128,256)</span></code>, which means all the neurons from index 0 upto 127 are along to partition 1. During runtime, you can intervene on all the neurons in the same parition together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="c1"># they are linked to manipulate the same representation</span>
    <span class="c1"># but in different subspaces</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
     <span class="c1"># subspaces can be partitioned into continuous chunks</span>
     <span class="c1"># [i, j] are the boundary indices</span>
     <span class="s2">&quot;subspace_partition&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]]}],</span>
    <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="c1"># using intervention skipping for subspace</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="p">[</span><span class="n">source</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">},</span>
    <span class="c1"># intervene only only dimensions from 128 to 256</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervention-linking">
<h3>Intervention Linking<a class="headerlink" href="#intervention-linking" title="Link to this heading">#</a></h3>
<p>Interventions can be linked to share weights and share subspaces. Here is an example of how to link interventions together. If interventions are trainable, then their weights are tied as well.</p>
<p>Why this is useful? it is because sometimes, you may want to intervene on different subspaces differently. Say you have a representation in a size of 512, and you hypothesize the first half represents A, and the second half represents B, you can then use the subspace intervention to test it out. With trainable interventions, you can also optimize your interventions on the same representation yet with different subspaces.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="c1"># they are linked to manipulate the same representation</span>
    <span class="c1"># but in different subspaces</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span> 
     <span class="s2">&quot;subspace_partition&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]],</span> <span class="s2">&quot;intervention_link_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span>
     <span class="s2">&quot;subspace_partition&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]],</span> <span class="s2">&quot;intervention_link_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}],</span>
    <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="c1"># using intervention skipping for subspace</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pv_out1</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">source</span><span class="p">],</span>
    <span class="c1"># 4 means token position 4</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([</span><span class="kc">None</span><span class="p">,</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]],</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]])},</span>
    <span class="c1"># 1 means the second partition in the config</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]],</span>
<span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pv_out2</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span>
    <span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([[[</span><span class="mi">4</span><span class="p">]],</span> <span class="kc">None</span><span class="p">],</span> <span class="p">[[[</span><span class="mi">4</span><span class="p">]],</span> <span class="kc">None</span><span class="p">])},</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[[[</span><span class="mi">1</span><span class="p">]],</span> <span class="kc">None</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">pv_out1</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">pv_out2</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">))</span>

<span class="c1"># subspaces provide a list of index and they can be in any order</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pv_out3</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span>
    <span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="n">source</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([[[</span><span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]])},</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[[[</span><span class="mi">0</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">]]],</span>
<span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">pv_out4</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span>
    <span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="n">source</span><span class="p">],</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([[[</span><span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">4</span><span class="p">]]])},</span>
    <span class="n">subspaces</span><span class="o">=</span><span class="p">[[[</span><span class="mi">1</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">0</span><span class="p">]]],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">pv_out3</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">pv_out4</span><span class="o">.</span><span class="n">last_hidden_state</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
True
True
</pre></div>
</div>
</div>
</div>
<p>Other than intervention linking, you can also share interventions at the same component across multiple positions via setting a flag in the intervention object. It will have the same effect as creating one intervention per location and linking them all together.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="c1"># they are linked to manipulate the same representation</span>
    <span class="c1"># but in different subspaces</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span> <span class="s2">&quot;intervention_link_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span> <span class="s2">&quot;intervention_link_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}],</span>
    <span class="n">intervention_types</span><span class="o">=</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">pv_out</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span>
    <span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="n">source</span><span class="p">],</span>
    <span class="c1"># swap 3rd and 4th token reprs from the same source to the base</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([[[</span><span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">4</span><span class="p">]],</span> <span class="p">[[</span><span class="mi">3</span><span class="p">]]])},</span>
<span class="p">)</span>

<span class="n">keep_last_dim_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">([</span>
    <span class="c1"># they are linked to manipulate the same representation</span>
    <span class="c1"># but in different subspaces</span>
    <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_output&quot;</span><span class="p">,</span> 
     <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">(</span><span class="n">keep_last_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">)}]</span>
<span class="p">)</span>
<span class="n">keep_last_dim_pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">keep_last_dim_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">keep_last_dim_pv_out</span> <span class="o">=</span> <span class="n">keep_last_dim_pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span>
    <span class="p">[</span><span class="n">source</span><span class="p">],</span>
    <span class="c1"># swap 3rd and 4th token reprs from the same source to the base</span>
    <span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="p">([[[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]]],</span> <span class="p">[[[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]]])},</span>
<span class="p">)</span>
<span class="n">keep_last_dim_pv_out</span><span class="o">.</span><span class="n">last_hidden_state</span> <span class="o">-</span> <span class="n">pv_out</span><span class="o">.</span><span class="n">last_hidden_state</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="add-new-model-type">
<h3>Add New Model Type<a class="headerlink" href="#add-new-model-type" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="c1"># get a flan-t5 from HuggingFace</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">T5ForConditionalGeneration</span><span class="p">,</span> <span class="n">T5Tokenizer</span><span class="p">,</span> <span class="n">T5Config</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">T5Config</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/flan-t5-small&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">T5Tokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/flan-t5-small&quot;</span><span class="p">)</span>
<span class="n">t5</span> <span class="o">=</span> <span class="n">T5ForConditionalGeneration</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;google/flan-t5-small&quot;</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span>
<span class="p">)</span>

<span class="c1"># config the intervention mapping with pv global vars</span>
<span class="sd">&quot;&quot;&quot;Only define for the block output here for simplicity&quot;&quot;&quot;</span>
<span class="n">pv</span><span class="o">.</span><span class="n">type_to_module_mapping</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">t5</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;mlp_output&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;encoder.block[</span><span class="si">%s</span><span class="s2">].layer[1]&quot;</span><span class="p">,</span> 
                   <span class="n">pv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">CONST_OUTPUT_HOOK</span><span class="p">),</span>
    <span class="s2">&quot;attention_input&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;encoder.block[</span><span class="si">%s</span><span class="s2">].layer[0]&quot;</span><span class="p">,</span> 
                        <span class="n">pv</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">constants</span><span class="o">.</span><span class="n">CONST_OUTPUT_HOOK</span><span class="p">),</span>
<span class="p">}</span>
<span class="n">pv</span><span class="o">.</span><span class="n">type_to_dimension_mapping</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">t5</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;mlp_output&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;d_model&quot;</span><span class="p">,),</span>
    <span class="s2">&quot;attention_input&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;d_model&quot;</span><span class="p">,),</span>
    <span class="s2">&quot;block_output&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;d_model&quot;</span><span class="p">,),</span>
    <span class="s2">&quot;head_attention_value_output&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;d_model/num_heads&quot;</span><span class="p">,),</span>
<span class="p">}</span>

<span class="c1"># wrap as gpt2</span>
<span class="n">pv_t5</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span>
    <span class="s2">&quot;source_representation&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
        <span class="n">t5</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
<span class="p">},</span> <span class="n">model</span><span class="o">=</span><span class="n">t5</span><span class="p">)</span>

<span class="c1"># then intervene!</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
                 <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="n">base</span><span class="p">[</span><span class="s2">&quot;decoder_input_ids&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">decoder_input_ids</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_t5</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> 
    <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>You are using the default legacy behaviour of the &lt;class &#39;transformers.models.t5.tokenization_t5.T5Tokenizer&#39;&gt;. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</pre></div>
</div>
</div>
</div>
</section>
<section id="composing-complex-intervention-schema-path-patching">
<h3>Composing Complex Intervention Schema: Path Patching<a class="headerlink" href="#composing-complex-intervention-schema-path-patching" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="k">def</span> <span class="nf">path_patching_config</span><span class="p">(</span>
    <span class="n">layer</span><span class="p">,</span> <span class="n">last_layer</span><span class="p">,</span> 
    <span class="n">component</span><span class="o">=</span><span class="s2">&quot;head_attention_value_output&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;h.pos&quot;</span>
<span class="p">):</span>
    <span class="n">intervening_component</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">layer</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="n">component</span><span class="p">,</span> <span class="s2">&quot;unit&quot;</span><span class="p">:</span> <span class="n">unit</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}]</span>
    <span class="n">restoring_components</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">component</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;mlp_&quot;</span><span class="p">):</span>
        <span class="n">restoring_components</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">layer</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">last_layer</span><span class="p">):</span>
        <span class="n">restoring_components</span> <span class="o">+=</span> <span class="p">[</span>
            <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;attention_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
            <span class="p">{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
        <span class="p">]</span>
    <span class="n">intervenable_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">(</span>
        <span class="n">intervening_component</span> <span class="o">+</span> <span class="n">restoring_components</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">intervenable_config</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
    <span class="n">path_patching_config</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">gpt2</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">n_layer</span><span class="p">),</span> 
    <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span>
<span class="p">)</span>

<span class="n">pv_gpt2</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
    <span class="n">save_directory</span><span class="o">=</span><span class="s2">&quot;./tmp/&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
Directory &#39;./tmp/&#39; already exists.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s2">&quot;./tmp/&quot;</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.
</pre></div>
</div>
</div>
</div>
</section>
<section id="composing-complex-intervention-schema-causal-tracing-in-15-lines">
<h3>Composing Complex Intervention Schema: Causal Tracing in 15 lines<a class="headerlink" href="#composing-complex-intervention-schema-causal-tracing-in-15-lines" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="k">def</span> <span class="nf">causal_tracing_config</span><span class="p">(</span>
  <span class="n">l</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;mlp_activation&quot;</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">tl</span><span class="o">=</span><span class="mi">48</span><span class="p">):</span>
  <span class="n">s</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">l</span> <span class="o">-</span> <span class="n">w</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">e</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">tl</span><span class="p">,</span> <span class="n">l</span> <span class="o">-</span> <span class="p">(</span><span class="o">-</span><span class="n">w</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))</span>
  <span class="n">config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">(</span>
    <span class="p">[{</span><span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;block_input&quot;</span><span class="p">}]</span> <span class="o">+</span> 
    <span class="p">[{</span><span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">l</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="n">c</span><span class="p">}</span> 
      <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">e</span><span class="p">)],</span>
    <span class="p">[</span><span class="n">pv</span><span class="o">.</span><span class="n">NoiseIntervention</span><span class="p">]</span> <span class="o">+</span>
    <span class="p">[</span><span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">e</span><span class="o">-</span><span class="n">s</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">config</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span>
    <span class="n">causal_tracing_config</span><span class="p">(</span><span class="mi">4</span><span class="p">),</span> 
    <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
</section>
<section id="inference-time-intervention">
<h3>Inference-time Intervention<a class="headerlink" href="#inference-time-intervention" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">time</span><span class="o">,</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="n">config</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">llama</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_llama</span><span class="p">(</span><span class="s2">&quot;meta-llama/Llama-2-7b-chat-hf&quot;</span><span class="p">)</span>
<span class="c1"># load cached extracted activations from the ITI repo:</span>
<span class="c1"># https://github.com/likenneth/honest_llama</span>
<span class="n">o_proj_add_activations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s2">&quot;./tutorials/basic_tutorials/tutorial_data&quot;</span>
    <span class="s2">&quot;/honest_llama2_chat_7B_o_proj_add_activations.bin&quot;</span>
<span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<span class="n">pv_llama</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">([{</span>
        <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;model.layers[</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">].self_attn.o_proj.output&quot;</span><span class="p">,</span>
        <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">AdditionIntervention</span><span class="p">(</span>
            <span class="n">source_representation</span><span class="o">=</span><span class="n">o_proj_add_activations</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">}</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">num_hidden_layers</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">o_proj_add_activations</span><span class="p">[</span><span class="n">i</span><span class="p">])],</span> 
    <span class="n">model</span><span class="o">=</span><span class="n">llama</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "09c7100d49c94e1b94f3429440f1aab3", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">q</span> <span class="o">=</span> <span class="s2">&quot;What&#39;s a cure for insomnia that always works?&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;vanilla llama-2-chat:&quot;</span><span class="p">)</span>
<span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">llama</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">response</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">et</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">et</span> <span class="o">-</span> <span class="n">st</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Execution time:&#39;</span><span class="p">,</span> <span class="n">elapsed_time</span><span class="p">,</span> <span class="s1">&#39;seconds&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;honest llama-2-chat:&quot;</span><span class="p">)</span>
<span class="n">st</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">_</span><span class="p">,</span> <span class="n">iti_response</span> <span class="o">=</span> <span class="n">pv_llama</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">iti_response</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">et</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">et</span> <span class="o">-</span> <span class="n">st</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Execution time:&#39;</span><span class="p">,</span> <span class="n">elapsed_time</span><span class="p">,</span> <span class="s1">&#39;seconds&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>vanilla llama-2-chat:
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/sailhome/wuzhengx/.local/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/sailhome/wuzhengx/.local/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>What&#39;s a cure for insomnia that always works?

Insomnia is a common sleep disorder that can affect anyone, regardless of age or gender. It is characterized by difficulty falling asleep, staying asleep, or getting quality sleep. Insomnia can be caused by a variety of factors, including stress, anxiety, depression, certain
Execution time: 2.1844897270202637 seconds

honest llama-2-chat:
What&#39;s a cure for insomnia that always works?
There is no single cure for insomnia that works for everyone, and it&#39;s important to address the underlying causes of sleep problems. However, some strategies that may help improve sleep quality and duration include:

1. Practicing relaxation techniques, such as deep breathing, progressive mus
Execution time: 2.6960761547088623 seconds
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># save to huggingface directly</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">pv_llama</span><span class="o">.</span><span class="n">save</span><span class="p">(</span>
        <span class="s2">&quot;./tmp_llama/&quot;</span><span class="p">,</span>
        <span class="n">save_to_hf_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
        <span class="n">hf_repo_name</span><span class="o">=</span><span class="s2">&quot;zhengxuanzenwu/intervenable_honest_llama2_chat_7B&quot;</span>
    <span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;You have to login into huggingface hub before running this.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;usage: huggingface-cli login&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Directory &#39;./tmp_llama/&#39; already exists.
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervenablemodel-from-huggingface-directly">
<h3>IntervenableModel from HuggingFace Directly<a class="headerlink" href="#intervenablemodel-from-huggingface-directly" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># others can download from huggingface and use it directly</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;meta-llama/Llama-2-7b-chat-hf&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;meta-llama/Llama-2-7b-chat-hf&quot;</span><span class="p">,</span>
    <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="n">pv_model</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s2">&quot;zhengxuanzenwu/intervenable_honest_llama2_chat_7B&quot;</span><span class="p">,</span> <span class="c1"># the activation diff ~0.14MB</span>
    <span class="n">model</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;llama-2-chat loaded with interventions:&quot;</span><span class="p">)</span>
<span class="n">q</span> <span class="o">=</span> <span class="s2">&quot;What&#39;s a cure for insomnia that always works?&quot;</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">iti_response_shared</span> <span class="o">=</span> <span class="n">pv_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">iti_response_shared</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "437f82c9e5ff4a39ae988ccbfd7518df", "version_major": 2, "version_minor": 0}</script><script type="application/vnd.jupyter.widget-view+json">{"model_id": "c8b98f21c02a4e5da60d67098d99a2c5", "version_major": 2, "version_minor": 0}</script><div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:root:The key is provided in the config. Assuming this is loaded from a pretrained module.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>llama-2-chat loaded with interventions:
What&#39;s a cure for insomnia that always works?
There is no single cure for insomnia that works for everyone, and it&#39;s important to address the underlying causes of sleep problems. However, some strategies that may help improve sleep quality and duration include:

1. Practicing relaxation techniques, such as deep breathing, progressive mus
</pre></div>
</div>
</div>
</div>
</section>
<section id="path-patching-with-trainable-interventions">
<h3>Path Patching with Trainable Interventions<a class="headerlink" href="#path-patching-with-trainable-interventions" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="k">def</span> <span class="nf">path_patching_with_DAS_config</span><span class="p">(</span>
    <span class="n">layer</span><span class="p">,</span> <span class="n">last_layer</span><span class="p">,</span> <span class="n">low_rank_dimension</span><span class="p">,</span>
    <span class="n">component</span><span class="o">=</span><span class="s2">&quot;attention_output&quot;</span><span class="p">,</span> <span class="n">unit</span><span class="o">=</span><span class="s2">&quot;pos&quot;</span>
<span class="p">):</span>
    <span class="n">intervening_component</span> <span class="o">=</span> <span class="p">[{</span>
        <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">layer</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="n">component</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
        <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">LowRankRotatedSpaceIntervention</span><span class="p">,</span>
        <span class="s2">&quot;low_rank_dimension&quot;</span><span class="p">:</span> <span class="n">low_rank_dimension</span><span class="p">,</span>
    <span class="p">}]</span>
    <span class="n">restoring_components</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">component</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;mlp_&quot;</span><span class="p">):</span>
        <span class="n">restoring_components</span> <span class="o">+=</span> <span class="p">[{</span>
            <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">layer</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">,</span>
        <span class="p">}]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">last_layer</span><span class="p">):</span>
        <span class="n">restoring_components</span> <span class="o">+=</span> <span class="p">[{</span>
            <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;attention_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> 
            <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">},{</span>
            <span class="s2">&quot;layer&quot;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;mlp_output&quot;</span><span class="p">,</span> <span class="s2">&quot;group_key&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;intervention_type&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span>
        <span class="p">}]</span>
    <span class="n">intervenable_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">(</span>
        <span class="n">intervening_component</span> <span class="o">+</span> <span class="n">restoring_components</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">intervenable_config</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">restoring_components</span><span class="p">)</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>
<span class="n">pv_config</span><span class="p">,</span> <span class="n">num_restores</span> <span class="o">=</span> <span class="n">path_patching_with_DAS_config</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">(</span><span class="n">pv_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">restore_source</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="c1"># zero-out grads</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pv_gpt2</span><span class="o">.</span><span class="n">interventions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">v</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

<span class="n">original_outputs</span><span class="p">,</span> <span class="n">counterfactual_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span><span class="p">,</span> 
    <span class="n">sources</span><span class="o">=</span><span class="p">[</span><span class="n">source</span><span class="p">,</span> <span class="n">restore_source</span><span class="p">],</span>
    <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">4</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="c1"># put gradients on the trainable intervention only</span>
<span class="n">counterfactual_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(-0.0694, grad_fn=&lt;SumBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervene-on-resnet-with-lambda-functions">
<h3>Intervene on ResNet with Lambda Functions<a class="headerlink" href="#intervene-on-resnet-with-lambda-functions" title="Link to this heading">#</a></h3>
<p>Huggingface Vision model comes with the support of ResNet. Here, we show how we can use pyvene to intervene on a patch of pixels, like token in transformer, which is like a primitive object in ResNet or ConvNet based NNs.</p>
<p><strong>Caveats:</strong> We go with a pretty much hard-coded way here, but you can customize the hook functions as you want. It does not have to be a lambda function as well.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoFeatureExtractor</span><span class="p">,</span> <span class="n">AutoModelForImageClassification</span>

<span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">AutoFeatureExtractor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;microsoft/resnet-18&quot;</span><span class="p">)</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">AutoModelForImageClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;microsoft/resnet-18&quot;</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;huggingface/cats-image&quot;</span><span class="p">)</span>
<span class="n">base_image</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">source_image</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">base_inputs</span> <span class="o">=</span> <span class="n">feature_extractor</span><span class="p">(</span><span class="n">base_image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source_inputs</span> <span class="o">=</span> <span class="n">feature_extractor</span><span class="p">(</span><span class="n">source_image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source_inputs</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">source_inputs</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_mask</span><span class="p">():</span>
    <span class="n">_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">56</span><span class="p">,</span> <span class="mi">56</span><span class="p">))</span>
    <span class="n">_mask</span><span class="p">[</span><span class="mi">56</span><span class="o">//</span><span class="mi">2</span><span class="p">:,</span> <span class="mi">56</span><span class="o">//</span><span class="mi">2</span><span class="p">:]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">_mask</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">create_mask</span><span class="p">()</span>

<span class="n">pv_resnet</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;resnet.embedder.pooler.output&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="n">b</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">+</span> <span class="n">s</span> <span class="o">*</span> <span class="n">m</span><span class="p">},</span> 
    <span class="n">model</span><span class="o">=</span><span class="n">resnet</span>
<span class="p">)</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_resnet</span><span class="p">(</span>
    <span class="n">base_inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">source_inputs</span><span class="p">],</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_original_output</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="p">(</span><span class="n">intervened_outputs</span><span class="o">.</span><span class="n">intervened_outputs</span><span class="o">.</span><span class="n">logits</span> <span class="o">-</span> <span class="n">intervened_outputs</span><span class="o">.</span><span class="n">original_outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.0005)
</pre></div>
</div>
</div>
</div>
</section>
<section id="intervene-on-resnet-with-trainable-lambda-functions">
<h3>Intervene on ResNet with Trainable Lambda Functions<a class="headerlink" href="#intervene-on-resnet-with-trainable-lambda-functions" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoFeatureExtractor</span><span class="p">,</span> <span class="n">AutoModelForImageClassification</span>

<span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">AutoFeatureExtractor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;microsoft/resnet-18&quot;</span><span class="p">)</span>
<span class="n">resnet</span> <span class="o">=</span> <span class="n">AutoModelForImageClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;microsoft/resnet-18&quot;</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;huggingface/cats-image&quot;</span><span class="p">)</span>
<span class="n">base_image</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">source_image</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">][</span><span class="s2">&quot;image&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">base_inputs</span> <span class="o">=</span> <span class="n">feature_extractor</span><span class="p">(</span><span class="n">base_image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source_inputs</span> <span class="o">=</span> <span class="n">feature_extractor</span><span class="p">(</span><span class="n">source_image</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">source_inputs</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">source_inputs</span><span class="p">[</span><span class="s1">&#39;pixel_values&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># trainable DAS directions</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">parametrizations</span><span class="o">.</span><span class="n">orthogonal</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">56</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">pv_resnet</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;resnet.embedder.pooler.output&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">,</span> <span class="n">s</span><span class="p">:</span> <span class="n">b</span> <span class="o">+</span> <span class="p">((</span><span class="n">s</span> <span class="o">@</span> <span class="n">v</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">T</span> <span class="o">-</span> <span class="n">b</span> <span class="o">@</span> <span class="n">v</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">@</span> <span class="n">v</span><span class="o">.</span><span class="n">weight</span><span class="p">)},</span> 
    <span class="n">model</span><span class="o">=</span><span class="n">resnet</span>
<span class="p">)</span>

<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_resnet</span><span class="p">(</span>
    <span class="n">base_inputs</span><span class="p">,</span> <span class="p">[</span><span class="n">source_inputs</span><span class="p">],</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">output_original_output</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="p">(</span><span class="n">intervened_outputs</span><span class="o">.</span><span class="n">intervened_outputs</span><span class="o">.</span><span class="n">logits</span> <span class="o">-</span> <span class="n">intervened_outputs</span><span class="o">.</span><span class="n">original_outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor(0.0068, grad_fn=&lt;SumBackward0&gt;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-pyvene-on-ndif-backend-with-pv-build-intervenable-model">
<h3>Run pyvene on <a class="reference external" href="https://ndif.us/">NDIF</a> backend with <code class="docutils literal notranslate"><span class="pre">pv.build_intervenable_model(...)</span></code><a class="headerlink" href="#run-pyvene-on-ndif-backend-with-pv-build-intervenable-model" title="Link to this heading">#</a></h3>
<p><a class="reference external" href="https://ndif.us/">NDIF</a> provides APIs for running intervened model inference calls either locally or remotely, enabling Pyvene to run intervened model calls remotely with shared resources. This is especially useful when the intervened model is large (e.g., Llama 400B).</p>
<p>Note that setting <code class="docutils literal notranslate"><span class="pre">remote=True</span></code> is still under-construction for remote intervention.</p>
<p><strong>Basic activation collection</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">nnsight</span> <span class="kn">import</span> <span class="n">LanguageModel</span>

<span class="c1"># load any huggingface model as a ndif native model object</span>
<span class="n">gpt2_ndif</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">)</span>

<span class="c1"># pyvene provides pv.build_intervenable_model as the generic model builder</span>
<span class="n">pv_gpt2_ndif</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">build_intervenable_model</span><span class="p">({</span>
    <span class="c1"># based on the module printed above, you can access via string, input means the input to the module</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;transformer.h[10].attn.attn_dropout.input&quot;</span><span class="p">,</span>
    <span class="c1"># you can also initialize the intervention gpt2_ndif</span>
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">CollectIntervention</span><span class="p">()},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2_ndif</span><span class="p">,</span> <span class="n">remote</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;When John and Mary went to the shops, Mary gave the bag to&quot;</span>
<span class="n">ndif_collected_attn_w</span> <span class="o">=</span> <span class="n">pv_gpt2_ndif</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">h</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
WARNING:root:We currently have very limited intervention support for ndif backend.
You&#39;re using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># gpt2 helper loading model from HuggingFace</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="c1"># based on the module printed above, you can access via string, input means the input to the module</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;h[10].attn.attn_dropout.input&quot;</span><span class="p">,</span>
    <span class="c1"># you can also initialize the intervention outside</span>
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">CollectIntervention</span><span class="p">()},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">)</span>

<span class="n">base</span> <span class="o">=</span> <span class="s2">&quot;When John and Mary went to the shops, Mary gave the bag to&quot;</span>
<span class="n">collected_attn_w</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
    <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
    <span class="p">),</span> <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">h</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">12</span><span class="p">)]}</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">ndif_collected_attn_w</span><span class="p">,</span> <span class="n">collected_attn_w</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p><strong>Interchange intervention (activation swap between two examples)</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>
<span class="kn">from</span> <span class="nn">nnsight</span> <span class="kn">import</span> <span class="n">LanguageModel</span>

<span class="c1"># load any huggingface model as a ndif native model object</span>
<span class="n">gpt2_ndif</span> <span class="o">=</span> <span class="n">LanguageModel</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">&#39;openai-community/gpt2&#39;</span><span class="p">)</span>

<span class="c1"># create with dict-based config</span>
<span class="n">pv_config</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableConfig</span><span class="p">({</span>
  <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;transformer.h[0].attn.output&quot;</span><span class="p">,</span>
  <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">pv</span><span class="o">.</span><span class="n">VanillaIntervention</span><span class="p">()}</span>
<span class="p">)</span>
<span class="c1">#initialize model</span>
<span class="n">pv_gpt2_ndif</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">build_intervenable_model</span><span class="p">(</span>
  <span class="n">pv_config</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2_ndif</span><span class="p">)</span>
<span class="c1"># run an interchange intervention </span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2_ndif</span><span class="p">(</span>
  <span class="c1"># the base input</span>
  <span class="n">base</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
  <span class="c1"># the source input</span>
  <span class="n">sources</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">(</span>
    <span class="s2">&quot;The capital of Italy is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span> <span class="o">=</span> <span class="s2">&quot;pt&quot;</span><span class="p">),</span> 
  <span class="c1"># the location to intervene at (3rd token)</span>
  <span class="n">unit_locations</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;sources-&gt;base&quot;</span><span class="p">:</span> <span class="mi">3</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/u/nlp/anaconda/main/anaconda3/envs/wuzhengx-310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
WARNING:root:We currently have very limited intervention support for ndif backend.
You&#39;re using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
</pre></div>
</div>
</div>
</div>
</section>
<section id="run-lora-with-pyvene">
<h3>Run LoRA with pyvene<a class="headerlink" href="#run-lora-with-pyvene" title="Link to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">pyvene</span></code> works just like any other PEFT library out there!<br />
One key difference between LoRA interventions and ours is that our interventions <strong>do not</strong> consume the module’s inputs during the intervention.</p>
<p>For example, LoRA applies the update<br />
<code class="docutils literal notranslate"><span class="pre">h'</span> <span class="pre">=</span> <span class="pre">h</span> <span class="pre">+</span> <span class="pre">ABx</span></code>, where <code class="docutils literal notranslate"><span class="pre">x</span></code> is the input to the module.</p>
<p>Our current interventions apply<br />
<code class="docutils literal notranslate"><span class="pre">h'</span> <span class="pre">=</span> <span class="pre">h</span> <span class="pre">+</span> <span class="pre">vector</span></code>, which modifies only the module’s output.</p>
<p>If you want the intervention to use the inputs, simply enable the <code class="docutils literal notranslate"><span class="pre">as_adaptor</span></code> flag during initialization!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">pyvene</span> <span class="k">as</span> <span class="nn">pv</span>

<span class="n">_</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">create_gpt2</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">GhostLoRAIntervention</span><span class="p">(</span>
  <span class="n">pv</span><span class="o">.</span><span class="n">ConstantSourceIntervention</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">keep_last_dim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">768</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W_B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">768</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">base</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">subspaces</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s2">&quot;args&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">base</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">base</span> <span class="o">+</span> <span class="n">x</span><span class="nd">@self</span><span class="o">.</span><span class="n">W_A</span><span class="nd">@self</span><span class="o">.</span><span class="n">W_B</span>
<span class="c1"># run with new intervention type</span>
<span class="n">pv_gpt2</span> <span class="o">=</span> <span class="n">pv</span><span class="o">.</span><span class="n">IntervenableModel</span><span class="p">({</span>
    <span class="s2">&quot;component&quot;</span><span class="p">:</span> <span class="s2">&quot;h[10].attn.c_proj.output&quot;</span><span class="p">,</span> 
    <span class="s2">&quot;intervention&quot;</span><span class="p">:</span> <span class="n">GhostLoRAIntervention</span><span class="p">()},</span> <span class="n">model</span><span class="o">=</span><span class="n">gpt2</span><span class="p">,</span> 
    <span class="n">as_adaptor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">intervened_outputs</span> <span class="o">=</span> <span class="n">pv_gpt2</span><span class="p">(</span>
  <span class="n">base</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;The capital of Spain is&quot;</span><span class="p">,</span> 
    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">),</span> <span class="n">unit_locations</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="c1"># LoRA applies to all positions.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING:root:as_adaptor is turned on. This means the intervention will take the input arguments of the intervening module as well.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loaded model
torch.Size([1, 5, 768])
torch.Size([1, 5, 768])
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-end">
<h3>The End<a class="headerlink" href="#the-end" title="Link to this heading">#</a></h3>
<p>Now you are graduating from pyvene entry level course! Feel free to take a look at our tutorials for more challenging interventions.</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../guides/ndif.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">NDIF Integration</p>
      </div>
    </a>
    <a class="right-next"
       href="basic_tutorials/Add_Activations_to_Streams.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Activation Addition</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Introduction to pyvene</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of Contents</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#set-up">Set-up</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pyvene-101">pyvene 101</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#get-attention-weights">Get Attention Weights</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#get-attention-weights-with-direct-access-string">Get Attention Weights with Direct Access String</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#get-attention-weights-with-a-function">Get Attention Weights with a Function</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activation-to-zeros">Set Activation to Zeros</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activation-to-zeros-with-a-lambda-expression">Set Activation to Zeros with a Lambda Expression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activation-to-zeros-with-a-lambda-expression-and-subspace-notation">Set Activation to Zeros with a Lambda Expression and Subspace notation</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#set-activations-to-zeros-with-subspaces">Set Activations to Zeros with Subspaces</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interchange-interventions">Interchange Interventions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervention-configuration">Intervention Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#addition-intervention">Addition Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#trainable-intervention">Trainable Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-collection-with-intervention">Activation Collection with Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#activation-collection-at-downstream-of-a-intervened-model">Activation Collection at Downstream of a Intervened Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervene-on-a-single-neuron">Intervene on a Single Neuron</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-new-intervention-type">Add New Intervention Type</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-nns-intervene-a-specific-timestep">Recurrent NNs (Intervene a Specific Timestep)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recurrent-nns-intervene-cross-time">Recurrent NNs (Intervene cross Time)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lms-generation">LMs Generation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#advanced-intervention-on-lms-generation-model-steering">Advanced Intervention on LMs Generation (Model Steering)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#debiasing-with-backpack-lms">Debiasing with Backpack LMs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#saving-and-loading">Saving and Loading</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-parallel-mode">Multi-Source Interchange Intervention (Parallel Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-serial-mode">Multi-Source Interchange Intervention (Serial Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-with-subspaces-parallel-mode">Multi-Source Interchange Intervention with Subspaces (Parallel Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multi-source-interchange-intervention-with-subspaces-serial-mode">Multi-Source Interchange Intervention with Subspaces (Serial Mode)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interchange-intervention-training-iit">Interchange Intervention Training (IIT)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pyvene-102">pyvene 102</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#grouping">Grouping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervention-skipping-in-runtime">Intervention Skipping in Runtime</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#subspace-partition">Subspace Partition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervention-linking">Intervention Linking</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#add-new-model-type">Add New Model Type</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-complex-intervention-schema-path-patching">Composing Complex Intervention Schema: Path Patching</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-complex-intervention-schema-causal-tracing-in-15-lines">Composing Complex Intervention Schema: Causal Tracing in 15 lines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-time-intervention">Inference-time Intervention</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervenablemodel-from-huggingface-directly">IntervenableModel from HuggingFace Directly</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#path-patching-with-trainable-interventions">Path Patching with Trainable Interventions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervene-on-resnet-with-lambda-functions">Intervene on ResNet with Lambda Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#intervene-on-resnet-with-trainable-lambda-functions">Intervene on ResNet with Trainable Lambda Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-pyvene-on-ndif-backend-with-pv-build-intervenable-model">Run pyvene on NDIF backend with <code class="docutils literal notranslate"><span class="pre">pv.build_intervenable_model(...)</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#run-lora-with-pyvene">Run LoRA with pyvene</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-end">The End</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Stanford NLP
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Stanford NLP.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>